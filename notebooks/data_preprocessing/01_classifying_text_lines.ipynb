{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying text lines\n",
    "\n",
    "A classifier is trained to classify single text lines of a report. For example, the lines can be classified as containing a diagnosis (`\"dm\"`) or history (`his`) of a patient. This task was used as a preprocessing step to later steps of structured information extraction. So that only lines classified as containing a diagnosis will be fed to a downstream classifier, extracting the exact diagnosis. This step might be unnecessary with modern transformers that can handle longer text inputs.\n",
    "\n",
    "The files containing the necessary information are inside the `data/raw/labelling` directory. It contains manually labelled reports from different sessions.\n",
    "\n",
    "The original classes per label are:\n",
    "\n",
    "| category    | subcategory       | abbreviation |\n",
    "|-------------|-------------------|--------------|\n",
    "| diagnosis   | MS diagnosis      | dm           |\n",
    "|             | other             | do           |\n",
    "| current state     |              | cu           |\n",
    "| history     |                   | his          |\n",
    "| symptoms    | MS related        | sym          |\n",
    "|             | other             | so           |\n",
    "| MRI | results                  | mr           |\n",
    "| lab | results                  | labr         |\n",
    "|             | other             | labo         |\n",
    "| medication  | MS related        | medms        |\n",
    "|             | other             | medo         |\n",
    "| test, treatment        | results | tr           |\n",
    "| header      |                   | head         |\n",
    "| unknown     |                   | unk          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd()+\"/../..\")\n",
    "from src import paths\n",
    "import polars as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "def load_line_labelling():\n",
    "    \"\"\"Loading the data from the nested csv files in the different \"imported_time\" directories. Labelled reports have a \"rev.csv\" ending.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pl.DataFrame(\n",
    "    \n",
    "    )\n",
    "\n",
    "    for root, dirs, files in os.walk(paths.DATA_PATH_LABELLED):\n",
    "        for file in files:\n",
    "            # Get the research id from filename\n",
    "            rid = file.split(\"_\")[0]\n",
    "            \n",
    "            if (file.endswith(\"rev.csv\") and \"mri\" not in file):\n",
    "                # Create a dataframe from the csv file\n",
    "                _df = pl.read_csv(os.path.join(root, file))\n",
    "                \n",
    "                # Add the rid to the dataframe\n",
    "                _df = _df.select(\n",
    "                    pl.col(\"text\").alias(\"text\"),\n",
    "                    pl.col(\"class\").alias(\"class\"),\n",
    "                    pl.lit(rid).alias(\"rid\"),\n",
    "                )\n",
    "                # Append the dataframe to the main dataframe\n",
    "                try: \n",
    "                    df = df.vstack(_df)\n",
    "                except:\n",
    "                    print(\"Error with file: \", file)\n",
    "                    print(\"df head: \", df.head(5))\n",
    "                    print(\"_df head: \", _df.head(5))\n",
    "                    continue\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line_text(df: pl.DataFrame):\n",
    "    \"\"\"Cleans the dataframe from the load_line_labelling function. \n",
    "    Text is cleaned by:\n",
    "    1) Removes whitespace from beginning and end of text\n",
    "    2) removes double spaces,\n",
    "    3) remove empty lines and lines starting with \"·\" or \"··\".\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): Input dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"text\").map_elements(lambda s: s.strip())\n",
    "        .map_elements(lambda s: s.replace(\"  \", \" \"))\n",
    "        .map_elements(lambda s: s.replace(\"·\", \"\"))\n",
    "        .map_elements(lambda s: s.replace(\"··\", \"\"))\n",
    "        ).filter(pl.col(\"text\").is_not_null())\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_line_class(df: pl.DataFrame):\n",
    "    \"\"\"Cleans the dataframe labels in \"class\".\n",
    "    1) Removes whitespace from beginning and end of text\n",
    "    2) Correct spelling mistakes\n",
    "    3) Exclude classes that are not part of the original approach\n",
    "    4) Create a new column \"class_agg\" with the aggregated classes of the original approach.\n",
    "    5) OneHotEncode the \"class_agg\" column\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): Input dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Class mapping spelling mistakes\n",
    "    class_mapping_spelling = {\n",
    "        'memds': 'medms',\n",
    "    }\n",
    "\n",
    "    # Classes of original approach abbreviation\n",
    "    classes_orig = [\"dm\", \"do\", \"cu\", \"his\", \"sym\", \"so\", \"mr\", \"labr\", \"labo\", \"medms\", \"medo\", \"tr\", \"head\", \"unk\"]\n",
    "\n",
    "    \n",
    "    \n",
    "    # Class mapping of original approach\n",
    "    class_mapping_agg = {\n",
    "        'his': 'his_sym_cu',\n",
    "        'sym': 'his_sym_cu',\n",
    "        'cu': 'his_sym_cu',\n",
    "        'labr': 'labr_labo',\n",
    "        'labo': 'labr_labo',\n",
    "        'to': 'to_tr',\n",
    "        'tr': 'to_tr',\n",
    "        'medo': 'medo_unk_do_so',\n",
    "        'unk': 'medo_unk_do_so',\n",
    "        'do': 'medo_unk_do_so',\n",
    "        'so': 'medo_unk_do_so',\n",
    "    }\n",
    "\n",
    "    # Cleaning the class column\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"class\").map_elements(lambda s: s.strip())\n",
    "        .map_elements(lambda s: class_mapping_spelling.get(s, s))\n",
    "        .map_elements(lambda s: s if s in classes_orig else None)\n",
    "    )\n",
    "\n",
    "\n",
    "    # Creating a new column with the aggregated classes\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"class\").map_elements(lambda s: class_mapping_agg.get(s, s))\n",
    "        .alias(\"class_agg\"),\n",
    "    )\n",
    "\n",
    "    enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    class_agg_ohe = enc.fit_transform(df[\"class_agg\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "    df = df.with_columns(\n",
    "        pl.lit(class_agg_ohe).alias(\"class_agg_ohe\"),\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_line_df(df: pl.DataFrame):\n",
    "    \"\"\"Cleans the dataframe from the load_line_labelling function. \n",
    "    Removes whitespaces, double spaces, empty lines and lines starting with \"·\" or \"··\". Corrects spelling mistakes in labells\n",
    "    and excludes classes that are not part of the original approach. Creates a new column \"class_agg\" with the aggregated classes\n",
    "    of the original approach.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): Input dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df = clean_line_text(df)\n",
    "    df = clean_line_class(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and cleaning\n",
    "df = load_line_labelling()\n",
    "df = clean_line_df(df)\n",
    "\n",
    "# Reorder rid to first column\n",
    "#df = df[[\"rid\", \"text\", \"class\", \"class_agg\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "display(df.head(5))\n",
    "\n",
    "# Save the dataframe\n",
    "df.write_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line_labelling_clean.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in train, validation and test\n",
    "train_val_texts, test_texts, train_val_labels, test_labels = train_test_split(df['text'], df['class_agg'], test_size=0.2, random_state=42, shuffle=True)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_val_texts, train_val_labels, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create huggingface dataset\n",
    "train_dataset = Dataset.from_dict({\"text\": train_texts, \"label\": train_labels})\n",
    "val_dataset = Dataset.from_dict({\"text\": val_texts, \"label\": val_labels})\n",
    "test_dataset = Dataset.from_dict({\"text\": test_texts, \"label\": test_labels})\n",
    "\n",
    "# Concatenate into one dataset\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "# Save the dataset\n",
    "dataset.save_to_disk(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line_labelling_clean_dataset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = DatasetDict.load_from_disk(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line_labelling_clean_dataset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][\"label\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf-extr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
