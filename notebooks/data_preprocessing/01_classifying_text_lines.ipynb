{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying text lines\n",
    "\n",
    "This notebook is used to create the dataset to train and evaluate the line classifier of the project. Be sure to run:\n",
    "\n",
    "1. notebooks/00_preprocessing_old_project\n",
    "\n",
    "first.\n",
    "\n",
    "A classifier is trained to classify single text lines of a report. For example, the lines can be classified as containing a diagnosis (`\"dm\"`) or history (`his`) of a patient. This task was used as a preprocessing step to later steps of structured information extraction. So that only lines classified as containing a diagnosis will be fed to a downstream classifier, extracting the exact diagnosis. This step might be unnecessary with modern transformers that can handle longer text inputs. But it could still help by only feeding relevant input. Even more important old approach only trained and evaluated classifier 2 (MS-Diag) on reports containing \"dm\", which gives a more accurate idea of the whole pipeline.\n",
    "\n",
    "The files containing the necessary information are inside the `data/raw/labelling` directory. It contains manually labelled reports from different sessions.\n",
    "\n",
    "The original classes per label are:\n",
    "\n",
    "| category    | subcategory       | abbreviation |\n",
    "|-------------|-------------------|--------------|\n",
    "| diagnosis   | MS diagnosis      | dm           |\n",
    "|             | other             | do           |\n",
    "| current state     |              | cu           |\n",
    "| history     |                   | his          |\n",
    "| symptoms    | MS related        | sym          |\n",
    "|             | other             | so           |\n",
    "| MRI | results                  | mr           |\n",
    "| lab | results                  | labr         |\n",
    "|             | other             | labo         |\n",
    "| medication  | MS related        | medms        |\n",
    "|             | other             | medo         |\n",
    "| test, treatment        | results | tr           |\n",
    "| header      |                   | head         |\n",
    "| unknown     |                   | unk          |\n",
    "\n",
    "I will group the classes according to the original approach, and drop observations with no text or label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd()+\"/../..\")\n",
    "\n",
    "from src import paths\n",
    "from src.utils import line_label_label2id, prepare_pd_dataset_for_lineclass\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import Dataset, DatasetDict, concatenate_datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Level Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_line_labelling():\n",
    "    \"\"\"Loading the data from the nested csv files in the different \"imported_time\" directories. Labelled reports have a \"rev.csv\" ending\n",
    "    and are in a \"_Marc\" subdirectory. There should only be one entry per rid, that is labelled. Duplicates will be removed.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with columns: \"text\", \"class\", \"rid\"\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    rid_list = []\n",
    "\n",
    "    for root, dirs, files in os.walk(paths.DATA_PATH_LABELLED):\n",
    "        if \"Marc\" not in root:\n",
    "            continue\n",
    "        for file in files:\n",
    "\n",
    "            # Get the research id from filename\n",
    "            rid = file.split(\"_\")[0]\n",
    "            \n",
    "            # Check if the file is a labelled report (and not mri) and if the rid is already in the list\n",
    "            if (file.endswith(\"rev.csv\") and \"mri\" not in file and rid not in rid_list):\n",
    "                \n",
    "                # Append rid to rid list to keep track of which files have been added\n",
    "                rid_list.append(rid)\n",
    "\n",
    "                # Create a dataframe from the csv file\n",
    "                _df = pd.read_csv(os.path.join(root, file))\n",
    "                \n",
    "                # Add the rid to the dataframe\n",
    "                _df = _df.rename(columns={\"text\": \"text\", \"class\": \"class\"})\n",
    "                _df['rid'] = rid\n",
    "                _df['index_within_rid'] = _df.index\n",
    "                \n",
    "                # Append the dataframe to the main dataframe\n",
    "                try: \n",
    "                    df_list.append(_df)\n",
    "                except:\n",
    "                    print(\"Error with file: \", file)\n",
    "                    print(\"df head: \", _df.head(5))\n",
    "                    print(\"_df head: \", _df.head(5))\n",
    "                    continue\n",
    "    print(\"Number of reports: \", len(df_list))\n",
    "    return pd.concat(df_list)[[\"text\", \"class\", \"rid\", \"index_within_rid\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line_text(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    For Transformer to work, there has to be text in the text column. If there is no text, the text column is removed.\n",
    "    \"\"\"\n",
    "    df = df.dropna(subset=[\"text\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_line_class(df: pd.DataFrame):\n",
    "    \"\"\"Cleans the dataframe labels in \"class\".\n",
    "    1) Removes whitespace from beginning and end of text\n",
    "    2) Correct spelling mistakes\n",
    "    3) Fill NaN values with \"unk\"\n",
    "    4) Create a new column \"class_agg\" with the aggregated classes of the original approach.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Class mapping spelling mistakes\n",
    "    class_mapping_spelling = {\n",
    "        'memds': 'medms',\n",
    "        'hs': 'his',\n",
    "        'm': 'mr',\n",
    "    }\n",
    "    class_mapping_agg = {\n",
    "        'his': 'his_sym_cu',\n",
    "        'sym': 'his_sym_cu',\n",
    "        'cu': 'his_sym_cu',\n",
    "        'labr': 'labr_labo',\n",
    "        'labo': 'labr_labo',\n",
    "        'to': 'to_tr',\n",
    "        'tr': 'to_tr',\n",
    "        'medo': 'medo_unk_do_so',\n",
    "        'unk': 'medo_unk_do_so',\n",
    "        'do': 'medo_unk_do_so',\n",
    "        'so': 'medo_unk_do_so',\n",
    "    }\n",
    "\n",
    "    # Cleaning the class column\n",
    "    df['class'] = df['class'].str.strip() \\\n",
    "                             .replace(class_mapping_spelling) \\\n",
    "                             .fillna(\"unk\") \n",
    "\n",
    "    # Creating a new column with the aggregated classes\n",
    "    df['class_agg'] = df['class'].replace(class_mapping_agg)\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_clean_line_df():\n",
    "    \"\"\"Loads and cleans the dataframe from the load_line_labelling function.\n",
    "    \"\"\"\n",
    "    df = load_line_labelling()\n",
    "    df = clean_line_text(df)\n",
    "    df = clean_line_class(df)\n",
    "    print(df.columns)\n",
    "\n",
    "    return df[[\"rid\", \"index_within_rid\",\"text\", \"class\", \"class_agg\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reports:  74\n",
      "Index(['text', 'class', 'rid', 'index_within_rid', 'class_agg'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>index_within_rid</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>class_agg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41</td>\n",
       "      <td>0</td>\n",
       "      <td>Schubförmige Multiple Sklerose (RRMS), (ES/ED ...</td>\n",
       "      <td>dm</td>\n",
       "      <td>dm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41</td>\n",
       "      <td>1</td>\n",
       "      <td>Klinisch:- residuell: spastisches Gangbild rec...</td>\n",
       "      <td>sym</td>\n",
       "      <td>his_sym_cu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41</td>\n",
       "      <td>2</td>\n",
       "      <td>Verlauf: - 05/1999- 08/2011 rezidivierende Sch...</td>\n",
       "      <td>his</td>\n",
       "      <td>his_sym_cu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41</td>\n",
       "      <td>3</td>\n",
       "      <td>Diagnostisch:</td>\n",
       "      <td>head</td>\n",
       "      <td>head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41</td>\n",
       "      <td>4</td>\n",
       "      <td>INDENT - 1998 Liquor: oligoklonale Banden posi...</td>\n",
       "      <td>labr</td>\n",
       "      <td>labr_labo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    rid  index_within_rid  \\\n",
       "0  3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41                 0   \n",
       "1  3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41                 1   \n",
       "2  3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41                 2   \n",
       "3  3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41                 3   \n",
       "4  3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41                 4   \n",
       "\n",
       "                                                text class   class_agg  \n",
       "0  Schubförmige Multiple Sklerose (RRMS), (ES/ED ...    dm          dm  \n",
       "1  Klinisch:- residuell: spastisches Gangbild rec...   sym  his_sym_cu  \n",
       "2  Verlauf: - 05/1999- 08/2011 rezidivierende Sch...   his  his_sym_cu  \n",
       "3                                      Diagnostisch:  head        head  \n",
       "4  INDENT - 1998 Liquor: oligoklonale Banden posi...  labr   labr_labo  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_agg values:  class_agg\n",
      "his_sym_cu        312\n",
      "mr                270\n",
      "head              236\n",
      "medms             213\n",
      "labr_labo         184\n",
      "medo_unk_do_so    139\n",
      "to_tr             114\n",
      "dm                 74\n",
      "Name: count, dtype: int64\n",
      "class values:  class\n",
      "mr       270\n",
      "head     236\n",
      "medms    213\n",
      "his      210\n",
      "labr     166\n",
      "tr        77\n",
      "dm        74\n",
      "sym       61\n",
      "unk       50\n",
      "do        42\n",
      "cu        41\n",
      "to        37\n",
      "medo      35\n",
      "labo      18\n",
      "so        12\n",
      "Name: count, dtype: int64\n",
      "Number of reports with missing values in class_agg:  0\n"
     ]
    }
   ],
   "source": [
    "df = load_clean_line_df()\n",
    "display(df.head(5))\n",
    "\n",
    "# Class distribution\n",
    "print(\"class_agg values: \", df.class_agg.value_counts())\n",
    "print(\"class values: \", df[\"class\"].value_counts())\n",
    "\n",
    "# Number of reports with missing values in class_agg\n",
    "print(\"Number of reports with missing values in class_agg: \", df[df[\"class_agg\"].isnull()].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schubförmige Multiple Sklerose (RRMS), (ES/ED 1998), EDSS 4.0 dm\n",
      "Klinisch:- residuell: spastisches Gangbild rechtsbetont sym\n",
      "Verlauf: - 05/1999- 08/2011 rezidivierende Schübe  his\n",
      "Diagnostisch: head\n",
      "INDENT - 1998 Liquor: oligoklonale Banden positiv  labr\n",
      "INDENT - 04/2012 NPSY: normgerecht; leichte mentale Ermüdbarkeit tr\n",
      "INDENT - 02/2015 cMRI (extern): stationärer Befund. mr\n",
      "INDENT - OCTiMS-Studie medo\n",
      "INDENT - 03/2002 - 12/2003 Rebif 3x44ug/Woche s.c. medms\n",
      "INDENT Klinisch aktuell: Spastisch-ataktische Gangstörung bei linksbetonter Tetraspastik, sensiblem Querschnittssyndrom sub Th5, neurogene Blasenstörung cu\n",
      "INDENT Reha in Valens 2005, 2006 gute Erfolge unk\n",
      "INDENT 10/2009 stationäre Neurorehabilitation in Valens to\n",
      "Abdominelle Beschwerden und Stuhlinkontinenz seit ca. 2016 do\n",
      "INDENT - nur an Fusssohlen, geringe Krankheitsaktivität  so\n",
      "INDENT Immunologie-Screening Serum: ausstehend labo\n"
     ]
    }
   ],
   "source": [
    "# Examples\n",
    "for cls in df[\"class\"].unique():\n",
    "    example = df[df[\"class\"] == cls].iloc[0]\n",
    "    print(example[\"text\"], cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory\n",
    "os.makedirs(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line-label\"), exist_ok=True)\n",
    "# Save the dataframe\n",
    "df.to_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line-label/line-label_clean.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train test split by rid\n",
    "rids = df.rid.unique()\n",
    "rids_train, rids_test = train_test_split(rids, test_size=0.2, random_state=42)\n",
    "rids_train, rids_val = train_test_split(rids_train, test_size=0.2, random_state=42)\n",
    "\n",
    "df_train = df[df.rid.isin(rids_train)]\n",
    "df_val = df[df.rid.isin(rids_val)]\n",
    "df_test = df[df.rid.isin(rids_test)]\n",
    "\n",
    "# Save the train, val and test dataframes\n",
    "df_train.to_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line-label/line-label_clean_train.csv\"))\n",
    "\n",
    "df_val.to_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line-label/line-label_clean_val.csv\"))\n",
    "\n",
    "df_test.to_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line-label/line-label_clean_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all of the data for dataset clf2 construction\n",
    "df_all = pd.read_csv(paths.DATA_PATH_PREPROCESSED/\"midatams/seantis_kisim.csv\")\n",
    "df_all = df_all[[\"research_id\", \"index_within_rid\",\"text\"]].rename(columns={\"research_id\": \"rid\"})\n",
    "df_all[\"class_agg\"] = None\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HuggingFace Dataset\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train),\n",
    "    \"val\": Dataset.from_pandas(df_val),\n",
    "    \"test\": Dataset.from_pandas(df_test),\n",
    "})\n",
    "\n",
    "# Drop unnecessary columns\n",
    "dataset = dataset.remove_columns([\"class\", \"__index_level_0__\"])\n",
    "\n",
    "# Add the all dataset\n",
    "dataset[\"all\"] = Dataset.from_pandas(df_all)\n",
    "\n",
    "# Create labels \n",
    "dataset = dataset.map(lambda example: {\"labels\":[line_label_label2id.get(e, None) for e in example[\"class_agg\"]]}, batched=True)\n",
    "\n",
    "# Save the dataset\n",
    "dataset.save_to_disk(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line-label/line-label_clean_dataset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of reports\n",
    "print(\"Number of reports: \", len(df[\"rid\"].unique()))\n",
    "\n",
    "# Number of lines\n",
    "print(\"Number of lines: \", df.shape[0])\n",
    "\n",
    "# Value counts of class_agg\n",
    "print(\"Value counts of class: \", df[\"class\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Level Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a preprocessing step to label all the observations in seantis_kisim.csv, the dataset containing the reports in line splitted format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset needs columns rid, text, class_agg. The text column contains one line of a report per row. \n",
    "# The class_agg column can have all Null values, it will be filled by the lineclass model.\n",
    "\n",
    "df_all = pd.read_csv(paths.DATA_PATH_PREPROCESSED/\"midatams/seantis_kisim.csv\")\n",
    "df_all = df_all[[\"research_id\", \"text\"]].rename(columns={\"research_id\": \"rid\"})\n",
    "df_all[\"class_agg\"] = None\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(paths.DATA_PATH_PREPROCESSED/\"line-label/line-label_clean_train.csv\")\n",
    "df_val = pd.read_csv(paths.DATA_PATH_PREPROCESSED/\"line-label/line-label_clean_val.csv\")\n",
    "df_test = pd.read_csv(paths.DATA_PATH_PREPROCESSED/\"line-label/line-label_clean_test.csv\")\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train),\n",
    "    \"val\": Dataset.from_pandas(df_val),\n",
    "    \"test\": Dataset.from_pandas(df_test),\n",
    "    \"all\": Dataset.from_pandas(df_all)\n",
    "})\n",
    "\n",
    "df_token_train = prepare_pd_dataset_for_lineclass(df_train)\n",
    "df_token_val = prepare_pd_dataset_for_lineclass(df_val)\n",
    "df_token_test = prepare_pd_dataset_for_lineclass(df_test)\n",
    "df_token_all = prepare_pd_dataset_for_lineclass(df_all)\n",
    "\n",
    "dataset_token = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_token_train),\n",
    "    \"val\": Dataset.from_pandas(df_token_val),\n",
    "    \"test\": Dataset.from_pandas(df_token_test),\n",
    "    \"all\": Dataset.from_pandas(df_token_all)\n",
    "})\n",
    "\n",
    "# Add a few of the validation examples to the training set\n",
    "dataset_token[\"train\"] = concatenate_datasets([dataset_token[\"train\"], dataset_token[\"val\"].select(range(8))])\n",
    "dataset_token[\"val\"] = dataset_token[\"val\"].select(range(8, len(dataset_token[\"val\"])))\n",
    "\n",
    "# Save the tokenized datasets\n",
    "dataset_token.save_to_disk(paths.DATA_PATH_PREPROCESSED/\"line-label/line-label_for_token_classification\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
