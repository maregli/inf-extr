{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medication Extraction\n",
    "\n",
    "This notebook is intended as an example of extracting medications and their attributes from text.\n",
    "You can specify your own dataset (must contain text), sampler, schema, model, prompting strategy and templates or use the default ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd()+\"/../..\")\n",
    "from src import paths\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from src import paths\n",
    "from src.utils import (load_model_and_tokenizer,   \n",
    "                       check_gpu_memory,\n",
    "                       get_format_fun,\n",
    "                        information_retrieval, \n",
    "                        get_sampler,\n",
    "                        get_outlines_generator,\n",
    "                        get_pydantic_schema,\n",
    "                        format_prompt,\n",
    "                        outlines_medication_prompting,\n",
    ")\n",
    "\n",
    "import argparse\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "import json\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Llama2-MedTuned-13b\"\n",
    "QUANTIZATION = \"4bit\"\n",
    "PROMPT_STRATEGY = \"few_shot_instruction\"\n",
    "SAMPLER_NAME = \"greedy\"\n",
    "ATTN_IMPLEMENTATION = \"flash_attention_2\" # Only enable this if your GPU is able to use flash_attention_2, check https://github.com/Dao-AILab/flash-attention\n",
    "MAX_TOKENS = 500\n",
    "NUM_EXAMPLES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU Memory, for 13B model should have at least 16GB of VRAM (12 could work for short examples)\n",
    "check_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model and Tokenizer\n",
    "model, tokenizer = load_model_and_tokenizer(model_name = MODEL_NAME,\n",
    "                                            task_type = \"outlines\",\n",
    "                                            quantization = QUANTIZATION,\n",
    "                                            attn_implementation = ATTN_IMPLEMENTATION,\n",
    "                                            )\n",
    "check_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output schema (you can implement your own, must follow pydantic BaseModel, or check https://github.com/outlines-dev/outlines\n",
    "schema = get_pydantic_schema(schema_name=\"medication\")\n",
    "\n",
    "# Example of what this looks like\n",
    "get_default_pydantic_model(\"medication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sampler (could also be \"multionmial\" or \"beam\")\n",
    "sampler = get_sampler(SAMPLER_NAME)\n",
    "\n",
    "# Get Generator (for task with JSON output according to schema)\n",
    "generator = get_outlines_generator(model, sampler, task = \"json\", schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "df = Dataset.load_from_disk(paths.DATA_PATH_PREPROCESSED/\"medication/kisim_medication_sample\")\n",
    "text = df[\"text\"][1] # Sample of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your task instruction, system prompt and examples or load default ones\n",
    "with open(paths.DATA_PATH_PREPROCESSED/\"medication/task_instruction.txt\", \"r\") as f:\n",
    "    task_instruction = f.read()\n",
    "\n",
    "with open(paths.DATA_PATH_PREPROCESSED/\"medication/system_prompt.txt\", \"r\") as f:\n",
    "    system_prompt = f.read()\n",
    "\n",
    "with open(paths.DATA_PATH_PREPROCESSED/\"medication/examples.json\", \"r\") as file:\n",
    "    examples = json.load(file)                  \n",
    "\n",
    "# Can also select a subset of examples at random\n",
    "random.seed(42)\n",
    "examples = random.sample(examples, NUM_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a prompting template and format input\n",
    "format_fun = get_format_fun(prompting_strategy=PROMPT_STRATEGY)\n",
    "input = format_prompt(text = text, format_fun=format_fun, task_instruction = task_instruction, system_prompt = system_prompt, examples = examples)\n",
    "\n",
    "# If you don't want to use any of the templates and formatting you can also use the tokenizer to prepare an input:\n",
    "# input = tokenizer([\"This is a test\"], return_tensors = \"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results (note you can also use DataLoaders to submit\n",
    "result = generator(input, max_tokens = MAX_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively you can stream the input and observe the progress\n",
    "for token in generator.stream(input, max_tokens = MAX_TOKENS):\n",
    "    print(token, end = \"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
