{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import DatasetDict\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import torchmetrics\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd()+\"/../..\")\n",
    "from src import paths\n",
    "from src.utils import plot_embeddings\n",
    "from huggingface_hub import notebook_login\n",
    "import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to Hugging Face Hub as model is gated\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = DatasetDict.load_from_disk(paths.DATA_PATH_PREPROCESSED/'line_labelling_clean_dataset')\n",
    "\n",
    "# Num Labels\n",
    "num_labels = len(set(dataset['train']['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint = \"GerMedBERT/medbert-512\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "# Load model for embedding\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=num_labels, problem_type=\"multi_label_classification\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out None labels\n",
    "# train_dataset = train_dataset.filter(lambda example: example['label'] is not None)\n",
    "# val_dataset = val_dataset.filter(lambda example: example['label'] is not None)\n",
    "# test_dataset = test_dataset.filter(lambda example: example['label'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset\n",
    "class MedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe: DatasetDict, tokenizer, max_length: int = 512, split: str = 'train'):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False).fit(np.stack(self.dataframe['train']['label']).reshape(-1, 1))\n",
    "        self.labels = self.enc.transform(np.stack(self.dataframe[split]['label']).reshape(-1, 1))\n",
    "        self.encodings = self.tokenizer(self.dataframe[split]['text'], truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: (val[idx].clone().detach()) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Datasets\n",
    "train_dataset = MedDataset(dataset, tokenizer, split='train')\n",
    "val_dataset = MedDataset(dataset, tokenizer, split='validation')\n",
    "test_dataset = MedDataset(dataset, tokenizer, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch Implementation\n",
    "\n",
    "# # Set only specific layers to be trainable\n",
    "# for param in model.base_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Set only specific layers to be trainable\n",
    "# for param in model.classifier.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# Dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Loss\n",
    "def loss_fn(logits, targets):\n",
    "    loss = (torch.nn.CrossEntropyLoss()(logits, targets) + \n",
    "            torchmetrics.classification.MulticlassF1Score(num_classes=num_labels, average='weighted').to(device)(logits, targets))\n",
    "    return loss\n",
    "\n",
    "# GPU Memory optimization\n",
    "model.gradient_checkpointing_enable()\n",
    "accelerator = Accelerator(fp16=True)\n",
    "model, optimizer, train_loader, val_loader, test_loader = accelerator.prepare(model, optimizer, train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "epochs = 36\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    pbar = tqdm.tqdm(train_loader)\n",
    "    for i, batch in enumerate(pbar):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Logging Progress\n",
    "        if i % 10 == 0:\n",
    "            pbar.set_description(f\"Epoch {epoch} training loss: {loss.item()}\")\n",
    "    \n",
    "    # Evaluate on Validation\n",
    "    val_CE_loss = []\n",
    "    val_f1 = []\n",
    "\n",
    "    pbar = tqdm.tqdm(val_loader)\n",
    "    pbar.set_description(f\"Epoch {epoch} Validation\")\n",
    "    for batch in pbar:\n",
    "        with torch.no_grad():\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        val_CE_loss.append(torch.nn.CrossEntropyLoss()(outputs.logits, labels).item())\n",
    "        val_f1.append(torchmetrics.classification.MulticlassF1Score(num_classes=num_labels, average='weighted').to(device)(outputs.logits, labels).item())\n",
    "    \n",
    "    print(f\"Epoch {epoch} CrossEntropy Val loss: {np.mean(val_CE_loss)}\")\n",
    "    print(f\"Epoch {epoch} F1 Val score: {np.mean(val_f1)}\")\n",
    "    \n",
    "    # # Saving Model    \n",
    "    # if epoch % 10 == 0:\n",
    "    #     torch.save(model.state_dict(), paths.MODEL_PATH/f\"line-label_medBERT-finetuned_{epoch}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free GPU Memory\n",
    "torch.cuda.empty_cache()\n",
    "del input_ids\n",
    "del attention_mask\n",
    "del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths.MODEL_PATH/f\"line-label_medBERT-finetuned_{epoch}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm.tqdm(test_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs.append(model(input_ids, attention_mask=attention_mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "preds = [np.argmax(output.logits.cpu().numpy(), axis=1) for output in outputs]\n",
    "preds = np.concatenate(preds)\n",
    "\n",
    "# Get true labels\n",
    "true = np.argmax(test_labels_enc, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = np.sum(preds == true) / len(true)\n",
    "\n",
    "# F1 Score\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(true, preds, average='weighted')\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=4,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=200,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    save_strategy='epoch',\n",
    "    evaluation_strategy='epoch',\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset            # evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting pooling and head to trainable\n",
    "for name, param in trainer.model.named_parameters():\n",
    "    if \"pooler\" in name or \"classifier\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "trainer.save_model(os.path.join(paths.MODEL_PATH, \"medbert-diag-label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "labels = np.argmax(predictions.label_ids, axis=1)\n",
    "\n",
    "print(f\"Accuracy: {np.sum(preds == labels) / len(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score, precision, recall\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "print(f\"F1 Score: {f1_score(labels, preds, average='macro')}\")\n",
    "print(f\"Precision: {precision_score(labels, preds, average='macro')}\")\n",
    "print(f\"Recall: {recall_score(labels, preds, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.categories_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_predictions(labels, preds, display_labels=enc.categories_[0], xticks_rotation=90)\n",
    "# Plot the confusion matrix with rotated x-axis labels\n",
    "# fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# disp.plot(ax=ax, xticks_rotation=45)  # Adjust the rotation angle as needed\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pooled embeddings\n",
    "embeddings = []\n",
    "batch_size = 16\n",
    "\n",
    "for i in tqdm.tqdm(range(0, len(df), batch_size)):\n",
    "    tokens = tokenizer(df['text'][i:i+batch_size].to_list(), padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    attention_mask = tokens[\"attention_mask\"][i:i+batch_size]\n",
    "    with torch.no_grad():\n",
    "        embeddings.append(trainer.model(**tokens, output_hidden_states=True).hidden_states[-1].cpu())\n",
    "    del tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings\n",
    "torch.save(embeddings, os.path.join(paths.DATA_PATH_PREPROCESSED, \"embeddings-fine-tuned.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "embeddings = torch.load(os.path.join(paths.DATA_PATH_PREPROCESSED, \"embeddings-fine-tuned.pt\"))\n",
    "\n",
    "# Mean over sequence\n",
    "embeddings_mean = [torch.mean(embedding, dim=1) for embedding in embeddings]\n",
    "embeddings_mean = torch.cat(embeddings_mean, dim=0)\n",
    "\n",
    "# Plot Mean Embeddings\n",
    "plot_embeddings(embeddings_mean, df[\"class_agg\"], title=\"Mean Embeddings\", method=\"pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings(embeddings_mean, df[\"class_agg\"], title=\"Mean Embeddings\", method=\"umap\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf-extr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
