{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38412455-78c3-4c9c-8c5d-e40fcfcf948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd()+\"/../..\")\n",
    "from src import paths\n",
    "\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils import plot_embeddings, pretty_confusion_matrix, ms_label2id, ms_id2label\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6a0741",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_results(file_name: str, plot_hidden_states = True, plot_title:str=None) -> None:\n",
    "    results = torch.load(paths.RESULTS_PATH / \"ms-diag\" / f\"{file_name}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    display_label_mapping = {0: \"PPMS\", 1: \"RRMS\", 2: \"SPMS\", 3: \"Other\"}\n",
    "    pretty_confusion_matrix(y_true=results[\"labels\"], y_pred=results[\"preds\"], label_dict=display_label_mapping, title= plot_title)\n",
    "\n",
    "    # Plot embeddings\n",
    "    if plot_hidden_states:\n",
    "        # Exclude None values (for pipeline approach this is to be expected)\n",
    "        results[\"last_hidden_state\"] = [batch for batch in results[\"last_hidden_state\"] if batch is not None]\n",
    "        plot_labels = [results[\"labels\"][i] for i in range(len(results[\"last_hidden_state\"])) if results[\"last_hidden_state\"][i] is not None]\n",
    "        # plot_labels = [display_label_mapping[label] for label in plot_labels]\n",
    "        \n",
    "        # Last hidden states is a list of tensors of shape (seq_len, hidden_size)\n",
    "        last_hidden_state = [batch[0, :] for batch in results[\"last_hidden_state\"]]  # Use CLS token\n",
    "        embeddings = torch.stack(last_hidden_state, dim=0).to(torch.float16)\n",
    "        plot_embeddings(embeddings=embeddings, labels=plot_labels, title=plot_title, method=\"umap\", display_label_mapping=display_label_mapping)\n",
    "        plt.show()\n",
    "\n",
    "    # Print classification report\n",
    "    labels = [display_label_mapping[label] for label in results[\"labels\"]]\n",
    "    preds = [display_label_mapping[pred] for pred in results[\"preds\"]]\n",
    "    print(classification_report(y_true=labels, y_pred=preds), \"\\n\\n\")\n",
    "\n",
    "    # Show all wrongly classified samples\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] != preds[i]:\n",
    "            print(f\"Observation: {i}\")\n",
    "            print(f\"Label: {labels[i]} - Prediction: {preds[i]}\")\n",
    "            try:\n",
    "                print(results[\"text\"][i])\n",
    "            except:\n",
    "                print(results[\"original_text\"][i])\n",
    "            # Print the probabilities for each class by converting the logits to probabilities, then rounding them\n",
    "            print(\"Probabilities:\", dict(zip(ms_label2id.keys(), [round(prob, 3) for prob in torch.softmax(torch.tensor(results[\"logits\"][i]), dim=0).numpy()])), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0e5062",
   "metadata": {},
   "source": [
    "# MedBERT 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077f1440",
   "metadata": {},
   "source": [
    "## Strategy: Classify on single lines, 4 Labels (including no MS) and oversampling for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09edb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(\"ms-diag_medbert-512_class_line_oversample_test.pt\", plot_title=\"MedBERT Classification Line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd652e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.load(paths.RESULTS_PATH / \"ms-diag\" / \"ms-diag_medbert-512_class_line_oversample_test.pt\")\n",
    "# Creat DF from rid, pred, label, text\n",
    "def majority_vote(result):\n",
    "    # Create a DataFrame from the results\n",
    "    df = pd.DataFrame({\"rid\": result[\"rid\"], \"preds\": result[\"preds\"], \n",
    "                   \"labels\": result[\"labels\"], \"text\": result[\"text\"], \n",
    "                   \"logits\": result[\"logits\"], \"last_hidden_state\": result[\"last_hidden_state\"],\n",
    "                   \"index_within_rid\": result[\"index_within_rid\"]})\n",
    "    \n",
    "    # All rids that have at least one prediction other than 3 (no MS)\n",
    "    df_list = []\n",
    "\n",
    "    for i, rid_data in df.groupby(\"rid\"):\n",
    "        # Get most frequent prediction from classes [0, 1, 2]\n",
    "        # Take first of the lines predicted as this class\n",
    "        _df = {}\n",
    "\n",
    "        value_counts = rid_data[\"preds\"].value_counts()\n",
    "\n",
    "        if len(value_counts) == 1 or value_counts.index[0] != 3:\n",
    "            majority_class = value_counts.index[0]\n",
    "            _df[\"preds\"] = majority_class\n",
    "            _df[\"logits\"] = rid_data[rid_data[\"preds\"] == majority_class][\"logits\"].values[0]\n",
    "            _df[\"last_hidden_state\"] = rid_data[rid_data[\"preds\"] == majority_class][\"last_hidden_state\"].values[0]\n",
    "\n",
    "        elif len(value_counts) > 1 and value_counts.index[0] == 3:\n",
    "            majority_class = value_counts.index[1]\n",
    "            _df[\"preds\"] = majority_class\n",
    "            _df[\"logits\"] = rid_data[rid_data[\"preds\"] == majority_class][\"logits\"].values[0]\n",
    "            _df[\"last_hidden_state\"] = rid_data[rid_data[\"preds\"] == majority_class][\"last_hidden_state\"].values[0]\n",
    "\n",
    "        # There should only be one kind label other than 3 (no MS) or just 3\n",
    "        if rid_data[\"labels\"].value_counts().index[0] == 3 and len(rid_data[\"labels\"].value_counts()) > 1:\n",
    "            _df[\"labels\"] = rid_data[\"labels\"].value_counts().index[1]\n",
    "        else:\n",
    "            _df[\"labels\"] = rid_data[\"labels\"].value_counts().index[0]\n",
    "        \n",
    "        _df[\"rid\"] = i\n",
    "        _df[\"text\"] = \"\\n\".join(rid_data[\"text\"].tolist())\n",
    "\n",
    "        df_list.append(_df)\n",
    "    \n",
    "    return pd.DataFrame(df_list)\n",
    "\n",
    "df_agg = majority_vote(result)\n",
    "torch.save(df_agg.to_dict(\"list\"), paths.RESULTS_PATH / \"ms-diag\" / \"ms-diag_medbert-512_class_line_oversample_test_agg.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6e13cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(\"ms-diag_medbert-512_class_line_oversample_test_agg.pt\", plot_hidden_states=True, plot_title=\"MedBERT Classification Line Aggregated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3020b1c0",
   "metadata": {},
   "source": [
    "The bad precision stems from the fact the we have an imbalanced dataset. Even though only 4 RRMS get classified wrong, it makes a huge difference for the precision of PPMS and SPMS as there are only so few examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90730e57",
   "metadata": {},
   "source": [
    "## Strategy: Classify on single lines, 3 Labels (original approach with only dm samples) and oversampling for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e54b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(\"ms-diag_medbert-512_class_line_original_approach_test.pt\", plot_title=\"MedBERT Classification Line Original Approach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f66565-b6df-4bbd-81e3-17bfd8bccf99",
   "metadata": {},
   "source": [
    "## Strategy: Classify on whole report, 4 labels (including no ms) training on oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5017d232-02b2-4ad7-a33b-4bfbf7dfbbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(\"ms-diag_medbert-512_class_all_oversample_test.pt\", plot_title=\"MedBERT Classification Whole Prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d6d9c-09d2-4918-944d-2e1df5bb79dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.utils\n",
    "importlib.reload(src.utils)\n",
    "from src.utils import pretty_confusion_matrix\n",
    "results = torch.load(paths.RESULTS_PATH / \"ms-diag\" / \"ms-diag_medbert-512_class_all_oversample_test.pt\")\n",
    "plot_title = \"MedBERT Classification Whole Prompt\"\n",
    "# Plot confusion matrix\n",
    "display_label_mapping = {0: \"PPMS\", 1: \"RRMS\", 2: \"SPMS\", 3: \"Other\"}\n",
    "pretty_confusion_matrix(y_true=results[\"labels\"], y_pred=results[\"preds\"], label_dict=display_label_mapping, save_dir = paths.THESIS_PATH/\"ms_diag_medbert_cm_base.png\")\n",
    "# Exclude None values (for pipeline approach this is to be expected)\n",
    "results[\"last_hidden_state\"] = [batch for batch in results[\"last_hidden_state\"] if batch is not None]\n",
    "plot_labels = [results[\"labels\"][i] for i in range(len(results[\"last_hidden_state\"])) if results[\"last_hidden_state\"][i] is not None]\n",
    "# plot_labels = [display_label_mapping[label] for label in plot_labels]\n",
    "\n",
    "# Last hidden states is a list of tensors of shape (seq_len, hidden_size)\n",
    "last_hidden_state = [batch[0, :] for batch in results[\"last_hidden_state\"]]  # Use CLS token\n",
    "embeddings = torch.stack(last_hidden_state, dim=0).to(torch.float16)\n",
    "plot_embeddings(embeddings=embeddings, labels=plot_labels, method=\"umap\", display_label_mapping=display_label_mapping, save_dir = paths.THESIS_PATH/\"ms_diag_medbert_embeddings_base.png\")\n",
    "\n",
    "# Print classification report\n",
    "labels = [display_label_mapping[label] for label in results[\"labels\"]]\n",
    "preds = [display_label_mapping[pred] for pred in results[\"preds\"]]\n",
    "pd.DataFrame(classification_report(y_true=labels, y_pred=preds, output_dict = True)).transpose().round(2).to_csv(\"ms-diag_medbert-512_class_all_oversample_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944449dd-17eb-40d2-9904-c4c5efc9ccf2",
   "metadata": {},
   "source": [
    "## Strategy: Classify on whole report, 3 Labels (original approach with only reports containing at least one dm line), oversampling for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11323a4e-6eeb-401e-b3c5-53faeab6e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(\"ms-diag_medbert-512_class_all_original_approach_test.pt\", plot_title=\"MedBERT Classification Whole Prompt Original Approach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5f8925",
   "metadata": {},
   "source": [
    "## Pipeline Approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e24c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(\"ms-diag_medbert-512_pipeline_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ab4102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label of obs 25 is wrong, should be Other\n",
    "results_corrected = torch.load(paths.RESULTS_PATH / \"ms-diag\" / \"ms-diag_medbert-512_pipeline_test.pt\")\n",
    "results_corrected[\"labels\"][25] = 3\n",
    "\n",
    "torch.save(results_corrected, paths.RESULTS_PATH / \"ms-diag\" / \"ms-diag_medbert-512_pipeline_test_corrected.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca405a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(\"ms-diag_medbert-512_pipeline_test_corrected.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e3984-a18f-4d53-afef-a67940b54bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.load(paths.RESULTS_PATH / \"ms-diag\" / \"ms-diag_medbert-512_pipeline_test_corrected.pt\")\n",
    "plot_title = \"MedBERT Classification S2A\"\n",
    "# Plot confusion matrix\n",
    "display_label_mapping = {0: \"PPMS\", 1: \"RRMS\", 2: \"SPMS\", 3: \"Other\"}\n",
    "pretty_confusion_matrix(y_true=results[\"labels\"], y_pred=results[\"preds\"], label_dict=display_label_mapping, save_dir = paths.THESIS_PATH/\"ms_diag_medbert_cm_s2a.png\")\n",
    "\n",
    "# Print classification report\n",
    "labels = [display_label_mapping[label] for label in results[\"labels\"]]\n",
    "preds = [display_label_mapping[pred] for pred in results[\"preds\"]]\n",
    "pd.DataFrame(classification_report(y_true=labels, y_pred=preds, output_dict = True)).transpose().round(2).to_csv(\"ms-diag_medbert-512_pipeline_test_corrected.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3fbdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additionally to compare to old approach remove other labels\n",
    "other_idx = [i for i, label in enumerate(results_corrected[\"labels\"]) if label == 3]\n",
    "\n",
    "results_corrected_no = {}\n",
    "for key in results_corrected.keys():\n",
    "    results_corrected_no[key] = [value for i, value in enumerate(results_corrected[key]) if i not in other_idx]\n",
    "\n",
    "torch.save(results_corrected_no, paths.RESULTS_PATH / \"ms-diag\" / \"ms-diag_medbert-512_pipeline_test_corrected_no_other.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6396cfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For thesis plot of Pipeline approach (no other class for downstream classifier)\n",
    "from umap import UMAP\n",
    "import seaborn as sns\n",
    "\n",
    "results = torch.load(paths.RESULTS_PATH / \"ms-diag\" / \"ms-diag_medbert-512_pipeline_test_corrected_no_other.pt\")\n",
    "\n",
    "# Exclude None values (for pipeline approach this is to be expected)\n",
    "results[\"last_hidden_state\"] = [batch for batch in results[\"last_hidden_state\"] if batch is not None]\n",
    "plot_labels = [results[\"labels\"][i] for i in range(len(results[\"last_hidden_state\"])) if results[\"last_hidden_state\"][i] is not None]\n",
    "# plot_labels = [display_label_mapping[label] for label in plot_labels]\n",
    "\n",
    "# Last hidden states is a list of tensors of shape (seq_len, hidden_size)\n",
    "last_hidden_state = [batch[0, :] for batch in results[\"last_hidden_state\"]]  # Use CLS token\n",
    "embeddings = torch.stack(last_hidden_state, dim=0).to(torch.float16)\n",
    "\n",
    "reducer = UMAP()\n",
    "# Fit and transform the embeddings using the PCA object\n",
    "principalComponents = reducer.fit_transform(embeddings)\n",
    "principalComponents.shape\n",
    "\n",
    "# Create a dataframe with the embeddings and the corresponding labels\n",
    "df_embeddings = pd.DataFrame(principalComponents, columns=['x', 'y'])\n",
    "df_embeddings['label'] = plot_labels\n",
    "\n",
    "# Sort the labels\n",
    "df_embeddings = df_embeddings.sort_values(by='label', ascending=True)\n",
    "\n",
    "# Display the label mapping\n",
    "if display_label_mapping:\n",
    "    df_embeddings['label'] = df_embeddings['label'].map(display_label_mapping)\n",
    "\n",
    "# Plot using Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set_theme(style='whitegrid')\n",
    "sns.scatterplot(data=df_embeddings, x='x', y='y', hue='label', palette=sns.color_palette(\"gist_ncar\", 4)[:3], alpha=0.7)\n",
    "plt.xlabel('UMAP 1', fontsize='large', fontweight='bold')\n",
    "plt.ylabel('UMAP 2', fontsize='large', fontweight='bold')\n",
    "\n",
    "# Add a title and legend\n",
    "plt.legend(title='Label', loc='upper left', bbox_to_anchor=(1, 1), fontsize='large')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(paths.THESIS_PATH/\"ms_diag_medbert_embeddings_s2a.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81629f-dfa9-4638-9c1e-9d6de4f9aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.load(paths.RESULTS_PATH / \"ms-diag\" / \"ms-diag_medbert-512_pipeline_test_corrected_no_other.pt\")\n",
    "# Print classification report\n",
    "labels = [display_label_mapping[label] for label in results[\"labels\"]]\n",
    "preds = [display_label_mapping[pred] for pred in results[\"preds\"]]\n",
    "pd.DataFrame(classification_report(y_true=labels, y_pred=preds, output_dict = True)).transpose().round(2).to_csv(\"ms-diag_medbert-512_pipeline_test_corrected_no_other.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
