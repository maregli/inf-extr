{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e927d5c-5913-48ef-a16e-6b0dfcca48ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd()+\"/../..\")\n",
    "from src import paths\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils import get_default_pydantic_model\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f3baf4-accd-4b0c-a245-f61d6d985586",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ec3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to fix broken JSON by searching for last \"}\" then adding \"]\"\n",
    "default_model = get_default_pydantic_model(\"medication\")\n",
    "def fix_json(json_str):\n",
    "    last_index = json_str.rfind(\"}\")\n",
    "    if last_index != -1:  # If \"},\" is found\n",
    "        fixed_json = json_str[:last_index + 1] + \"]}\"\n",
    "\n",
    "        return fixed_json\n",
    "    else:\n",
    "        # If \"},\" is not found, return the default_model\n",
    "        return default_model.model_dump_json()\n",
    "    \n",
    "# If all the values of morning, noon, evening, night are 0, then set them all to -99\n",
    "def check_and_replace(df, cols_to_check):\n",
    "    \"\"\"\n",
    "    Check if 4 specified columns in each row are all 0,\n",
    "    then replace those 4 columns with -99.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): Input DataFrame.\n",
    "        cols_to_check (list): List of column names to check.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with replacements.\n",
    "    \"\"\"\n",
    "    for index, row in df.iterrows():\n",
    "        if (row[cols_to_check] == 0).sum() >= 4:\n",
    "            df.loc[index, cols_to_check] = -99\n",
    "    return df\n",
    "\n",
    "def prepare_results(path: str)->pd.DataFrame:\n",
    "    results = torch.load(path)\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    # Fix model_answers wherever successful is False\n",
    "    _df_fixed = df[~df[\"successful\"]].apply(lambda row: fix_json(row[\"model_answers\"]), axis=1)\n",
    "    df_fixed = df.copy()\n",
    "    df_fixed.loc[~df[\"successful\"], \"model_answers\"] = _df_fixed\n",
    "\n",
    "    dfs = []\n",
    "    for idx, (answer, text) in enumerate(zip(df_fixed[\"model_answers\"], df_fixed[\"text\"])):\n",
    "        try:\n",
    "            answer = json.loads(answer)\n",
    "            medications = answer[\"medications\"]\n",
    "            for med in medications:\n",
    "                med[\"text\"] = text\n",
    "                med[\"id\"] = idx\n",
    "                dfs.append((med))\n",
    "        except:\n",
    "            print(f\"Error at index {idx}\")\n",
    "    res = pd.DataFrame(dfs)\n",
    "\n",
    "    # If all the values of morning, noon, evening, night are 0, then set them all to -99\n",
    "    res = check_and_replace(res, [\"morning\", \"noon\", \"evening\", \"night\"])\n",
    "\n",
    "    # Convert everything to string and lowercase\n",
    "    res = res.map(lambda x: str(x).lower())\n",
    "\n",
    "    # Remove .0+ from every string\n",
    "    expression = r\"\\.0+$\"\n",
    "    res = res.replace(expression, \"\", regex=True)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faca820",
   "metadata": {},
   "source": [
    "- False Positives (FP): Predicted but not in ground truth. So if a dose for a tp medication is predicted wrongly, or if a medication was predicted that is not in the ground truth (and thus also a dose was predicted that is not in the ground truth)\n",
    "- True Positives (TP): Predicted and in ground truth.\n",
    "- False Negatives (FN): Not predicted but in ground truth. This can only happen if the medication is not predicted as if it is predicted it will always also predict a unit.\n",
    "- True Negatives (TN): Not predicted and not in ground truth (not relevant for this task)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a0fbf",
   "metadata": {},
   "source": [
    "Stuff it doesn't catch\n",
    "- Spelling mistakes: defalgan instead of dafalgan. Example 73 for E/ml vs IE/ml. Example 79 for wrong schema (but I would also not know what to do)\n",
    "- Sometimes didn't write full name or splits it up (Irfen Dolo; Excipial U Lipolotion)\n",
    "- A lot of times if no schema was there it just put 0 0 0 0 for the intake. It had a tendency to write 0 (instead of -99) for stuff it didn't find. Also 1-0-0-0 not really safe. The rest seem robust.\n",
    "    - Could convert to -99 if all of them are 0 which doesn't make sense anyways. Check if better metrics.\n",
    "- Couldn't catch split stuff in dose like 80/10, 800/160\n",
    "- Text 48 and 60 is good examples of what rule based dosis intake would not catch\n",
    "- Also example 63 for dosis (2 fÃ¼r beideseitig)\n",
    "- Example 68 for something you had to google as well (no mg, so model puts Filmtabl)\n",
    "- Example 77 for something that is very hard to catch for a model like this\n",
    "- Example 78 for hallucination of medication (because Insurance sounds like medication)\n",
    "- Example 87 for a hard case (with no medication implicit), could probably be alleviated with correct example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feaf290",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57c19ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(path: str)->pd.DataFrame:\n",
    "    labels = pd.read_excel(path) \n",
    "\n",
    "    # Convert everything to string and lowercase\n",
    "    labels = labels.map(lambda x: str(x).lower())\n",
    "\n",
    "    # Remove .0+ from every string\n",
    "    expression = r\"\\.0+$\"\n",
    "    labels = labels.replace(expression, \"\", regex=True)\n",
    "\n",
    "    return labels\n",
    "\n",
    "def calculate_precision_recall(ground_truth, predicted):\n",
    "    ground_truth = ground_truth.copy()\n",
    "    predicted = predicted.copy()\n",
    "    true_positives = {}\n",
    "    false_positives = {}\n",
    "    false_negatives = {}\n",
    "    \n",
    "    for pred in predicted:\n",
    "        pred_name = pred[\"name\"]\n",
    "        true_positives.setdefault(\"name\", 0)\n",
    "        matched = False\n",
    "        for i, truth in enumerate(ground_truth):\n",
    "            if truth[\"name\"] in pred_name or pred_name in truth[\"name\"]: # First we match the medication to the corresponding ground truth\n",
    "                matched = True\n",
    "                pred.pop(\"name\") # Remove name and put true positive\n",
    "                true_positives[\"name\"] += 1\n",
    "                for key in pred: # Then iterate over the keys and count the true positives and false positives\n",
    "                    if pred[key] == truth[key]:\n",
    "                        true_positives.setdefault(key, 0)\n",
    "                        true_positives[key] += 1\n",
    "                    else:\n",
    "                        false_positives.setdefault(key, 0)\n",
    "                        false_positives[key] += 1\n",
    "                        \n",
    "                del ground_truth[i]  # Remove the matched item\n",
    "                break  # Move to the next predicted item\n",
    "        \n",
    "        if not matched: # If there is no medication in the ground truth that matches, then it is a false positive for all keys\n",
    "            for key in pred:\n",
    "                false_positives.setdefault(key, 0)\n",
    "                false_positives[key] += 1\n",
    "    for truth in ground_truth:\n",
    "        for key in truth:\n",
    "            false_negatives.setdefault(key, 0)\n",
    "            false_negatives[key] += 1\n",
    "    \n",
    "    precision = {}\n",
    "    recall = {}\n",
    "    f1_score = {}\n",
    "\n",
    "    if len(predicted) == 0:\n",
    "        true_positives = {key: 0 for key in ground_truth[0].keys()}\n",
    "        false_positives = {key: 0 for key in ground_truth[0].keys()}\n",
    "\n",
    "    for key in relevant_columns:\n",
    "        # Precision: TP / (TP + FP)\n",
    "        precision[key] = true_positives.get(key, 0) / (true_positives.get(key, 0) + false_positives.get(key, 0) + 1e-10)\n",
    "\n",
    "        # Recall: TP / (TP + FN)\n",
    "        recall[key] = true_positives.get(key, 0) / (true_positives.get(key, 0) + false_negatives.get(key, 0) + 1e-10)\n",
    "\n",
    "        # F1 Score: 2 * (Precision * Recall) / (Precision + Recall)\n",
    "        f1_score[key] = 2 * (precision[key] * recall[key]) / (precision[key] + recall[key] + 1e-10)\n",
    "    \n",
    "    # Catch NA values in true_positives\n",
    "    \n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def evaluate_df(ground_truth: pd.DataFrame, predicted: pd.DataFrame, relevant_columns: list)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluates the predicted DataFrame against the ground truth DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        ground_truth (pandas.DataFrame): DataFrame with the ground truth.\n",
    "        predicted (pandas.DataFrame): DataFrame with the predicted values.\n",
    "        relevant_columns (list): List of relevant columns to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with the evaluated scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    evaluated = []\n",
    "    assert len(ground_truth.id.unique()) == len(predicted.id.unique()), \"The number of unique ids (texts) in the ground truth and predicted DataFrames do not match.\"\n",
    "\n",
    "    for idx in ground_truth.id.unique():\n",
    "        ground_truth_dict = ground_truth[ground_truth.id == idx][relevant_columns].to_dict(\"records\")\n",
    "        predicted_dict = predicted[predicted.id == idx][relevant_columns].to_dict(\"records\")\n",
    "\n",
    "        precision, recall, f1_score = calculate_precision_recall(ground_truth_dict, predicted_dict)\n",
    "\n",
    "        precision_dict = {f\"precision_{key}\": value for key, value in precision.items()}\n",
    "        recall_dict = {f\"recall_{key}\": value for key, value in recall.items()}\n",
    "        f1_score_dict = {f\"f1_score_{key}\": value for key, value in f1_score.items()}\n",
    "        \n",
    "        merged = {**precision_dict, **recall_dict, **f1_score_dict}\n",
    "        merged[\"text\"] = predicted[predicted.id == idx][\"text\"].values[0]\n",
    "        merged[\"id\"] = idx\n",
    "        evaluated.append(merged)\n",
    "\n",
    "    return pd.DataFrame(evaluated)\n",
    "\n",
    "def aggregate_scores(evaluated: pd.DataFrame, columns_to_drop: list = [\"id\", \"text\"])->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregates the metrics by averaging metrics over all unique texts. Also aggregates intake dosage metrics.\n",
    "\n",
    "    Parameters:\n",
    "        evaluated (pandas.DataFrame): DataFrame with the evaluated scores.\n",
    "        columns_to_drop (list): List of columns to drop. Default is [\"id\", \"text\"].\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with the aggregated scores.\n",
    "    \"\"\"\n",
    "    agg_df = evaluated.drop(columns=columns_to_drop).mean()\n",
    "    agg_df[\"precision_intake\"] = agg_df[[\"precision_morning\", \"precision_noon\", \"precision_evening\", \"precision_night\"]].mean()\n",
    "    agg_df[\"recall_intake\"] = agg_df[[\"recall_morning\", \"recall_noon\", \"recall_evening\", \"recall_night\"]].mean()\n",
    "    agg_df[\"f1_score_intake\"] = agg_df[[\"f1_score_morning\", \"f1_score_noon\", \"f1_score_evening\", \"f1_score_night\"]].mean()\n",
    "    agg_df.drop([\"precision_morning\", \"precision_noon\", \"precision_evening\", \"precision_night\", \"recall_morning\", \"recall_noon\", \"recall_evening\", \"recall_night\", \"f1_score_morning\", \"f1_score_noon\", \"f1_score_evening\", \"f1_score_night\"], inplace=True)\n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee16d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = prepare_labels(paths.RESULTS_PATH/\"medication/labels.xlsx\")\n",
    "\n",
    "res = prepare_results(paths.RESULTS_PATH/\"medication/medication_outlines_Llama2-MedTuned-13b_4bit_few_shot_instruction_examples_10.pt\")\n",
    "\n",
    "# Choose only the relevant columns\n",
    "relevant_columns = [\"name\", \"dose\", \"dose_unit\", \"morning\", \"noon\", \"evening\", \"night\"]\n",
    "\n",
    "evaluated = evaluate_df(labels, res, relevant_columns)\n",
    "\n",
    "agg_df = aggregate_scores(evaluated)\n",
    "\n",
    "type(agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bc75d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d897d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama 13B\n",
    "results_13b = []\n",
    "filenames13b = [filename for filename in os.listdir(paths.RESULTS_PATH/\"medication\") if filename.startswith(\"medication_outlines_Llama2-MedTuned-13b\")]\n",
    "for filename in filenames13b:\n",
    "    res = prepare_results(paths.RESULTS_PATH/\"medication\"/filename)\n",
    "    evaluated = evaluate_df(labels, res, relevant_columns)\n",
    "    agg_df = aggregate_scores(evaluated)\n",
    "    results_13b.append(agg_df)\n",
    "results_13b = pd.concat(results_13b, axis=1).round(2)\n",
    "results_13b.columns = [\"Few-Shot Instruction 1\", \"Few-Shot Instruction 10\", \"Few-Shot Instruction 2\", \"Few-Shot Instruction 4\", \"Few-Shot Instruction 8\", \"Few-Shot Base 10\", \"Zero-Shot Instruction 0\", \"Zero-Shot Base 0\"]\n",
    "# Reorder columns\n",
    "results_13b = results_13b[[\"Zero-Shot Base 0\", \"Zero-Shot Instruction 0\", \"Few-Shot Base 10\", \"Few-Shot Instruction 10\", \"Few-Shot Instruction 1\", \"Few-Shot Instruction 2\", \"Few-Shot Instruction 4\", \"Few-Shot Instruction 8\"]]\n",
    "\n",
    "# Reorder rows\n",
    "results_13b = results_13b.reindex([\"precision_name\", \"precision_dose\", \"precision_dose_unit\", \"precision_intake\", \"recall_name\", \"recall_dose\", \"recall_dose_unit\", \"recall_intake\", \"f1_score_name\", \"f1_score_dose\", \"f1_score_dose_unit\", \"f1_score_intake\"])\n",
    "results_13b.to_csv(paths.RESULTS_PATH/\"medication\"/\"results_13b.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e3bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_13b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab1452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama 7B\n",
    "results_7b = []\n",
    "filenames7b = [filename for filename in os.listdir(paths.RESULTS_PATH/\"medication\") if filename.startswith(\"medication_outlines_Llama2-MedTuned-7b\")]\n",
    "for filename in filenames7b:\n",
    "    res = prepare_results(paths.RESULTS_PATH/\"medication\"/filename)\n",
    "    evaluated = evaluate_df(labels, res, relevant_columns)\n",
    "    agg_df = aggregate_scores(evaluated)\n",
    "    results_7b.append(agg_df)\n",
    "results_7b = pd.concat(results_7b, axis=1).round(2)\n",
    "results_7b.columns = [\"Few-Shot Instruction 1\", \"Few-Shot Instruction 10\", \"Few-Shot Instruction 2\", \"Few-Shot Instruction 4\", \"Few-Shot Instruction 8\", \"Few-Shot Base 10\", \"Zero-Shot Instruction 0\", \"Zero-Shot Base 0\"]\n",
    "# Reorder columns\n",
    "results_7b = results_7b[[\"Zero-Shot Base 0\", \"Zero-Shot Instruction 0\", \"Few-Shot Base 10\", \"Few-Shot Instruction 10\", \"Few-Shot Instruction 1\", \"Few-Shot Instruction 2\", \"Few-Shot Instruction 4\", \"Few-Shot Instruction 8\"]]\n",
    "# Reorder rows\n",
    "results_7b = results_7b.reindex([\"precision_name\", \"precision_dose\", \"precision_dose_unit\", \"precision_intake\", \"recall_name\", \"recall_dose\", \"recall_dose_unit\", \"recall_intake\", \"f1_score_name\", \"f1_score_dose\", \"f1_score_dose_unit\", \"f1_score_intake\"])\n",
    "results_7b.to_csv(paths.RESULTS_PATH/\"medication\"/\"results_7b.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36740b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_7b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c270d9",
   "metadata": {},
   "source": [
    "# Rule Based Approach\n",
    "From old project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67660478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_list_medi_ms():\n",
    "    \n",
    "    '''\n",
    "    load list of MS medications\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    with open(paths.PROJECT_ROOT/\"resources/old_project/medication_for_ms.txt\", \"r\") as f:\n",
    "        list_medi_ms = f.readlines()\n",
    "    list_medi_ms = [item.strip() for item in list_medi_ms]\n",
    "    \n",
    "    return list_medi_ms\n",
    "\n",
    "def _split_dose_and_unit(test_str, list_unit):\n",
    "    \n",
    "    '''\n",
    "    split strings for dose and unit which aren't separated by a space, e.g. '120mg' and '0.5mg'\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def _contains_alpha_and_numeric(test_str):\n",
    "        '''\n",
    "        helper function to determine whether string could represent a dose and a unit and if it contains a dot\n",
    "        '''\n",
    "\n",
    "        # initiliaze\n",
    "        status = 'no'\n",
    "        \n",
    "        # dose and unit start with a digit and end with a letter\n",
    "        if (test_str[0].isdigit()) & (test_str[-1].isalpha()):\n",
    "\n",
    "            # does it contain a dot\n",
    "            if '.' in test_str:\n",
    "                status = 'w/_dot'\n",
    "            else:\n",
    "                status = 'w/o_dot'\n",
    "\n",
    "        return status\n",
    "\n",
    "    # initialize\n",
    "    list_tokens = [test_str]\n",
    "\n",
    "    # get status whether it could be a dose and unit\n",
    "    status = _contains_alpha_and_numeric(test_str)\n",
    "    \n",
    "    # if it contains 1 dot but no other special characters, and all letters represent a unit\n",
    "    if status == 'w/_dot':\n",
    "\n",
    "        if (test_str.count('.') == 1) & (len(re.findall('[\\W]', test_str.replace('.', ''))) == 0):\n",
    "            \n",
    "            if re.findall('[a-zA-Z]+', test_str)[0] in list_unit:\n",
    "    \n",
    "                list_tokens = list(re.findall('(\\d+)\\.(\\d+)?(\\w+)', test_str)[0])\n",
    "                list_tokens = ['.'.join(list_tokens[:2]), list_tokens[-1]]\n",
    "\n",
    "    # if it doesn't contain a dot and all characters are either digits or letters\n",
    "    if status == 'w/o_dot':\n",
    "        \n",
    "        if test_str.isalnum():\n",
    "    \n",
    "            list_tokens = list(re.findall('(\\d+)(\\w+)', test_str)[0])\n",
    "    \n",
    "    return list_tokens\n",
    "\n",
    "def extract_dose_and_unit(list_tokens, list_unit_match):\n",
    "\n",
    "    # intialize\n",
    "    dose = ''\n",
    "    unit = ''\n",
    "    \n",
    "    # extract dose and unit if there is exactly one match\n",
    "    if len(list_unit_match) == 1:\n",
    "\n",
    "        unit = list_unit_match[0]\n",
    "        dose = list_tokens[list_tokens.index(unit) - 1]   \n",
    "        \n",
    "    return dose, unit\n",
    "\n",
    "def extract_dosage_across_day(list_dose_match):\n",
    "    \n",
    "    # initialize\n",
    "    morning = ''\n",
    "    noon = ''\n",
    "    evening = ''\n",
    "    night = ''\n",
    "    \n",
    "    # extract dosage for first entry\n",
    "    if len(list_dose_match) >= 1:\n",
    "        \n",
    "        medi_dose = list_dose_match[0]\n",
    "        list_medi_doses = medi_dose.split('-')\n",
    "        \n",
    "        # 3 entries, e.g 1-1-1\n",
    "        if len(list_medi_doses) == 3:\n",
    "            morning = list_medi_doses[0]\n",
    "            noon = list_medi_doses[1]\n",
    "            evening = list_medi_doses[2]\n",
    "            night = 0\n",
    "            \n",
    "        # 4 entries, e.g. 1-0-0-0\n",
    "        elif len(list_medi_doses) == 4:\n",
    "            morning = list_medi_doses[0]\n",
    "            noon = list_medi_doses[1]\n",
    "            evening = list_medi_doses[2]\n",
    "            night = list_medi_doses[3]\n",
    "            \n",
    "    return morning, noon, evening, night\n",
    "\n",
    "   \n",
    "def flatten_listoflists(listoflists):\n",
    "    '''\n",
    "    function to flatten a list of lists\n",
    "    \n",
    "    input:\n",
    "    - listoflists: nested list\n",
    "    \n",
    "    output:\n",
    "    - flat_list: unnested list\n",
    "    '''\n",
    "    \n",
    "    flat_list = [item for sublist in listoflists for item in sublist]\n",
    "    \n",
    "    return flat_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded3fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medi = pd.read_csv(paths.DATA_PATH_PREPROCESSED/\"medication/kisim_medication_sample.csv\")\n",
    "df_medi[\"id\"] = df_medi.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcbe2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of units and MS medications\n",
    "list_unit = ['mg', 'ug', 'g']\n",
    "list_medi_ms = load_list_medi_ms()\n",
    "\n",
    "# intitialize\n",
    "list_output = list()\n",
    "\n",
    "# for each row\n",
    "for _, row in df_medi.iterrows():\n",
    "    \n",
    "    # get research id, etc.\n",
    "    rid = row['rid']\n",
    "    text_all = row['text']\n",
    "    id = row['id']\n",
    "    \n",
    "    # split text into lines\n",
    "    list_text_all = text_all.splitlines()\n",
    "    \n",
    "    # for each text line\n",
    "    for text in list_text_all:\n",
    "        \n",
    "        # get tokens and split dose and unit, e.g. '120mg'\n",
    "        list_tokens = text.split()\n",
    "        list_tokens = flatten_listoflists([_split_dose_and_unit(item, list_unit) for item in list_tokens])\n",
    "        \n",
    "        # match medication names, units and dosing (e.g. 1-1-1)\n",
    "        list_name_match = list(set(list_tokens).intersection(list_medi_ms))\n",
    "        list_unit_match = list(set(list_tokens).intersection(list_unit))\n",
    "        list_dose_match = [item for item in list_tokens if '-' in item]\n",
    "\n",
    "        # if an MS medication name was matched\n",
    "        if len(list_name_match) >=  1:\n",
    "\n",
    "            # get (first) medication name (there are very few cases with > 1 name)\n",
    "            name = list_name_match[0]\n",
    "\n",
    "            # get dose and unit\n",
    "            dose, unit = extract_dose_and_unit(list_tokens, list_unit_match)\n",
    "              \n",
    "            # get dosage across day\n",
    "            morning, noon, evening, night = extract_dosage_across_day(list_dose_match)\n",
    "\n",
    "            # extra field\n",
    "            extra = \"\"\n",
    "\n",
    "            # append\n",
    "            list_output.append((name, dose, unit, morning, noon, evening, night, extra, text_all, id))       \n",
    "            \n",
    "# generate output data frame\n",
    "df_results = pd.DataFrame(list_output, \n",
    "                         columns = [ \n",
    "                                    'name', 'dose', 'dose_unit', \n",
    "                                    'morning', 'noon', 'evening','night',\n",
    "                                    'extra',\n",
    "                                    'text', \"id\"])\n",
    "output_ids = set(df_results.id.unique())\n",
    "print(\"Number of reports that were processed:\", len(output_ids))\n",
    "left_over_ids = set(df_medi.id.unique()) - output_ids\n",
    "\n",
    "left_over_dfs = []\n",
    "for id in left_over_ids:\n",
    "    _df = {**default_model.model_dump()[\"medications\"][0], \"text\": df_medi[df_medi.id == id].text.values[0], \"id\": id}\n",
    "    left_over_dfs.append(_df)\n",
    "left_over_df = pd.DataFrame(left_over_dfs)\n",
    "\n",
    "df_results = pd.concat([df_results, left_over_df]).sort_values(\"id\").reset_index(drop=True)\n",
    "\n",
    "# To get comparability need to map to string\n",
    "\n",
    "df_results = df_results.map(lambda x: str(x).lower())\n",
    "expression = r\"\\.0+$\"\n",
    "df_results = df_results.replace(expression, \"\", regex=True)\n",
    "\n",
    "\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bcede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[df_results.id == \"93\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a854f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res[\"id\"] == \"78\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5281e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[labels[\"id\"] == \"78\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d0ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_rule = evaluate_df(labels, df_results, relevant_columns)\n",
    "agg_df_rule = aggregate_scores(evaluated_rule)\n",
    "agg_df_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the ones it predicted:\n",
    "predicted_examples_ids = [str(id) for id in output_ids]\n",
    "aggregate_scores(evaluated_rule[evaluated_rule.id.isin(predicted_examples_ids)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167ae46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rule = pd.DataFrame([aggregate_scores(evaluated_rule), aggregate_scores(evaluated_rule[evaluated_rule.id.isin(predicted_examples_ids)])]).round(2)\n",
    "res_rule.to_csv(paths.RESULTS_PATH/\"medication\"/\"results_rule.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e884c",
   "metadata": {},
   "source": [
    "Notes for rule based:\n",
    "- Only first example of medication is extracted.\n",
    "- Only 4 out of 100 examples were even detected. (Also in original one they only detected around 6% of examples)\n",
    "- Even for the ones it detected, if there are multiple medications it won't extract them. So recall not as high.\n",
    "- For precision of course very high, but also here mistakes. Like dose-unit 0,5 is different from 0.5, which LLM catches as it outputs float format, while rule based does text matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e2b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfafa04d",
   "metadata": {},
   "source": [
    "## Intermezzo\n",
    "Just to check if they also just extracted so few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ea385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medi1 = pd.read_csv(paths.DATA_PATH_RSD/'reports_kisim_medication.csv')\n",
    "# drop empty medication text\n",
    "df_medi1 = df_medi1[df_medi1['medication_name'].notnull()]\n",
    "# list of units and MS medications\n",
    "list_unit = ['mg', 'ug', 'g']\n",
    "list_medi_ms = load_list_medi_ms()\n",
    "\n",
    "# intitialize\n",
    "list_output = list()\n",
    "\n",
    "# for each row\n",
    "for _, row in df_medi1.iterrows():\n",
    "    \n",
    "    # # get research id, etc.\n",
    "    # rid = row['rid']\n",
    "    # text_all = row['text']\n",
    "    # get research id, etc.\n",
    "    rid = row['research_id']\n",
    "    date = row['medication_prescription_date']\n",
    "    prescription = row['medication_prescription_name']\n",
    "    text_all = row['medication_name']\n",
    "    \n",
    "    # split text into lines\n",
    "    list_text_all = text_all.splitlines()\n",
    "    \n",
    "    # for each text line\n",
    "    for text in list_text_all:\n",
    "        \n",
    "        # get tokens and split dose and unit, e.g. '120mg'\n",
    "        list_tokens = text.split()\n",
    "        list_tokens = flatten_listoflists([_split_dose_and_unit(item, list_unit) for item in list_tokens])\n",
    "        \n",
    "        # match medication names, units and dosing (e.g. 1-1-1)\n",
    "        list_name_match = list(set(list_tokens).intersection(list_medi_ms))\n",
    "        list_unit_match = list(set(list_tokens).intersection(list_unit))\n",
    "        list_dose_match = [item for item in list_tokens if '-' in item]\n",
    "\n",
    "        # if an MS medication name was matched\n",
    "        if len(list_name_match) >=  1:\n",
    "\n",
    "            # get (first) medication name (there are very few cases with > 1 name)\n",
    "            name = list_name_match[0]\n",
    "\n",
    "            # get dose and unit\n",
    "            dose, unit = extract_dose_and_unit(list_tokens, list_unit_match)\n",
    "              \n",
    "            # get dosage across day\n",
    "            morning, noon, evening, night = extract_dosage_across_day(list_dose_match)\n",
    "\n",
    "            # append\n",
    "            list_output.append((rid, name, dose, unit, morning, noon, evening, night, text, text_all))        \n",
    "            \n",
    "# generate output data frame\n",
    "df_results1 = pd.DataFrame(list_output, \n",
    "                         columns = ['rid', \n",
    "                                    'name', 'dose', 'unit', \n",
    "                                    'morning', 'evening', 'noon', 'night',\n",
    "                                    'text_line', 'text_all'])\n",
    "len(df_results1)/len(df_medi1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
