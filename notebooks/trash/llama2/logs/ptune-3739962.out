=====================================================================
                   Welcome to Leonhard Med v.2.0.1                    

 * Documentation:  https://unlimited.ethz.ch/display/LEOMED2
 * Support:        leomed-support@id.ethz.ch
 * Software stack: type "enable_modules" to use Modules

Tenant name: BIOMED
OS: Ubuntu 20.04.6 LTS x86_64 
Uptime: 1 day, 18 hours, 24 mins 
CPU: AMD EPYC-Rome (124) @ 2.249GHz 
CPU Usage: 2% 
GPU: NVIDIA 00:0e.0 NVIDIA Corporation Device 2204 
GPU: NVIDIA 00:0d.0 NVIDIA Corporation Device 2204 
GPU: NVIDIA 00:09.0 NVIDIA Corporation Device 2204 
GPU: NVIDIA 00:0c.0 NVIDIA Corporation Device 2204 
GPU: NVIDIA 00:08.0 NVIDIA Corporation Device 2204 
GPU: NVIDIA 00:0b.0 NVIDIA Corporation Device 2204 
GPU: NVIDIA 00:0a.0 NVIDIA Corporation Device 2204 
GPU: NVIDIA 00:0f.0 NVIDIA Corporation Device 2204 
Memory: 217098MiB / 487921MiB (44%) 

=====================================================================
Starting job with ID 3739962...
Parsed Arguments:
job_id: unknown
model_name: llama2
quantization: bfloat16
truncation_size: 256
batch_size: 8
lr: 0.001
num_epochs: 4
gradient_accumulation_steps: None
peft_type: ptune
data: augmented
classification: multi-class
GPU 0: NVIDIA GeForce RTX 3090
   Total Memory: 23.69 GB
   Free Memory: 23.02 GB
   Allocated Memory : 0.00 GB
   Reserved Memory : 0.00 GB
Tokenizer pad token ID: 32000
Model pad token ID: 32000
Model config pad token ID: 32000
Vocabulary Size with Pad Token:  32001
Loaded Model and Tokenizer
trainable params: 1,163,520 || all params: 6,608,523,520 || trainable%: 0.017606353317480512
Loaded PEFT Model
Loaded Data
Starting Training
Saving Model at /cluster/dataset/midatams/inf-extr/resources/models/ms-diag_llama2_bfloat16_ptune_augmented_256
Saving Model at /cluster/dataset/midatams/inf-extr/resources/models/ms-diag_llama2_bfloat16_ptune_augmented_256
epoch=0: train_epoch_loss=tensor(2.1213, device='cuda:0') eval_epoch_loss=tensor(1.0371, device='cuda:0') f1=0.293859649122807
epoch=1: train_epoch_loss=tensor(1.1503, device='cuda:0') eval_epoch_loss=tensor(1.6523, device='cuda:0') f1=0.0989010989010989
Saving Model at /cluster/dataset/midatams/inf-extr/resources/models/ms-diag_llama2_bfloat16_ptune_augmented_256
epoch=2: train_epoch_loss=tensor(1.0129, device='cuda:0') eval_epoch_loss=tensor(1.4492, device='cuda:0') f1=0.4901960784313726
epoch=3: train_epoch_loss=tensor(0.9963, device='cuda:0') eval_epoch_loss=tensor(1.0977, device='cuda:0') f1=0.21052631578947367
Training Finished
Job finished
