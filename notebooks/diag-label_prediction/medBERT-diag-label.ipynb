{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd()+\"/../..\")\n",
    "from src import paths\n",
    "from huggingface_hub import notebook_login\n",
    "import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to Hugging Face Hub as model is gated\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "checkpoint = \"GerMedBERT/medbert-512\"\n",
    "\n",
    "# Load model\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "# Load model for embedding\n",
    "model = AutoModel.from_pretrained(checkpoint)\n",
    "model_base = model.base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pl.read_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line_labelling_clean.csv\"))\n",
    "df = df.filter(pl.col(\"text\").is_not_null())\n",
    "\n",
    "df[\"text\"].to_list()\n",
    "# Tokenize data\n",
    "tokenized = tokenizer(df[\"text\"].to_list(), padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "# Embed data while logging progress\n",
    "embeddings = []\n",
    "batch_size = 32\n",
    "\n",
    "for i in tqdm.tqdm(range(0, len(tokenized[\"input_ids\"]), batch_size)):\n",
    "    tokens = tokenized[\"input_ids\"][i:i+batch_size]\n",
    "    attention_mask = tokenized[\"attention_mask\"][i:i+batch_size]\n",
    "    embeddings.append(model(tokens, attention_mask).last_hidden_state.detach())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.cat(embeddings, dim=0)\n",
    "test.shape\n",
    "\n",
    "# CLS token\n",
    "cls = test[:,0,:]\n",
    "cls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embeddings with PCA\n",
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(cls)\n",
    "\n",
    "# Sample data\n",
    "x = components[:,0]\n",
    "y = components[:,1]\n",
    "labels = df[\"class_agg\"][:20].to_list()\n",
    "\n",
    "# Create a dictionary to map labels to unique numeric values\n",
    "label_to_numeric = {label: i for i, label in enumerate(df[\"class_agg\"].unique())}\n",
    "\n",
    "# Convert labels to numeric values\n",
    "numeric_labels = [label_to_numeric[label] for label in labels]\n",
    "\n",
    "# Create a colormap\n",
    "cmap = plt.get_cmap(\"viridis\")  # You can choose a different colormap if desired\n",
    "\n",
    "# Scatter plot with colors based on labels\n",
    "scatter = plt.scatter(x, y, c=numeric_labels ,cmap=cmap)\n",
    "\n",
    "# Create a colorbar to display label-color mapping\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label(\"Class Label\")\n",
    "\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.title(\"Scatter Plot with Colored Data Points\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.equal(output[\"last_hidden_state\"], output[\"hidden_states\"][-1])\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of tokenized data\n",
    "torch.equal(output.hidden_states[1], output2.hidden_states[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model_base.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf-extr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
