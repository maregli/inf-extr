{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38412455-78c3-4c9c-8c5d-e40fcfcf948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd()+\"/../..\")\n",
    "from src import paths\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238d4c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(filename:str, labels:str, load_line:bool = False, load_outlines:bool = False, label_correction:dict = None):\n",
    "    \"\"\" \n",
    "    Load results from a file and return a pandas dataframe with the results.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The name of the file to load.\n",
    "        labels (str): The name of the file containing the labels.\n",
    "        load_line (bool, optional): If True, the function will expect a line labelled dataset and return the aggregated results per rid.\n",
    "        load_outlines (bool, optional): If True, the function will expect the output of an outlines prompt (no hidden states and model answers are labels)\n",
    "        label_correcttion (dict, optional): A dictionary with rids as keys and the corrected labels as values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A pandas dataframe with the results.\n",
    "\n",
    "    \"\"\"\n",
    "    results = torch.load(paths.RESULTS_PATH/\"ms-diag\"/filename, map_location=torch.device('cpu'))\n",
    "    labels = torch.load(paths.RESULTS_PATH/\"ms-diag\"/labels, map_location=torch.device('cpu'))\n",
    "\n",
    "    output = {\"model_answers\": results.pop(\"model_answers\")}\n",
    "\n",
    "    if not load_outlines:\n",
    "        \n",
    "        # Get prediction through cosine similarity\n",
    "        last_hidden_states = results.pop(\"last_hidden_states\")\n",
    "        last_hidden_states = last_hidden_states.cpu()\n",
    "        preds = get_prediction(last_hidden_states, labels_hs=labels[1], label_names=labels[0])\n",
    "\n",
    "        # If rag\n",
    "        if \"rag\" in filename:\n",
    "            output[\"model_answers_mapped\"] = preds + [\"no information found\" for _ in range(len(output[\"model_answers\"])-len(preds))]\n",
    "        else:\n",
    "            output[\"model_answers_mapped\"] = preds\n",
    "    \n",
    "    # Map from string answer to int\n",
    "    label2id = {'primär progrediente Multiple Sklerose': 0,\n",
    "            'sekundär progrediente Multiple Sklerose': 2,\n",
    "            'schubförmige remittierende Multiple Sklerose': 1,\n",
    "            'other': 3,\n",
    "            'no information found': 3}\n",
    "    \n",
    "    if load_outlines:\n",
    "        key = \"model_answers\"\n",
    "    else:\n",
    "        key = \"model_answers_mapped\"\n",
    "    \n",
    "    output[\"preds\"] = [label2id[i] for i in output[key]]\n",
    "    output[\"exact_match\"] = [res.lower().split(\"### output:\\n\")[-1] in [key.lower() for key in label2id.keys()] for res in output[\"model_answers\"]]\n",
    "\n",
    "    output[\"labels\"] = results[\"labels\"]\n",
    "    output[\"rid\"] = results[\"rid\"]\n",
    "    output[\"text\"] = results[\"text\"]\n",
    "\n",
    "    if \"whole_prompt\" in results.keys():\n",
    "        whole_prompt = results[\"whole_prompt\"]\n",
    "        if \"rag\" in filename:\n",
    "            output[\"whole_prompt\"] = whole_prompt + [\"no information found\" for _ in range(len(output[\"model_answers\"])-len(whole_prompt))]\n",
    "        else:\n",
    "            output[\"whole_prompt\"] = whole_prompt\n",
    "    \n",
    "    df = pd.DataFrame(output)\n",
    "\n",
    "    # Correcting wrong labels from analysis:\n",
    "    if label_correction:\n",
    "        for rid, label in label_correction.items():\n",
    "            df.loc[df.rid == rid, \"labels\"] = label\n",
    "    \n",
    "\n",
    "    if load_line:\n",
    "        return convert_line2report(df, filename)\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "def get_prediction(hs: torch.Tensor, labels_hs: torch.Tensor, label_names: list):\n",
    "    \"\"\" \n",
    "    Get the prediction for a given hidden state and labels.\n",
    "\n",
    "    Args:\n",
    "        hs (torch.Tensor): The hidden state to use for prediction. Shape (n_samples, n_features).\n",
    "        labels_hs (torch.Tensor): The hidden states of the labels. Shape (n_labels, n_features).\n",
    "        label_names (list): The names of the labels. The order of the names should match the order of the hs-labels in dim 0.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The predicted labels.\n",
    "\n",
    "    \"\"\"\n",
    "    answer_idx = np.argmax(cosine_similarity(hs, labels_hs), axis=1)\n",
    "    model_answer = [label_names[i] for i in answer_idx]\n",
    "    return model_answer\n",
    "\n",
    "def convert_line2report(rids:list[str], preds:list[int])->list[int]:\n",
    "    \"\"\" \n",
    "    Aggregeates the results of a line labelled dataset in a majority vote fashion.\n",
    "\n",
    "    Args:\n",
    "        rids (list[str]): The rids of the samples.\n",
    "        preds (list[int]): The predictions of the samples.\n",
    "\n",
    "    Returns:\n",
    "        list[int]: The aggregated predictions.\n",
    "        \n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\"rid\":rids, \"preds\":preds})\n",
    "\n",
    "    # If len value counts >1 and value counts[0] is 3, then majority vote is value counts[1]\n",
    "    results = []\n",
    "    rid = []\n",
    "    for _df in df.groupby(\"rid\"):\n",
    "        if _df[1].preds.value_counts().shape[0] > 1 and _df[1].preds.value_counts().iloc[0] == 3:\n",
    "            result = df.loc[df.rid == _df[0], \"preds\"] = _df[1].preds.value_counts().index[1]\n",
    "        else:\n",
    "            result = df.loc[df.rid == _df[0], \"preds\"] = _df[1].preds.value_counts().index[0]\n",
    "        results.append(result)\n",
    "        rid.append(_df[0])\n",
    "    return result\n",
    "\n",
    "\n",
    "def summarize_performance(files: list[str], *args, **kwargs):\n",
    "\n",
    "    \"\"\" \n",
    "    Summarizes the performance of a given strategy (Base, RAG, Outlines) for all prompting strategies.\n",
    "\n",
    "    Args:\n",
    "        files (list[str]): The files to summarize.\n",
    "        *args: Variable length argument list.\n",
    "        **kwargs: Arbitrary keyword arguments.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A pandas dataframe with the summarized results.\n",
    "\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for filename in files:\n",
    "        strategies = [\"zero_shot_vanilla\", \"zero_shot_instruction\", \"few_shot_vanilla\", \"few_shot_instruction\"]\n",
    "        \n",
    "        # Set strategy name to whatever is found in the filename\n",
    "        for strategy in strategies:\n",
    "            if strategy in filename:\n",
    "                break\n",
    "\n",
    "        results = load_results(filename=filename, labels=kwargs.get(\"labels\"), load_line=kwargs.get(\"load_lines\"), load_outlines=kwargs.get(\"load_outlines\"), label_correction=kwargs.get(\"label_correction\"))\n",
    "\n",
    "        # Target names\n",
    "        metric_dict = classification_report(y_true=results[\"labels\"], y_pred=results[\"preds\"], output_dict=True)\n",
    "\n",
    "        # Create a dictionary with flattened keys\n",
    "        _df = pd.json_normalize(metric_dict)\n",
    "        \n",
    "\n",
    "        # Add additional information\n",
    "        _df[\"strategy\"] = strategy\n",
    "\n",
    "        # Look for exact label\n",
    "        _df[\"valid_label\"] = sum(results[\"exact_match\"])/len(results)\n",
    "\n",
    "        # Reorder columns\n",
    "        reordered_cols = _df.columns[-4:].append(_df.columns[:-4])\n",
    "        _df = _df[reordered_cols]\n",
    "\n",
    "        dfs.append(_df)\n",
    "\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "def generate_latex_table(df: pd.DataFrame, caption: str, label: str, metrics = list[str]) -> str:\n",
    "    \"\"\"\n",
    "    Generate LaTeX code for a table from a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the table data.\n",
    "        caption (str): Caption for the table.\n",
    "        label (str): Label for referencing the table.\n",
    "        metrics (list[str]): List of metrics to include in the table.\n",
    "\n",
    "    Returns:\n",
    "        str: LaTeX code for the table.\n",
    "    \"\"\"\n",
    "    # Create the LaTeX code for the table\n",
    "    latex = \"\\\\begin{table}[h]\\n\"\n",
    "    latex += \"    \\\\centering\\n\"\n",
    "\n",
    "    # Create tables for each metric\n",
    "    for metric in metrics:\n",
    "        latex += f\"    \\\\begin{{tabular}}{{lcccc}}\\n\"\n",
    "        latex += f\"        \\\\toprule\\n\"\n",
    "        latex += f\"        & \\\\multicolumn{{4}}{{c}}{{{metric}}}\\\\\\\\\\n\"\n",
    "        latex += f\"        \\\\cmidrule(lr){{2-5}}\\n\"\n",
    "        latex += f\"        & Base & +S2A & +Outlines & +S2A \\\\& Outlines \\\\\\\\\\n\"\n",
    "        latex += f\"        \\\\midrule\\n\"\n",
    "\n",
    "        for strategy in df['strategy'].unique():\n",
    "            base_value = df[(df['strategy'] == strategy) & (df['approach'] == 'base')][metric].iloc[0]\n",
    "            rag_value = df[(df['strategy'] == strategy) & (df['approach'] == 'rag')][metric].iloc[0]\n",
    "            outlines_value = df[(df['strategy'] == strategy) & (df['approach'] == 'outlines')][metric].iloc[0]\n",
    "            outlines_rag_value = df[(df['strategy'] == strategy) & (df['approach'] == 'outlines_rag')][metric].iloc[0]\n",
    "            \n",
    "            latex += f\"        {strategy.replace('_', '-')} & {base_value:.2f} & {rag_value:.2f} & {outlines_value:.2f} & {outlines_rag_value:.2f} \\\\\\\\\\n\"\n",
    "\n",
    "        latex += f\"        \\\\bottomrule\\n\"\n",
    "        latex += f\"    \\\\end{{tabular}}\\n\\n\"\n",
    "\n",
    "    # Add caption and label\n",
    "    latex += f\"    \\\\caption{{{caption}}}\\n\"\n",
    "    latex += f\"    \\\\label{{tab:{label}}}\\n\"\n",
    "    latex += \"\\\\end{table}\\n\"\n",
    "\n",
    "    return latex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea684de",
   "metadata": {},
   "source": [
    "# Llama2-MedTuned-13B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161f36d6",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0639401",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "summarize_performance([\"ms-diag_Llama2-MedTuned-13b_4bit_all_test_zero_shot_vanilla_rag.pt\",\n",
    "                       \"ms-diag_Llama2-MedTuned-13b_4bit_all_test_zero_shot_instruction_rag.pt\",\n",
    "                       \"ms-diag_Llama2-MedTuned-13b_4bit_all_test_few_shot_vanilla_rag.pt\",\n",
    "                       \"ms-diag_Llama2-MedTuned-13b_4bit_all_test_few_shot_instruction_rag.pt\",\n",
    "                       ], labels=\"label_encodings_Llama2-MedTuned-13b.pt\", load_line=False, load_outlines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88767f40",
   "metadata": {},
   "source": [
    "## Outlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560f24fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "summarize_performance([\"ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_zero_shot_vanilla.pt\",\n",
    "                       \"ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_zero_shot_instruction.pt\",\n",
    "                       \"ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_few_shot_vanilla.pt\",\n",
    "                       \"ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_few_shot_instruction.pt\",\n",
    "                       ], labels=\"label_encodings_Llama2-MedTuned-7b.pt\", load_line=False, load_outlines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019c2552",
   "metadata": {},
   "source": [
    "## RAG + Outlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df948dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "summarize_performance([\"ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_zero_shot_vanilla_rag.pt\",\n",
    "                       \"ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_zero_shot_instruction_rag.pt\",\n",
    "                       \"ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_few_shot_vanilla_rag.pt\",\n",
    "                       \"ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_few_shot_instruction_rag.pt\",\n",
    "                       ], labels=\"label_encodings_Llama2-MedTuned-13b.pt\", load_line=False, load_outlines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755f2409",
   "metadata": {},
   "source": [
    "### Label Corrections\n",
    "- rid: 96BC21AA-235F-4EED-A74F-58EFC11C1176, \n",
    "    - text: Hochgradiger V.a. entzündliche ZNS-Erkrankung ED 03.05.2019, EM 30.04.2019\\nINDENT ätiologisch: möglicherweise multiple Sklerose\n",
    "    - label: 1\n",
    "    - corrected label: 3\n",
    "- rid: B5B6D014-7E02-44E5-8390-F571F7C1D4E5\n",
    "    - text: Multiple Sklerose (EM 05/2011, ED 09/2011)\n",
    "    - label: 1\n",
    "    - corrected label: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca2fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_correction = {\"96BC21AA-235F-4EED-A74F-58EFC11C1176\" : 3, \"B5B6D014-7E02-44E5-8390-F571F7C1D4E5\": 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eceeea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_results = pd.concat([summarize_performance([\"ms-diag_Llama2-MedTuned-13b_4bit_all_test_zero_shot_vanilla.pt\",\n",
    "                                                       \"ms-diag_Llama2-MedTuned-13b_4bit_all_test_zero_shot_instruction.pt\",\n",
    "                                                       \"ms-diag_Llama2-MedTuned-13b_4bit_all_test_few_shot_vanilla.pt\",\n",
    "                                                       \"ms-diag_Llama2-MedTuned-13b_4bit_all_test_few_shot_instruction.pt\",\n",
    "                                                       ], labels=\"label_encodings_Llama2-MedTuned-13b.pt\", load_line=False, load_outlines=False, label_correction=label_correction),\n",
    "                              summarize_performance([\"ms-diag_Llama2-MedTuned-13b_4bit_all_test_zero_shot_vanilla_rag.pt\",\n",
    "                                                      \"ms-diag_Llama2-MedTuned-13b_4bit_all_test_zero_shot_instruction_rag.pt\",\n",
    "                                                         \"ms-diag_Llama2-MedTuned-13b_4bit_all_test_few_shot_vanilla_rag.pt\",\n",
    "                                                         \"ms-diag_Llama2-MedTuned-13b_4bit_all_test_few_shot_instruction_rag.pt\",\n",
    "                                                         ], labels=\"label_encodings_Llama2-MedTuned-13b.pt\", load_line=False, load_outlines=False, label_correction=label_correction),\n",
    "                            summarize_performance([\"ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_zero_shot_vanilla.pt\",\n",
    "                                                       \"ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_zero_shot_instruction.pt\",\n",
    "                                                       \"ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_few_shot_vanilla.pt\",\n",
    "                                                       \"ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_few_shot_instruction.pt\",\n",
    "                                                       ], labels=\"label_encodings_Llama2-MedTuned-7b.pt\", load_line=False, load_outlines=True, label_correction=label_correction),\n",
    "                            summarize_performance([\"ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_zero_shot_vanilla_rag.pt\",\n",
    "                                                       \"ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_zero_shot_instruction_rag.pt\",\n",
    "                                                       \"ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_few_shot_vanilla_rag.pt\",\n",
    "                                                       \"ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_few_shot_instruction_rag.pt\",\n",
    "                                                       ], labels=\"label_encodings_Llama2-MedTuned-13b.pt\", load_line=False, load_outlines=True, label_correction=label_correction)], ignore_index=True)\n",
    "overall_results[\"approach\"] = [\"base\"] * 4 + [\"rag\"] * 4 + [\"outlines\"] * 4 + [\"outlines_rag\"] * 4\n",
    "overall_results.rename(columns={\"macro avg.f1-score\": \"Macro F1-Score\",\n",
    "                                \"macro avg.precision\": \"Macro Precision\",\n",
    "                                \"macro avg.recall\": \"Macro Recall\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d201b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_latex_table(overall_results, \n",
    "                           caption=\"Macro Precision, Recall and F1-Score for different prompting strategies using Llama2-MedTuned-13B \\cite{rohanian2023exploring}\",\n",
    "                           label=\"tab:ms-diag-13B\",\n",
    "                           metrics=[\"Macro Precision\", \"Macro Recall\", \"Macro F1-Score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dda209",
   "metadata": {},
   "source": [
    "## Valid Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0de92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_results[['approach', 'strategy', 'valid_label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea678c",
   "metadata": {},
   "source": [
    "# Llama 7B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64df55f",
   "metadata": {},
   "source": [
    "## Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccfdfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "summarize_performance([\"ms-diag_Llama2-MedTuned-7b_4bit_all_test_zero_shot_vanilla.pt\",\n",
    "                       \"ms-diag_Llama2-MedTuned-7b_4bit_all_test_zero_shot_instruction.pt\",\n",
    "                       \"ms-diag_Llama2-MedTuned-7b_4bit_all_test_few_shot_vanilla.pt\",\n",
    "                       \"ms-diag_Llama2-MedTuned-7b_4bit_all_test_few_shot_instruction.pt\",\n",
    "                       ], labels=\"label_encodings_Llama2-MedTuned-7b.pt\", load_line=False, load_outlines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00a6326",
   "metadata": {},
   "source": [
    "## Outlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "summarize_performance([\"ms-diag_outlines_Llama2-MedTuned-7b_4bit_all_test_zero_shot_vanilla.pt\",\n",
    "                       \"ms-diag_outlines_Llama2-MedTuned-7b_4bit_all_test_zero_shot_instruction.pt\",\n",
    "                       \"ms-diag_outlines_Llama2-MedTuned-7b_4bit_all_test_few_shot_vanilla.pt\",\n",
    "                       \"ms-diag_outlines_Llama2-MedTuned-7b_4bit_all_test_few_shot_instruction.pt\",\n",
    "                       ], labels=\"label_encodings_Llama2-MedTuned-7b.pt\", load_line=False, load_outlines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef6c7c0",
   "metadata": {},
   "source": [
    "## RAG + Outlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20749616",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_performance([\"ms-diag_outlines_Llama2-MedTuned-7b_4bit_all_test_zero_shot_vanilla_rag.pt\",\n",
    "                          \"ms-diag_outlines_Llama2-MedTuned-7b_4bit_all_test_zero_shot_instruction_rag.pt\",\n",
    "                          \"ms-diag_outlines_Llama2-MedTuned-7b_4bit_all_test_few_shot_vanilla_rag.pt\",\n",
    "                          \"ms-diag_outlines_Llama2-MedTuned-7b_4bit_all_test_few_shot_instruction_rag.pt\",\n",
    "                          ], labels=\"label_encodings_Llama2-MedTuned-7b.pt\", load_line=False, load_outlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652b0b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_results = pd.concat([summarize_performance([\"ms-diag_Llama2-MedTuned-7b_4bit_all_test_zero_shot_vanilla.pt\",\n",
    "                            \"ms-diag_Llama2-MedTuned-7b_4bit_all_test_zero_shot_instruction.pt\",\n",
    "                            \"ms-diag_Llama2-MedTuned-7b_4bit_all_test_few_shot_vanilla.pt\",\n",
    "                            \"ms-diag_Llama2-MedTuned-7b_4bit_all_test_few_shot_instruction.pt\",\n",
    "                            ], labels=\"label_encodings_Llama2-MedTuned-7b.pt\", load_line=False, load_outlines=False, label_correction=label_correction),\n",
    "                                 summarize_performance([\"ms-diag_Llama2-MedTuned-7b_4bit_all_test_zero_shot_vanilla_rag.pt\",\n",
    "                            \"ms-diag_Llama2-MedTuned-7b_4bit_all_test_zero_shot_instruction_rag.pt\",\n",
    "                            \"ms-diag_Llama2-MedTuned-7b_4bit_all_test_few_shot_vanilla_rag.pt\",\n",
    "                            \"ms-diag_Llama2-MedTuned-7b_4bit_all_test_few_shot_instruction_rag.pt\",\n",
    "                            ], labels=\"label_encodings_Llama2-MedTuned-7b.pt\", load_line=False, load_outlines=False, label_correction=label_correction),\n",
    "                                 summarize_performance([\"ms-diag_outlines_Llama2-MedTuned-7b_4bit_all_test_zero_shot_vanilla.pt\",\n",
    "                            \"ms-diag_outlines_Llama2-MedTuned-7b_4bit_all_test_zero_shot_instruction.pt\",\n",
    "                            \"ms-diag_outlines_Llama2-MedTuned-7b_4bit_all_test_few_shot_vanilla.pt\",\n",
    "                            \"ms-diag_outlines_Llama2-MedTuned-7b_4bit_all_test_few_shot_instruction.pt\",\n",
    "                            ], labels=\"label_encodings_Llama2-MedTuned-7b.pt\", load_line=False, load_outlines=True, label_correction=label_correction),\n",
    "                                 summarize_performance([\"ms-diag_outlines_Llama2-MedTuned-7b_4bit_all_test_zero_shot_vanilla_rag.pt\",\n",
    "                            \"ms-diag_outlines_Llama2-MedTuned-7b_4bit_all_test_zero_shot_instruction_rag.pt\",\n",
    "                            \"ms-diag_outlines_Llama2-MedTuned-7b_4bit_all_test_few_shot_vanilla_rag.pt\",\n",
    "                            \"ms-diag_outlines_Llama2-MedTuned-7b_4bit_all_test_few_shot_instruction_rag.pt\",\n",
    "                            ], labels=\"label_encodings_Llama2-MedTuned-7b.pt\", load_line=False, load_outlines=True, label_correction=label_correction)])\n",
    "overall_results[\"approach\"] = [\"base\"] * 4 + [\"rag\"] * 4 + [\"outlines\"] * 4 + [\"outlines_rag\"] * 4\n",
    "overall_results.rename(columns={\"macro avg.f1-score\": \"Macro F1-Score\",\n",
    "                                \"macro avg.precision\": \"Macro Precision\",\n",
    "                                \"macro avg.recall\": \"Macro Recall\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24db0fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_latex_table(overall_results, \n",
    "                           caption=\"Macro Precision, Recall and F1-Score for different prompting strategies using Llama2-MedTuned-13B \\cite{rohanian2023exploring}\",\n",
    "                           label=\"tab:ms-diag-13B\",\n",
    "                           metrics=[\"Macro Precision\", \"Macro Recall\", \"Macro F1-Score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aceccdc",
   "metadata": {},
   "source": [
    "## Valid Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ee8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_results[['approach', 'strategy', 'valid_label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb771a4",
   "metadata": {},
   "source": [
    "# Comparison with Old Approach (no other class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ecc896",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fso = torch.load(paths.RESULTS_PATH/\"ms-diag/ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_few_shot_instruction.pt\")\n",
    "other_idx = other_idx = [i for i, label in enumerate(results_fso[\"labels\"]) if label == 3]\n",
    "\n",
    "results_fso_no = {}\n",
    "for key in results_fso.keys():\n",
    "    results_fso_no[key] = [value for i, value in enumerate(results_fso[key]) if i not in other_idx]\n",
    "\n",
    "torch.save(results_fso_no, paths.RESULTS_PATH/\"ms-diag/ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_few_shot_instruction_no.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c67e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fsos2a = torch.load(paths.RESULTS_PATH/\"ms-diag/ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_few_shot_instruction_rag.pt\")\n",
    "other_idx = other_idx = [i for i, label in enumerate(results_fsos2a[\"labels\"]) if label == 3]\n",
    "\n",
    "results_fsos2a_no = {}\n",
    "for key in results_fsos2a.keys():\n",
    "    results_fsos2a_no[key] = [value for i, value in enumerate(results_fsos2a[key]) if i not in other_idx]\n",
    "\n",
    "torch.save(results_fsos2a_no, paths.RESULTS_PATH/\"ms-diag/ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_few_shot_instruction_rag_no.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ddad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_no = summarize_performance([\"ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_few_shot_instruction_no.pt\",\n",
    "                                    \"ms-diag_outlines_Llama2-MedTuned-13b_4bit_all_test_few_shot_instruction_rag_no.pt\"], labels=\"label_encodings_Llama2-MedTuned-13b.pt\", load_line=False, load_outlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73696af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in [\"precision\", \"recall\", \"f1\"]:\n",
    "    cols = [col for col in summary_no.columns if metric in col and not col.startswith(\"3.\")][:3]\n",
    "    # Row mean\n",
    "    summary = pd.DataFrame(summary_no[cols].mean(axis=1).round(2), columns = [metric])\n",
    "    summary[\"strategy\"] = [\"FSI Outlines\", \"FSI Outlines + S2A\"]\n",
    "    display(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
