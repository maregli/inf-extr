{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polars import\n",
    "# Import the data\n",
    "def load_line_labelling():\n",
    "    \"\"\"Loading the data from the nested csv files in the different \"imported_time\" directories. Labelled reports have a \"rev.csv\" ending.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pl.DataFrame(\n",
    "    \n",
    "    )\n",
    "\n",
    "    for root, dirs, files in os.walk(paths.DATA_PATH_LABELLED):\n",
    "        for file in files:\n",
    "            # Get the research id from filename\n",
    "            rid = file.split(\"_\")[0]\n",
    "            \n",
    "            if (file.endswith(\"rev.csv\") and \"mri\" not in file):\n",
    "                # Create a dataframe from the csv file\n",
    "                _df = pl.read_csv(os.path.join(root, file))\n",
    "                \n",
    "                # Add the rid to the dataframe\n",
    "                _df = _df.select(\n",
    "                    pl.col(\"text\").alias(\"text\"),\n",
    "                    pl.col(\"class\").alias(\"class\"),\n",
    "                    pl.lit(rid).alias(\"rid\"),\n",
    "                )\n",
    "                # Append the dataframe to the main dataframe\n",
    "                try: \n",
    "                    df = df.vstack(_df)\n",
    "                except:\n",
    "                    print(\"Error with file: \", file)\n",
    "                    print(\"df head: \", df.head(5))\n",
    "                    print(\"_df head: \", _df.head(5))\n",
    "                    continue\n",
    "    return df\n",
    "\n",
    "def clean_line_text(df: pl.DataFrame):\n",
    "    \"\"\"Cleans the dataframe from the load_line_labelling function. \n",
    "    Text is cleaned by:\n",
    "    1) Removes whitespace from beginning and end of text\n",
    "    2) removes double spaces,\n",
    "    3) remove empty lines and lines starting with \"·\" or \"··\".\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): Input dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"text\").map_elements(lambda s: s.strip())\n",
    "        .map_elements(lambda s: s.replace(\"  \", \" \"))\n",
    "        .map_elements(lambda s: s.replace(\"·\", \"\"))\n",
    "        .map_elements(lambda s: s.replace(\"··\", \"\"))\n",
    "        ).filter(pl.col(\"text\").is_not_null())\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_line_class(df: pl.DataFrame):\n",
    "    \"\"\"Cleans the dataframe labels in \"class\".\n",
    "    1) Removes whitespace from beginning and end of text\n",
    "    2) Correct spelling mistakes\n",
    "    3) Exclude classes that are not part of the original approach\n",
    "    4) Create a new column \"class_agg\" with the aggregated classes of the original approach.\n",
    "    5) OneHotEncode the \"class_agg\" column\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): Input dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Class mapping spelling mistakes\n",
    "    class_mapping_spelling = {\n",
    "        'memds': 'medms',\n",
    "    }\n",
    "\n",
    "    # Classes of original approach abbreviation\n",
    "    classes_orig = [\"dm\", \"do\", \"cu\", \"his\", \"sym\", \"so\", \"mr\", \"labr\", \"labo\", \"medms\", \"medo\", \"tr\", \"head\", \"unk\"]\n",
    "\n",
    "    \n",
    "    \n",
    "    # Class mapping of original approach\n",
    "    class_mapping_agg = {\n",
    "        'his': 'his_sym_cu',\n",
    "        'sym': 'his_sym_cu',\n",
    "        'cu': 'his_sym_cu',\n",
    "        'labr': 'labr_labo',\n",
    "        'labo': 'labr_labo',\n",
    "        'to': 'to_tr',\n",
    "        'tr': 'to_tr',\n",
    "        'medo': 'medo_unk_do_so',\n",
    "        'unk': 'medo_unk_do_so',\n",
    "        'do': 'medo_unk_do_so',\n",
    "        'so': 'medo_unk_do_so',\n",
    "    }\n",
    "\n",
    "    # Cleaning the class column\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"class\").map_elements(lambda s: s.strip())\n",
    "        .map_elements(lambda s: class_mapping_spelling.get(s, s))\n",
    "        .map_elements(lambda s: s if s in classes_orig else None)\n",
    "    )\n",
    "\n",
    "\n",
    "    # Creating a new column with the aggregated classes\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"class\").map_elements(lambda s: class_mapping_agg.get(s, s))\n",
    "        .alias(\"class_agg\"),\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "# Cleaning Text\n",
    "def clean_line_text(df: pd.DataFrame):\n",
    "    \"\"\"Cleans the dataframe from the load_line_labelling function. \n",
    "    Text is cleaned by:\n",
    "    1) Removes whitespace from beginning and end of text\n",
    "    2) removes double spaces,\n",
    "    3) remove empty lines and lines starting with \"·\" or \"··\".\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df = (\n",
    "        df\n",
    "        .fillna(\"\")\n",
    "        .assign(text=lambda d: d[\"text\"].str.strip()\n",
    "                                        .str.replace(\"  \", \" \")\n",
    "                                        .str.replace(\"·\", \"\")\n",
    "                                        .str.replace(\"··\", \"\"))\n",
    "        \n",
    "\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in train, validation and test\n",
    "train_val_texts, test_texts, train_val_labels, test_labels = train_test_split(df['text'], df['class_agg'], test_size=0.2, random_state=42, shuffle=True)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_val_texts, train_val_labels, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_data, train_val_labels = train_test_split(df.drop(\"class_agg\"), df, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989cff94439f44609418847651ba76cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873d1b357eed4d8d923e4547adfbe2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/305 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aec5dfe642c41f1824a1aae06357038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/381 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0eea73873a046febe8193fe7c3de3de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f707dd16dd514cd187d6eba6f04acd47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/305 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f578af51a9746bca48dfbabb2211361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/381 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create huggingface dataset\n",
    "train_dataset = Dataset.from_dict({\"text\": train_texts, \"label\": train_labels})\n",
    "val_dataset = Dataset.from_dict({\"text\": val_texts, \"label\": val_labels})\n",
    "test_dataset = Dataset.from_dict({\"text\": test_texts, \"label\": test_labels})\n",
    "\n",
    "# Concatenate into one dataset\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "# OneHotEncode the labels with ClassLabel\n",
    "dataset = dataset.class_encode_column(\"label\")\n",
    "\n",
    "# Save the dataset\n",
    "dataset.save_to_disk(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line_labelling_clean_dataset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant columns\n",
    "text_cleaned = text[[\"research_id\", \"diagnosis_date\", \"diagnosis_label\"]].rename(columns={\"research_id\": \"rid\", \"diagnosis_date\": \"date\", \"diagnosis_label\": \"text\"})\n",
    "\n",
    "# Date column to YYYY-MM-DD format with default 2023-01-01 then set latest date per rid if date is missing\n",
    "text_cleaned[\"date\"] = text_cleaned[\"date\"].apply(lambda x: parser.parse(str(x), default=datetime.datetime(2023, 1, 1)).strftime(\"%Y-%m-%d\") if pd.notna(x) else x)\n",
    "text_cleaned['date'] = pd.to_datetime(text_cleaned['date'])\n",
    "text_cleaned['date'] = text_cleaned.groupby('rid')['date'].transform(lambda x: x.fillna(x.max()))\n",
    "\n",
    "# Extract longest text per rid\n",
    "text_cleaned = text_cleaned.groupby(\"rid\").apply(lambda x: x.loc[x['text'].str.len().idxmax()]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution:\n",
      "disease\n",
      "relapsing_remitting_multiple_sclerosis      286\n",
      "secondary_progressive_multiple_sclerosis     28\n",
      "primary_progressive_multiple_sclerosis       21\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Unique patient IDs:  328\n",
      "Duplicate patient IDs:  7\n"
     ]
    }
   ],
   "source": [
    "map_dict = {\n",
    "    \"Schubförmig remittierende Multiple Sklerose (RRMS)\": \"relapsing_remitting_multiple_sclerosis\",\n",
    "    \"Schubförmig remittierende Multiple Sklerose\": \"relapsing_remitting_multiple_sclerosis\",\n",
    "    \"Schubförmig remittierende Multiple Sklerose \": \"relapsing_remitting_multiple_sclerosis\",\n",
    "    \"Multiple Sklerose mit V.a. sekundär chronisch-progredienten Verlauf\": \"secondary_progressive_multiple_sclerosis\",\n",
    "    \"Multiple Sklerose a.e. primär progredient\": \"primary_progressive_multiple_sclerosis\",\n",
    "    \"Multiple Sklerose mit a.e. primär-progredientem Verlauf\": \"primary_progressive_multiple_sclerosis\",\n",
    "}\n",
    "\n",
    "label_list = [\"relapsing_remitting_multiple_sclerosis\", \"secondary_progressive_multiple_sclerosis\", \"primary_progressive_multiple_sclerosis\"]\n",
    "\n",
    "labels_cleaned = labels.replace(map_dict)\n",
    "labels_cleaned = labels_cleaned[labels_cleaned[\"disease\"].isin(label_list)]\n",
    "print(\"Label distribution:\")\n",
    "print(labels_cleaned[\"disease\"].value_counts(), \"\\n\")\n",
    "print(\"Unique patient IDs: \", len(labels_cleaned['research_id'].unique()))\n",
    "print(\"Duplicate patient IDs: \", len(labels_cleaned['research_id']) - len(labels_cleaned['research_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date column to YYYY-MM-DD format with default 2023-01-01\n",
    "labels_cleaned[\"diagnosis_date\"] = labels_cleaned[\"diagnosis_date\"].apply(lambda x: parser.parse(x, default=datetime.datetime(2023, 1, 1)).strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with non-confirmed diagnosis\n",
    "labels_cleaned = labels_cleaned[labels_cleaned[\"diagnosis_reliability\"] == \"confirmed\"]\n",
    "# Keep only date, rid and disease and rename columns\n",
    "labels_cleaned = labels_cleaned[[\"research_id\", \"diagnosis_date\", \"disease\", \"diagnosis_reliability\"]].rename(columns={\"research_id\": \"rid\", \"diagnosis_date\": \"date\", \"disease\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples Patients with multiple labels:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>diagnosis_reliability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [rid, date, label, diagnosis_reliability]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of cleaned dataset: \n",
      "\n",
      "        rid date label diagnosis_reliability\n",
      "count   260  260   260                   260\n",
      "unique  260  149     3                     1 \n",
      "\n",
      "shape:  (260, 4) \n",
      "\n",
      "label distribution: \n",
      " label\n",
      "relapsing_remitting_multiple_sclerosis      228\n",
      "secondary_progressive_multiple_sclerosis     17\n",
      "primary_progressive_multiple_sclerosis       15\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "missing: \n",
      " rid                      0\n",
      "date                     0\n",
      "label                    0\n",
      "diagnosis_reliability    0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the entries for the patients with multiple labels\n",
    "print(\"Examples Patients with multiple labels:\")\n",
    "display((labels_cleaned[labels_cleaned[\"rid\"].duplicated(keep=False)].sort_values(by=[\"rid\", \"date\"])))\n",
    "\n",
    "print(\"Summary of cleaned dataset: \\n\")\n",
    "print(labels_cleaned.describe().iloc[:2], \"\\n\")\n",
    "print(\"shape: \", labels_cleaned.shape, \"\\n\")\n",
    "print(\"label distribution: \\n\", labels_cleaned[\"label\"].value_counts(), \"\\n\")\n",
    "print(\"missing: \\n\", labels_cleaned.isna().sum(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd()+\"/../..\")\n",
    "from src import paths\n",
    "a = [\"bla\", \"blub\", \"blabla\"]\n",
    "# Save as csv\n",
    "pd.Series(a).to_csv(paths.RESULTS_PATH/\"test.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf-extr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
