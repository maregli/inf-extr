{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd()+\"/../..\")\n",
    "from src import paths\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the test rids\n",
    "test_rids = pd.read_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"ms-diag/test_rids.txt\"), header=None).values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nan values in text: 2\n"
     ]
    }
   ],
   "source": [
    "# Kisim diagnoses\n",
    "kisim_diagnoses = pd.read_csv(os.path.join(paths.DATA_PATH_SEANTIS, \"kisim_diagnoses.csv\")).rename(columns={\"diagnosis_label\": \"text\"})\n",
    "\n",
    "# Some text will be doubled in dataset as doctors just append, and there is now way to know from this data what text belongs to what.\n",
    "# LastUpdateDateTime is shared with first part of diagnosis id and then the second part is the indicator of the individual texts so 4085680|1 for example\n",
    "\n",
    "def filter_duplicate_entries(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    As text is sometimes just appended to a report, we need to find reports that start the same way and only keep the most recent/longest one.\n",
    "    Per default, this function considers the first 100 characters of the text as criteria for filtering.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFra me): The dataframe to filter. Must contain a column \"text\", \"research_id\" and \"LastUpdateDateTime\"\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The filtered dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by LastUpdateDateTime\n",
    "    df = df.sort_values(\"LastUpdateDateTime\", ascending=False)\n",
    "\n",
    "    # Group by research_id and text_start\n",
    "    text_start = df[\"text\"].apply(lambda x: x[:100] if len(x) > 100 else x)\n",
    "    grouped = df.groupby([\"research_id\", text_start]).head(1)\n",
    "\n",
    "    return grouped\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses the text by removing empty lines and adding 'INDENT' to lines starting with '-', '·', '··', and removing '·'\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to preprocess\n",
    "\n",
    "    Returns:\n",
    "        str: The preprocessed text\n",
    "    \"\"\"\n",
    "\n",
    "    text = text.split(\"\\n\")\n",
    "\n",
    "    # Remove empty strings and whitespace-only strings\n",
    "    try:\n",
    "        lines = [str(item) for item in text if not (not item or item.isspace())]\n",
    "\n",
    "    except:\n",
    "        print(text)\n",
    "    \n",
    "    # Add 'INDENT' to lines starting with '-', '·', '··', and remove '·'\n",
    "    lines = ['INDENT ' + item.replace('·', '') if item.startswith(('-', '·', '··')) else item for item in lines]\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def preprocess_df(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocesses the dataframe by removing nan values and filtering duplicate entries.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe to preprocess\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The preprocessed dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of nan values in text\n",
    "    print(f\"Number of nan values in text: {df['text'].isna().sum()}\")\n",
    "    df.dropna(subset=[\"text\"], inplace=True)\n",
    "\n",
    "    df = filter_duplicate_entries(df)\n",
    "\n",
    "    df[\"text\"] = df[\"text\"].apply(preprocess_text)\n",
    "\n",
    "    return df\n",
    "\n",
    "kisim_diagnoses = preprocess_df(kisim_diagnoses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove test entries\n",
    "from src.utils import load_ms_data\n",
    "\n",
    "test_data = load_ms_data(\"all\")[\"test\"]\n",
    "kisim_diagnoses = kisim_diagnoses[~kisim_diagnoses[\"text\"].isin(test_data[\"text\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nan values in text: 14\n"
     ]
    }
   ],
   "source": [
    "# Reports kisim diagnoses also contains more texts\n",
    "kisim_reports_diagnoses = pd.read_csv(os.path.join(paths.DATA_PATH_RSD, \"reports_kisim_diagnoses.csv\")).rename(columns={\"diagnosis_label\": \"text\"})\n",
    "kisim_reports_diagnoses = preprocess_df(kisim_reports_diagnoses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136cd0d5192a4ccd841a52c57d39b3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/41409 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine the two datasets\n",
    "df_all = pd.concat([kisim_diagnoses, kisim_reports_diagnoses], axis=0)\n",
    "\n",
    "# Drop double diagnoses ids\n",
    "df_all.drop_duplicates(subset=\"diagnosis_id\", inplace=True)\n",
    "\n",
    "# Save the combined dataset\n",
    "os.makedirs(paths.DATA_PATH_PREPROCESSED/\"text-finetune\", exist_ok=True)\n",
    "df_all.to_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"text-finetune/kisim_diagnoses_combined.csv\"), index=False)\n",
    "\n",
    "# Huggingface\n",
    "df = Dataset.from_dict({\"text\": df_all[\"text\"]})\n",
    "df.save_to_disk(os.path.join(paths.DATA_PATH_PREPROCESSED, \"text-finetune/kisim_diagnoses\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4582c9f631a4b5c8f49441489eabd34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/41409 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of tokens\n",
    "df = Dataset.load_from_disk(os.path.join(paths.DATA_PATH_PREPROCESSED, \"text-finetune/kisim_diagnoses\"))\n",
    "\n",
    "# tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(paths.MODEL_PATH/\"Llama2-MedTuned-13b\")\n",
    "\n",
    "def tokenize(example):\n",
    "    example = tokenizer(example[\"text\"], \n",
    "                        add_special_tokens=False)\n",
    "    return example\n",
    "    \n",
    "\n",
    "df_tokenized = df.map(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training tokens:  4870424\n",
      "Number of reports:  41409\n"
     ]
    }
   ],
   "source": [
    "# Number of tokens\n",
    "num_tokens = [len(input) for input in df_tokenized[\"input_ids\"]]\n",
    "print(\"Number of training tokens: \", sum(num_tokens))\n",
    "print(\"Number of reports: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_loss_and_lr(data):\n",
    "    epochs = [entry['epoch'] for entry in data]\n",
    "    loss_values = [entry['loss'] for entry in data]\n",
    "    lr_values = [entry['learning_rate'] for entry in data]\n",
    "\n",
    "    # Create subplots\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # Plot loss on primary y-axis\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss', color=color)\n",
    "    ax1.plot(epochs, loss_values, color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    # Create secondary y-axis for learning rate\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('Learning Rate', color=color)\n",
    "    ax2.plot(epochs, lr_values, color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    # Add grid\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Title and display\n",
    "    plt.title('Loss and Learning Rate Over Time')\n",
    "    plt.show()\n",
    "\n",
    "# plot_loss_and_lr(trainer.state.log_history[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79                                                                                                                                                                    INDENT Toviaz 8mg/d (St.n. Spasmo-Urgenin, Neo und Emselex)\n",
       "80                                                                                                                                                      INDENT Fampyra aufgrund von Nebenwirkungen abgesetzt (vermehrt Schwindel)\n",
       "87                                                                                                                                                                                                 therapeutisch: aktuell nihil  \n",
       "108                                                                                                                                                     anamnestisch: Patient kommt zur Baseline-Untersuchung vor Rituximab-Gabe.\n",
       "117                                                                                                                                                                                                                   Prozedere: \n",
       "                                                                                                                  ...                                                                                                            \n",
       "850                                                                                                                                                                             INDENT Bakterieller Harnwegsinfekt, ED 11.02.2020\n",
       "851                                                                                                                                           INDENT Stomatitis aphthosa mit schmerzhafter Aphthe an Zungenspitze seit 06.03.2020\n",
       "852                                                                                                                                                                                      INDENT Re-Soor-Stomatitis, ED 11.03.2020\n",
       "853                                                                                                                                                                                             Re-Soor-Stomatitis, ED 10.04.2020\n",
       "857    INDENT Anamnestisch: Im Januar 2020 pelziges Gefühl und Taubheitsgefühl im rechten Bein, seit dem Kortisonstoss im Februar 2020 vollständig regredient; Keine Fatigue, keine Blasen-/Mastdarm-/Sexualfunktionsstörungensym\n",
       "Name: text, Length: 79, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils import load_line_label_data\n",
    "# Comparison medication kisim reports\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "line_labels = pd.DataFrame(load_line_label_data()[\"train\"])\n",
    "line_labels[line_labels[\"class_agg\"] == \"medms\"][\"text\"].iloc[10]\n",
    "# It seems that in reports they don't have dosis and when, but more like start date and what medication\n",
    "line_labels[line_labels[\"class_agg\"] == \"medo_unk_do_so\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 OP Medrol 32 mg \t1-0-0\n",
      "2 OP Keppra 500 mg\t3-0-3\n",
      "1 OP Urbanyl 10 mg \t0-0-0.5 noch für eine Woche\n",
      "1 OP Rivotril 0.5 mg\t1-1-0 noch für eine Woche, dann 1-1-1\n"
     ]
    }
   ],
   "source": [
    "# Medications\n",
    "kisim_medications = pd.read_csv(os.path.join(paths.DATA_PATH_SEANTIS, \"kisim_medication.csv\"))\n",
    "kisim_medications_text = kisim_medications[\"medication_name\"]\n",
    "print(kisim_medications_text.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>laterality</th>\n",
       "      <th>medication_discontinuation_reason_medication_adverse_event</th>\n",
       "      <th>medication_discontinuation_reason_medication_intolerance</th>\n",
       "      <th>medication_discontinuation_reason_medication_not_effective</th>\n",
       "      <th>medication_discontinuation_reason_medication_pregnancy</th>\n",
       "      <th>medication_discontinuation_reason_medication_remission</th>\n",
       "      <th>medication_discontinuation_reason_medication_surgery</th>\n",
       "      <th>medication_discontinuation_reason_other</th>\n",
       "      <th>medication_dose</th>\n",
       "      <th>medication_dose_afternoon</th>\n",
       "      <th>...</th>\n",
       "      <th>medication_frequency_weekday_saturday</th>\n",
       "      <th>medication_frequency_weekday_sunday</th>\n",
       "      <th>medication_frequency_weekday_thursday</th>\n",
       "      <th>medication_frequency_weekday_tuesday</th>\n",
       "      <th>medication_frequency_weekday_wednesday</th>\n",
       "      <th>medication_generic_drug</th>\n",
       "      <th>medication_id</th>\n",
       "      <th>medication_route</th>\n",
       "      <th>medication_start_date</th>\n",
       "      <th>research_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dimethyl_fumarate</td>\n",
       "      <td>152</td>\n",
       "      <td>oral</td>\n",
       "      <td>2014-10</td>\n",
       "      <td>1C6C1C33-D734-4396-A515-34303C971AA6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zulassung von Tecfidera</td>\n",
       "      <td>240.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dimethyl_fumarate</td>\n",
       "      <td>153</td>\n",
       "      <td>oral</td>\n",
       "      <td>2014-08</td>\n",
       "      <td>1C6C1C33-D734-4396-A515-34303C971AA6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stosstherapie</td>\n",
       "      <td>500.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>methylprednisolone</td>\n",
       "      <td>154</td>\n",
       "      <td>oral</td>\n",
       "      <td>2012-10-19</td>\n",
       "      <td>1C6C1C33-D734-4396-A515-34303C971AA6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>interferon_beta_1a</td>\n",
       "      <td>92</td>\n",
       "      <td>subcutaneous</td>\n",
       "      <td>2013-08-26</td>\n",
       "      <td>2F1E06F1-6A37-4D08-9D03-2E8624535775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stosstherapie</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>methylprednisolone</td>\n",
       "      <td>93</td>\n",
       "      <td>intravenous</td>\n",
       "      <td>2013-07-02</td>\n",
       "      <td>2F1E06F1-6A37-4D08-9D03-2E8624535775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  laterality medication_discontinuation_reason_medication_adverse_event  \\\n",
       "0        NaN                                                        NaN   \n",
       "1        NaN                                                        NaN   \n",
       "2        NaN                                                        NaN   \n",
       "3        NaN                                                        NaN   \n",
       "4        NaN                                                        NaN   \n",
       "\n",
       "  medication_discontinuation_reason_medication_intolerance  \\\n",
       "0                                                      NaN   \n",
       "1                                                      NaN   \n",
       "2                                                      NaN   \n",
       "3                                                      NaN   \n",
       "4                                                      NaN   \n",
       "\n",
       "  medication_discontinuation_reason_medication_not_effective  \\\n",
       "0                                                        NaN   \n",
       "1                                                        NaN   \n",
       "2                                                        NaN   \n",
       "3                                                        NaN   \n",
       "4                                                        NaN   \n",
       "\n",
       "  medication_discontinuation_reason_medication_pregnancy  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "\n",
       "  medication_discontinuation_reason_medication_remission  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "\n",
       "   medication_discontinuation_reason_medication_surgery  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "\n",
       "  medication_discontinuation_reason_other  medication_dose  \\\n",
       "0                                     NaN          240.000   \n",
       "1                 Zulassung von Tecfidera          240.000   \n",
       "2                           Stosstherapie          500.000   \n",
       "3                                     NaN            0.044   \n",
       "4                           Stosstherapie         1000.000   \n",
       "\n",
       "   medication_dose_afternoon  ... medication_frequency_weekday_saturday  \\\n",
       "0                        NaN  ...                                   NaN   \n",
       "1                        NaN  ...                                   NaN   \n",
       "2                        NaN  ...                                   NaN   \n",
       "3                        NaN  ...                                   NaN   \n",
       "4                        NaN  ...                                   NaN   \n",
       "\n",
       "   medication_frequency_weekday_sunday medication_frequency_weekday_thursday  \\\n",
       "0                                  NaN                                   NaN   \n",
       "1                                  NaN                                   NaN   \n",
       "2                                  NaN                                   NaN   \n",
       "3                                  NaN                                   NaN   \n",
       "4                                  NaN                                   NaN   \n",
       "\n",
       "   medication_frequency_weekday_tuesday  \\\n",
       "0                                   NaN   \n",
       "1                                   NaN   \n",
       "2                                   NaN   \n",
       "3                                   NaN   \n",
       "4                                   NaN   \n",
       "\n",
       "  medication_frequency_weekday_wednesday  medication_generic_drug  \\\n",
       "0                                    NaN        dimethyl_fumarate   \n",
       "1                                    NaN        dimethyl_fumarate   \n",
       "2                                    NaN       methylprednisolone   \n",
       "3                                   True       interferon_beta_1a   \n",
       "4                                    NaN       methylprednisolone   \n",
       "\n",
       "  medication_id  medication_route medication_start_date  \\\n",
       "0           152              oral               2014-10   \n",
       "1           153              oral               2014-08   \n",
       "2           154              oral            2012-10-19   \n",
       "3            92      subcutaneous            2013-08-26   \n",
       "4            93       intravenous            2013-07-02   \n",
       "\n",
       "                            research_id  \n",
       "0  1C6C1C33-D734-4396-A515-34303C971AA6  \n",
       "1  1C6C1C33-D734-4396-A515-34303C971AA6  \n",
       "2  1C6C1C33-D734-4396-A515-34303C971AA6  \n",
       "3  2F1E06F1-6A37-4D08-9D03-2E8624535775  \n",
       "4  2F1E06F1-6A37-4D08-9D03-2E8624535775  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# medications.csv not really helpful as of now\n",
    "medications = pd.read_csv(os.path.join(paths.DATA_PATH_SEANTIS, \"medications.csv\"))\n",
    "medications.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# I will adapt the code from original project, that also produced preprocessed data for previous tasks.\n",
    "# Then c\n",
    "\n",
    "def _get_diag_lines(diag):\n",
    "    \n",
    "    '''\n",
    "    get list of text lines for a kisim_diagnoses.csv 'diag_label' entry\n",
    "    \n",
    "    input:\n",
    "    - diag: str with text from one 'diag_label' entry\n",
    "    \n",
    "    ouptut:\n",
    "    - diag_lines: list of text lines\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    diag_lines = diag.splitlines()\n",
    "    diag_lines = [item for item in diag_lines if not (not item or item.isspace())]\n",
    "    diag_lines = ['INDENT ' + item.replace('·', '') if item.startswith(('-', '·', '··')) else item for item in diag_lines]\n",
    "    \n",
    "    return diag_lines\n",
    "\n",
    "\n",
    "def extract_longest_diag_per_rid(df, var_date, var_diag):\n",
    "    '''\n",
    "    function to extract longest lines of all diagnosis texts for each research id\n",
    "    \n",
    "    input:\n",
    "    - df: dataframe containing all information\n",
    "    - var_date: column name of date column\n",
    "    - var_diag: column name of diagnosis text column\n",
    "    \n",
    "    ouptut:\n",
    "    - dict_diags: dictionary of diagnosis text (key: research id-diag_index-date, value: list of text lines)   \n",
    "    '''\n",
    "    \n",
    "    dict_diags = dict()\n",
    "    list_vars = [var_date, var_diag]\n",
    "\n",
    "    for rid in df['research_id'].unique():\n",
    "\n",
    "        list_lines = list()\n",
    "        date = ''\n",
    "        _df = df[df['research_id'] == rid].sort_values([var_date])[list_vars]\n",
    "\n",
    "        for diag_index, row in _df.iterrows():\n",
    "\n",
    "            diag = row[var_diag]\n",
    "\n",
    "            if isinstance(diag, str):\n",
    "                \n",
    "                diag_lines = _get_diag_lines(diag)\n",
    "                \n",
    "                if len(diag_lines) >= len(list_lines):\n",
    "                    \n",
    "                    list_lines = diag_lines[:]\n",
    "                    date = str(row[var_date])[:11]\n",
    "                    \n",
    "        key = '_'.join((rid, str(diag_index), date))\n",
    "                \n",
    "        dict_diags[key] = list_lines\n",
    "\n",
    "    return dict_diags"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
