{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e927d5c-5913-48ef-a16e-6b0dfcca48ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd()+\"/../..\")\n",
    "from src import paths\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils import get_default_pydantic_model\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f3baf4-accd-4b0c-a245-f61d6d985586",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ec3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to fix broken JSON by searching for last \"}\" then adding \"]\"\n",
    "default_model = get_default_pydantic_model(\"medication\")\n",
    "def fix_json(json_str):\n",
    "    last_index = json_str.rfind(\"}\")\n",
    "    if last_index != -1:  # If \"},\" is found\n",
    "        fixed_json = json_str[:last_index + 1] + \"]}\"\n",
    "\n",
    "        return fixed_json\n",
    "    else:\n",
    "        # If \"},\" is not found, return the default_model\n",
    "        return default_model.model_dump_json()\n",
    "    \n",
    "# If all the values of morning, noon, evening, night are 0, then set them all to -99\n",
    "def check_and_replace(df, cols_to_check):\n",
    "    \"\"\"\n",
    "    Check if 4 specified columns in each row are all 0,\n",
    "    then replace those 4 columns with -99.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): Input DataFrame.\n",
    "        cols_to_check (list): List of column names to check.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with replacements.\n",
    "    \"\"\"\n",
    "    for index, row in df.iterrows():\n",
    "        if (row[cols_to_check] == 0).sum() >= 4:\n",
    "            df.loc[index, cols_to_check] = -99\n",
    "    return df\n",
    "\n",
    "def prepare_results(path: str)->pd.DataFrame:\n",
    "    results = torch.load(path)\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    # Fix model_answers wherever successful is False\n",
    "    _df_fixed = df[~df[\"successful\"]].apply(lambda row: fix_json(row[\"model_answers\"]), axis=1)\n",
    "    df_fixed = df.copy()\n",
    "    df_fixed.loc[~df[\"successful\"], \"model_answers\"] = _df_fixed\n",
    "\n",
    "    dfs = []\n",
    "    for idx, (answer, text) in enumerate(zip(df_fixed[\"model_answers\"], df_fixed[\"text\"])):\n",
    "        try:\n",
    "            answer = json.loads(answer)\n",
    "            medications = answer[\"medications\"]\n",
    "            for med in medications:\n",
    "                med[\"text\"] = text\n",
    "                med[\"id\"] = idx\n",
    "                dfs.append((med))\n",
    "        except:\n",
    "            print(f\"Error at index {idx}\")\n",
    "    res = pd.DataFrame(dfs)\n",
    "\n",
    "    # If all the values of morning, noon, evening, night are 0, then set them all to -99\n",
    "    res = check_and_replace(res, [\"morning\", \"noon\", \"evening\", \"night\"])\n",
    "\n",
    "    # Convert everything to string and lowercase\n",
    "    res = res.map(lambda x: str(x).lower())\n",
    "\n",
    "    # Remove .0+ from every string\n",
    "    expression = r\"\\.0+$\"\n",
    "    res = res.replace(expression, \"\", regex=True)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feaf290",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57c19ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(path: str)->pd.DataFrame:\n",
    "    labels = pd.read_excel(path) \n",
    "\n",
    "    # Convert everything to string and lowercase\n",
    "    labels = labels.map(lambda x: str(x).lower())\n",
    "\n",
    "    # Remove .0+ from every string\n",
    "    expression = r\"\\.0+$\"\n",
    "    labels = labels.replace(expression, \"\", regex=True)\n",
    "\n",
    "    return labels\n",
    "\n",
    "def calculate_precision_recall(ground_truth, predicted):\n",
    "    ground_truth = ground_truth.copy()\n",
    "    predicted = predicted.copy()\n",
    "    true_positives = {}\n",
    "    false_positives = {}\n",
    "    false_negatives = {}\n",
    "    \n",
    "    for pred in predicted:\n",
    "        pred_name = pred[\"name\"]\n",
    "        true_positives.setdefault(\"name\", 0)\n",
    "        matched = False\n",
    "        for i, truth in enumerate(ground_truth):\n",
    "            if truth[\"name\"] in pred_name or pred_name in truth[\"name\"]: # First we match the medication to the corresponding ground truth\n",
    "                matched = True\n",
    "                pred.pop(\"name\") # Remove name and put true positive\n",
    "                true_positives[\"name\"] += 1\n",
    "                for key in pred: # Then iterate over the keys and count the true positives and false positives\n",
    "                    if pred[key] == truth[key]:\n",
    "                        true_positives.setdefault(key, 0)\n",
    "                        true_positives[key] += 1\n",
    "                    else:\n",
    "                        # If there is no match it means that there is a ground truth without prediction (false negative) and a prediction without\n",
    "                        # ground truth (false positive)\n",
    "                        false_positives.setdefault(key, 0)\n",
    "                        false_positives[key] += 1\n",
    "                        false_negatives.setdefault(key, 0)\n",
    "                        false_negatives[key] += 1\n",
    "                        \n",
    "                del ground_truth[i]  # Remove the matched item\n",
    "                break  # Move to the next predicted item\n",
    "        \n",
    "        if not matched: # If there is no medication in the ground truth that matches, then it is a false positive for all keys\n",
    "            for key in pred:\n",
    "                false_positives.setdefault(key, 0)\n",
    "                false_positives[key] += 1\n",
    "    for truth in ground_truth:\n",
    "        for key in truth:\n",
    "            false_negatives.setdefault(key, 0)\n",
    "            false_negatives[key] += 1\n",
    "    \n",
    "    precision = {}\n",
    "    recall = {}\n",
    "    f1_score = {}\n",
    "\n",
    "    if len(predicted) == 0:\n",
    "        true_positives = {key: 0 for key in ground_truth[0].keys()}\n",
    "        false_positives = {key: 0 for key in ground_truth[0].keys()}\n",
    "\n",
    "    for key in relevant_columns:\n",
    "        # Precision: TP / (TP + FP)\n",
    "        precision[key] = true_positives.get(key, 0) / (true_positives.get(key, 0) + false_positives.get(key, 0) + 1e-10)\n",
    "\n",
    "        # Recall: TP / (TP + FN)\n",
    "        recall[key] = true_positives.get(key, 0) / (true_positives.get(key, 0) + false_negatives.get(key, 0) + 1e-10)\n",
    "\n",
    "        # F1 Score: 2 * (Precision * Recall) / (Precision + Recall)\n",
    "        f1_score[key] = 2 * (precision[key] * recall[key]) / (precision[key] + recall[key] + 1e-10)\n",
    "    \n",
    "    # Catch NA values in true_positives\n",
    "    \n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def evaluate_df(ground_truth: pd.DataFrame, predicted: pd.DataFrame, relevant_columns: list)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluates the predicted DataFrame against the ground truth DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        ground_truth (pandas.DataFrame): DataFrame with the ground truth.\n",
    "        predicted (pandas.DataFrame): DataFrame with the predicted values.\n",
    "        relevant_columns (list): List of relevant columns to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with the evaluated scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    evaluated = []\n",
    "    assert len(ground_truth.id.unique()) == len(predicted.id.unique()), \"The number of unique ids (texts) in the ground truth and predicted DataFrames do not match.\"\n",
    "\n",
    "    for idx in ground_truth.id.unique():\n",
    "        ground_truth_dict = ground_truth[ground_truth.id == idx][relevant_columns].to_dict(\"records\")\n",
    "        predicted_dict = predicted[predicted.id == idx][relevant_columns].to_dict(\"records\")\n",
    "\n",
    "        precision, recall, f1_score = calculate_precision_recall(ground_truth_dict, predicted_dict)\n",
    "\n",
    "        precision_dict = {f\"precision_{key}\": value for key, value in precision.items()}\n",
    "        recall_dict = {f\"recall_{key}\": value for key, value in recall.items()}\n",
    "        f1_score_dict = {f\"f1_score_{key}\": value for key, value in f1_score.items()}\n",
    "        \n",
    "        merged = {**precision_dict, **recall_dict, **f1_score_dict}\n",
    "        merged[\"text\"] = predicted[predicted.id == idx][\"text\"].values[0]\n",
    "        merged[\"id\"] = idx\n",
    "        evaluated.append(merged)\n",
    "\n",
    "    return pd.DataFrame(evaluated)\n",
    "\n",
    "def aggregate_scores(evaluated: pd.DataFrame, columns_to_drop: list = [\"id\", \"text\"])->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregates the metrics by averaging metrics over all unique texts. Also aggregates intake dosage metrics.\n",
    "\n",
    "    Parameters:\n",
    "        evaluated (pandas.DataFrame): DataFrame with the evaluated scores.\n",
    "        columns_to_drop (list): List of columns to drop. Default is [\"id\", \"text\"].\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with the aggregated scores.\n",
    "    \"\"\"\n",
    "    agg_df = evaluated.drop(columns=columns_to_drop).mean()\n",
    "    agg_df[\"precision_intake\"] = agg_df[[\"precision_morning\", \"precision_noon\", \"precision_evening\", \"precision_night\"]].mean()\n",
    "    agg_df[\"recall_intake\"] = agg_df[[\"recall_morning\", \"recall_noon\", \"recall_evening\", \"recall_night\"]].mean()\n",
    "    agg_df[\"f1_score_intake\"] = agg_df[[\"f1_score_morning\", \"f1_score_noon\", \"f1_score_evening\", \"f1_score_night\"]].mean()\n",
    "    agg_df.drop([\"precision_morning\", \"precision_noon\", \"precision_evening\", \"precision_night\", \"recall_morning\", \"recall_noon\", \"recall_evening\", \"recall_night\", \"f1_score_morning\", \"f1_score_noon\", \"f1_score_evening\", \"f1_score_night\"], inplace=True)\n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faca820",
   "metadata": {},
   "source": [
    "- True Positives (TP): Predicted and in ground truth.\n",
    "- False Positives (FP): Predicted but not in ground truth. So if a dose for a tp medication is predicted wrongly, or if a medication was predicted that is not in the ground truth (and thus also a dose was predicted that is not in the ground truth)\n",
    "- False Negatives (FN): Not predicted but in ground truth. Happens if a medication is not predicted (and thus also a dose not predicted for this) or if the wrong dose was predicted for the matched medication (entity predicted that is not in ground truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee16d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = prepare_labels(paths.RESULTS_PATH/\"medication/labels.xlsx\")\n",
    "\n",
    "res = prepare_results(paths.RESULTS_PATH/\"medication/medication_outlines_Llama2-MedTuned-13b_4bit_few_shot_instruction_examples_10.pt\")\n",
    "\n",
    "# Choose only the relevant columns\n",
    "relevant_columns = [\"name\", \"dose\", \"dose_unit\", \"morning\", \"noon\", \"evening\", \"night\"]\n",
    "\n",
    "evaluated = evaluate_df(labels, res, relevant_columns)\n",
    "\n",
    "agg_df = aggregate_scores(evaluated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bc75d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13879b0c-aff5-4d03-92b9-34b38179410d",
   "metadata": {},
   "source": [
    "# Examples for Thesis and Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220ae6e3-3cba-4f20-af8d-8d34f65b1a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spelling mistakes\n",
    "display(res[res[\"id\"] == \"40\"]) # also here very imprecise for dose unit , means 1g?\n",
    "display(res[res[\"id\"] == \"79\"]) # Schema for medrol 10-0-0, should be 1-0-0-0 probably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28660fd4-7fc5-48d2-b6b9-d354da3e1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spelling mistakes\n",
    "print(res[res[\"id\"] == \"40\"][res.columns[:-2]].to_dict(orient=\"records\")) # also here very imprecise for dose unit , means 1g?\n",
    "print(res[res[\"id\"] == \"79\"][res.columns[:-2]].to_dict(orient=\"records\")) # Schema for medrol 10-0-0, should be 1-0-0-0 probably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf56762-fc0f-43e6-907e-45a791a20a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difficulty in medication names, would have to be discussed with people interested in task\n",
    "display(res[res[\"id\"] == \"25\"].iloc[[-1]]) # Excipial U Lipolotion would be more precise but just uses excipial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b84bb6-cd1e-4aaa-acfa-c5e74f2c127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res[res[\"id\"] == \"25\"][res.columns[:-2]].to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e02630-9c3f-4cde-a587-5d79ed3ff69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example where I did a bad job\n",
    "display(res[res[\"id\"] == \"47\"]) # Split in dosis 800/160, but couldn't as restricted to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5cfd46-efb8-4523-ad93-e26e63e21fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res[res[\"id\"] == \"47\"][res.columns[:-2]].to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b0e9a-8f43-4c7e-ab90-93165fc4b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where model struggles (if info not given explicitly)\n",
    "display(res[res[\"id\"] == \"68\"]) # like mg here (I had to google as well)\n",
    "display(res[res[\"id\"] == \"77\"]) # 2h vor schlafengehen means night/evening. But model didn't see any schema I \n",
    "display(res[res[\"id\"] == \"87\"]) # For us clear that lioresal is meant for everything, but model struggles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f1b49-6705-46a5-9f60-d16923275fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res[res[\"id\"] == \"68\"][res.columns[:-2]].to_dict(orient=\"records\"))\n",
    "print(res[res[\"id\"] == \"77\"][res.columns[:-2]].to_dict(orient=\"records\"))\n",
    "print(res[res[\"id\"] == \"87\"][res.columns[:-2]].to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd9672f-e5c3-4ef3-9a51-62e01ce77b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for model hallucination (Avanex is insurance not medication)\n",
    "display(res[res[\"id\"] == \"78\"].iloc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe6932b-e8c9-4722-93c3-b8249413d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res[res[\"id\"] == \"78\"][res.columns[:-2]].to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc671de0-8053-4f97-ba37-9848a3447e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example where LLM excels (compared to rule-based)\n",
    "\n",
    "display(res[res[\"id\"] == \"48\"]) # 3x3 täglich\n",
    "display(res[res[\"id\"] == \"60\"]) # 1 tbl. täglich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da06fe1-8778-4955-8770-fb2d11ea0480",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res[res[\"id\"] == \"0\"][res.columns[:-2]].to_dict(orient=\"records\"))\n",
    "print(res[res[\"id\"] == \"48\"][res.columns[:-2]].to_dict(orient=\"records\"))\n",
    "print(res[res[\"id\"] == \"60\"][res.columns[:-2]].to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be42275c-44ab-49ac-b477-ba952d653a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = pd.concat([\n",
    "    res[res[\"id\"] == \"0\"],\n",
    "           res[res[\"id\"] == \"48\"],\n",
    "           res[res[\"id\"] == \"60\"],\n",
    "        res[res[\"id\"] == \"40\"],\n",
    "           res[res[\"id\"] == \"79\"],\n",
    "          res[res[\"id\"] == \"25\"].iloc[[-1]],\n",
    "          res[res[\"id\"] == \"47\"],\n",
    "           res[res[\"id\"] == \"68\"],\n",
    "           res[res[\"id\"] == \"77\"],\n",
    "           res[res[\"id\"] == \"87\"],\n",
    "           res[res[\"id\"] == \"78\"],\n",
    "          ], axis = 0)\n",
    "examples.to_csv(paths.THESIS_PATH/\"presentation_examples.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b4c61a-6143-48a4-9e43-ac608670d457",
   "metadata": {},
   "source": [
    "Problems in input:\n",
    "- Some inputs are structured with one line per medication e.g. df[\"text\"][0], others are medical recipes like df[\"text\"][38]. The model struggles a bit sometimes with inputs that are not as well structured (but still really good)\n",
    "- The problem above seems to be solvable by providing appropriate examples but I don't know if I get all the different input formats.\n",
    "- Sometimes medications are misspelled (like Propanolol) and model extracts it the way it was (which is the desired behaviour I think, because I don't have the medical expertise to correct it). Unsure what the best way to correct it is.\n",
    "- A lot of times the schema for intake changes, so after 2 weeks maybe it is less or more. Additionally extracting this in detail could be very hard and might negatively affect the performance of the other outputs (which seem more important to me, but I am no doctor). This is also only the case for a few of the examples as far as I can tell.\n",
    "- If the text just mentions \"once daily\" or similar I told the model to map it all in the morning (so once daily is 1-0-0) but not sure if that would be desired behaviour.\n",
    "- How would I evaluate the performance (spelling mistakes, forget medicine etc.). I could evaluate a test set myself (100 examples) but I can't guarantee that the criteria I set would be reasonable from a medical point of view."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b8613-eb88-40b9-84d5-6de4e18049c7",
   "metadata": {},
   "source": [
    "# Results 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d897d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama 13B\n",
    "results_13b = []\n",
    "filenames13b = [filename for filename in os.listdir(paths.RESULTS_PATH/\"medication\") if filename.startswith(\"medication_outlines_Llama2-MedTuned-13b\")]\n",
    "for filename in filenames13b:\n",
    "    res = prepare_results(paths.RESULTS_PATH/\"medication\"/filename)\n",
    "    evaluated = evaluate_df(labels, res, relevant_columns)\n",
    "    agg_df = aggregate_scores(evaluated)\n",
    "    results_13b.append(agg_df)\n",
    "results_13b = pd.concat(results_13b, axis=1).round(2)\n",
    "results_13b.columns = [filename.split(\"4bit_\")[1] for filename in filenames13b]\n",
    "\n",
    "# Reorder rows\n",
    "results_13b = results_13b.reindex([\"precision_name\", \"precision_dose\", \"precision_dose_unit\", \"precision_intake\", \"recall_name\", \"recall_dose\", \"recall_dose_unit\", \"recall_intake\", \"f1_score_name\", \"f1_score_dose\", \"f1_score_dose_unit\", \"f1_score_intake\"]).transpose()\n",
    "results_13b.to_csv(paths.THESIS_PATH/\"medication_results_13b.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e3bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_13b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f25101-90f3-4c0d-bc49-9c0283e03055",
   "metadata": {},
   "source": [
    "# Results 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab1452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama 7B\n",
    "results_7b = []\n",
    "filenames7b = [filename for filename in os.listdir(paths.RESULTS_PATH/\"medication\") if filename.startswith(\"medication_outlines_Llama2-MedTuned-7b\")]\n",
    "for filename in filenames7b:\n",
    "    res = prepare_results(paths.RESULTS_PATH/\"medication\"/filename)\n",
    "    evaluated = evaluate_df(labels, res, relevant_columns)\n",
    "    agg_df = aggregate_scores(evaluated)\n",
    "    results_7b.append(agg_df)\n",
    "results_7b = pd.concat(results_7b, axis=1).round(2)\n",
    "results_7b.columns = [filename.split(\"4bit_\")[1] for filename in filenames7b]\n",
    "\n",
    "# Reorder rows\n",
    "results_7b = results_7b.reindex([\"precision_name\", \"precision_dose\", \"precision_dose_unit\", \"precision_intake\", \"recall_name\", \"recall_dose\", \"recall_dose_unit\", \"recall_intake\", \"f1_score_name\", \"f1_score_dose\", \"f1_score_dose_unit\", \"f1_score_intake\"]).transpose()\n",
    "results_7b.to_csv(paths.THESIS_PATH/\"medication_results_7b.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36740b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_7b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c270d9",
   "metadata": {},
   "source": [
    "# Rule Based Approach\n",
    "From old project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67660478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_list_medi_ms():\n",
    "    \n",
    "    '''\n",
    "    load list of MS medications\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    with open(paths.PROJECT_ROOT/\"resources/old_project/medication_for_ms.txt\", \"r\") as f:\n",
    "        list_medi_ms = f.readlines()\n",
    "    list_medi_ms = [item.strip() for item in list_medi_ms]\n",
    "    \n",
    "    return list_medi_ms\n",
    "\n",
    "def _split_dose_and_unit(test_str, list_unit):\n",
    "    \n",
    "    '''\n",
    "    split strings for dose and unit which aren't separated by a space, e.g. '120mg' and '0.5mg'\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def _contains_alpha_and_numeric(test_str):\n",
    "        '''\n",
    "        helper function to determine whether string could represent a dose and a unit and if it contains a dot\n",
    "        '''\n",
    "\n",
    "        # initiliaze\n",
    "        status = 'no'\n",
    "        \n",
    "        # dose and unit start with a digit and end with a letter\n",
    "        if (test_str[0].isdigit()) & (test_str[-1].isalpha()):\n",
    "\n",
    "            # does it contain a dot\n",
    "            if '.' in test_str:\n",
    "                status = 'w/_dot'\n",
    "            else:\n",
    "                status = 'w/o_dot'\n",
    "\n",
    "        return status\n",
    "\n",
    "    # initialize\n",
    "    list_tokens = [test_str]\n",
    "\n",
    "    # get status whether it could be a dose and unit\n",
    "    status = _contains_alpha_and_numeric(test_str)\n",
    "    \n",
    "    # if it contains 1 dot but no other special characters, and all letters represent a unit\n",
    "    if status == 'w/_dot':\n",
    "\n",
    "        if (test_str.count('.') == 1) & (len(re.findall('[\\W]', test_str.replace('.', ''))) == 0):\n",
    "            \n",
    "            if re.findall('[a-zA-Z]+', test_str)[0] in list_unit:\n",
    "    \n",
    "                list_tokens = list(re.findall('(\\d+)\\.(\\d+)?(\\w+)', test_str)[0])\n",
    "                list_tokens = ['.'.join(list_tokens[:2]), list_tokens[-1]]\n",
    "\n",
    "    # if it doesn't contain a dot and all characters are either digits or letters\n",
    "    if status == 'w/o_dot':\n",
    "        \n",
    "        if test_str.isalnum():\n",
    "    \n",
    "            list_tokens = list(re.findall('(\\d+)(\\w+)', test_str)[0])\n",
    "    \n",
    "    return list_tokens\n",
    "\n",
    "def extract_dose_and_unit(list_tokens, list_unit_match):\n",
    "\n",
    "    # intialize\n",
    "    dose = ''\n",
    "    unit = ''\n",
    "    \n",
    "    # extract dose and unit if there is exactly one match\n",
    "    if len(list_unit_match) == 1:\n",
    "\n",
    "        unit = list_unit_match[0]\n",
    "        dose = list_tokens[list_tokens.index(unit) - 1]   \n",
    "        \n",
    "    return dose, unit\n",
    "\n",
    "def extract_dosage_across_day(list_dose_match):\n",
    "    \n",
    "    # initialize\n",
    "    morning = ''\n",
    "    noon = ''\n",
    "    evening = ''\n",
    "    night = ''\n",
    "    \n",
    "    # extract dosage for first entry\n",
    "    if len(list_dose_match) >= 1:\n",
    "        \n",
    "        medi_dose = list_dose_match[0]\n",
    "        list_medi_doses = medi_dose.split('-')\n",
    "        \n",
    "        # 3 entries, e.g 1-1-1\n",
    "        if len(list_medi_doses) == 3:\n",
    "            morning = list_medi_doses[0]\n",
    "            noon = list_medi_doses[1]\n",
    "            evening = list_medi_doses[2]\n",
    "            night = 0\n",
    "            \n",
    "        # 4 entries, e.g. 1-0-0-0\n",
    "        elif len(list_medi_doses) == 4:\n",
    "            morning = list_medi_doses[0]\n",
    "            noon = list_medi_doses[1]\n",
    "            evening = list_medi_doses[2]\n",
    "            night = list_medi_doses[3]\n",
    "            \n",
    "    return morning, noon, evening, night\n",
    "\n",
    "   \n",
    "def flatten_listoflists(listoflists):\n",
    "    '''\n",
    "    function to flatten a list of lists\n",
    "    \n",
    "    input:\n",
    "    - listoflists: nested list\n",
    "    \n",
    "    output:\n",
    "    - flat_list: unnested list\n",
    "    '''\n",
    "    \n",
    "    flat_list = [item for sublist in listoflists for item in sublist]\n",
    "    \n",
    "    return flat_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded3fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medi = pd.read_csv(paths.DATA_PATH_PREPROCESSED/\"medication/kisim_medication_sample.csv\")\n",
    "df_medi[\"id\"] = df_medi.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcbe2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of units and MS medications\n",
    "list_unit = ['mg', 'ug', 'g']\n",
    "list_medi_ms = load_list_medi_ms()\n",
    "\n",
    "# intitialize\n",
    "list_output = list()\n",
    "\n",
    "# for each row\n",
    "for _, row in df_medi.iterrows():\n",
    "    \n",
    "    # get research id, etc.\n",
    "    rid = row['rid']\n",
    "    text_all = row['text']\n",
    "    id = row['id']\n",
    "    \n",
    "    # split text into lines\n",
    "    list_text_all = text_all.splitlines()\n",
    "    \n",
    "    # for each text line\n",
    "    for text in list_text_all:\n",
    "        \n",
    "        # get tokens and split dose and unit, e.g. '120mg'\n",
    "        list_tokens = text.split()\n",
    "        list_tokens = flatten_listoflists([_split_dose_and_unit(item, list_unit) for item in list_tokens])\n",
    "        \n",
    "        # match medication names, units and dosing (e.g. 1-1-1)\n",
    "        list_name_match = list(set(list_tokens).intersection(list_medi_ms))\n",
    "        list_unit_match = list(set(list_tokens).intersection(list_unit))\n",
    "        list_dose_match = [item for item in list_tokens if '-' in item]\n",
    "\n",
    "        # if an MS medication name was matched\n",
    "        if len(list_name_match) >=  1:\n",
    "\n",
    "            # get (first) medication name (there are very few cases with > 1 name)\n",
    "            name = list_name_match[0]\n",
    "\n",
    "            # get dose and unit\n",
    "            dose, unit = extract_dose_and_unit(list_tokens, list_unit_match)\n",
    "              \n",
    "            # get dosage across day\n",
    "            morning, noon, evening, night = extract_dosage_across_day(list_dose_match)\n",
    "\n",
    "            # extra field\n",
    "            extra = \"\"\n",
    "\n",
    "            # append\n",
    "            list_output.append((name, dose, unit, morning, noon, evening, night, extra, text_all, id))       \n",
    "            \n",
    "# generate output data frame\n",
    "df_results = pd.DataFrame(list_output, \n",
    "                         columns = [ \n",
    "                                    'name', 'dose', 'dose_unit', \n",
    "                                    'morning', 'noon', 'evening','night',\n",
    "                                    'extra',\n",
    "                                    'text', \"id\"])\n",
    "output_ids = set(df_results.id.unique())\n",
    "print(\"Number of reports that were processed:\", len(output_ids))\n",
    "left_over_ids = set(df_medi.id.unique()) - output_ids\n",
    "\n",
    "left_over_dfs = []\n",
    "for id in left_over_ids:\n",
    "    _df = {**default_model.model_dump()[\"medications\"][0], \"text\": df_medi[df_medi.id == id].text.values[0], \"id\": id}\n",
    "    left_over_dfs.append(_df)\n",
    "left_over_df = pd.DataFrame(left_over_dfs)\n",
    "\n",
    "df_results = pd.concat([df_results, left_over_df]).sort_values(\"id\").reset_index(drop=True)\n",
    "\n",
    "# To get comparability need to map to string\n",
    "\n",
    "df_results = df_results.map(lambda x: str(x).lower())\n",
    "expression = r\"\\.0+$\"\n",
    "df_results = df_results.replace(expression, \"\", regex=True)\n",
    "\n",
    "\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bcede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[df_results.id == \"93\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a854f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res[\"id\"] == \"78\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5281e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[labels[\"id\"] == \"78\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d0ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_rule = evaluate_df(labels, df_results, relevant_columns)\n",
    "agg_df_rule = aggregate_scores(evaluated_rule)\n",
    "agg_df_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the ones it predicted:\n",
    "predicted_examples_ids = [str(id) for id in output_ids]\n",
    "aggregate_scores(evaluated_rule[evaluated_rule.id.isin(predicted_examples_ids)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167ae46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rule = pd.DataFrame([aggregate_scores(evaluated_rule), aggregate_scores(evaluated_rule[evaluated_rule.id.isin(predicted_examples_ids)])]).round(2)\n",
    "res_rule[\"sample\"] = [\"whole test set\", \"extracted\"]\n",
    "res_rule.to_csv(paths.THESIS_PATH/\"medication_results_rule.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f8ff4d-dca0-4af6-85eb-94249275e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e884c",
   "metadata": {},
   "source": [
    "Notes for rule based:\n",
    "- Only first example of medication is extracted.\n",
    "- Only 4 out of 100 examples were even detected. (Also in original one they only detected around 6% of examples)\n",
    "- Even for the ones it detected, if there are multiple medications it won't extract them. So recall not as high.\n",
    "- For precision of course very high, but also here mistakes. Like dose-unit 0,5 is different from 0.5, which LLM catches as it outputs float format, while rule based does text matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfafa04d",
   "metadata": {},
   "source": [
    "## Intermezzo\n",
    "Just to check if they also just extracted so few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ea385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medi1 = pd.read_csv(paths.DATA_PATH_RSD/'reports_kisim_medication.csv')\n",
    "# drop empty medication text\n",
    "df_medi1 = df_medi1[df_medi1['medication_name'].notnull()]\n",
    "# list of units and MS medications\n",
    "list_unit = ['mg', 'ug', 'g']\n",
    "list_medi_ms = load_list_medi_ms()\n",
    "\n",
    "# intitialize\n",
    "list_output = list()\n",
    "\n",
    "# for each row\n",
    "for _, row in df_medi1.iterrows():\n",
    "    \n",
    "    # # get research id, etc.\n",
    "    # rid = row['rid']\n",
    "    # text_all = row['text']\n",
    "    # get research id, etc.\n",
    "    rid = row['research_id']\n",
    "    date = row['medication_prescription_date']\n",
    "    prescription = row['medication_prescription_name']\n",
    "    text_all = row['medication_name']\n",
    "    \n",
    "    # split text into lines\n",
    "    list_text_all = text_all.splitlines()\n",
    "    \n",
    "    # for each text line\n",
    "    for text in list_text_all:\n",
    "        \n",
    "        # get tokens and split dose and unit, e.g. '120mg'\n",
    "        list_tokens = text.split()\n",
    "        list_tokens = flatten_listoflists([_split_dose_and_unit(item, list_unit) for item in list_tokens])\n",
    "        \n",
    "        # match medication names, units and dosing (e.g. 1-1-1)\n",
    "        list_name_match = list(set(list_tokens).intersection(list_medi_ms))\n",
    "        list_unit_match = list(set(list_tokens).intersection(list_unit))\n",
    "        list_dose_match = [item for item in list_tokens if '-' in item]\n",
    "\n",
    "        # if an MS medication name was matched\n",
    "        if len(list_name_match) >=  1:\n",
    "\n",
    "            # get (first) medication name (there are very few cases with > 1 name)\n",
    "            name = list_name_match[0]\n",
    "\n",
    "            # get dose and unit\n",
    "            dose, unit = extract_dose_and_unit(list_tokens, list_unit_match)\n",
    "              \n",
    "            # get dosage across day\n",
    "            morning, noon, evening, night = extract_dosage_across_day(list_dose_match)\n",
    "\n",
    "            # append\n",
    "            list_output.append((rid, name, dose, unit, morning, noon, evening, night, text, text_all))        \n",
    "            \n",
    "# generate output data frame\n",
    "df_results1 = pd.DataFrame(list_output, \n",
    "                         columns = ['rid', \n",
    "                                    'name', 'dose', 'unit', \n",
    "                                    'morning', 'evening', 'noon', 'night',\n",
    "                                    'text_line', 'text_all'])\n",
    "len(df_results1)/len(df_medi1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
