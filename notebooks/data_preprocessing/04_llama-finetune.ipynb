{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd()+\"/../..\")\n",
    "from src import paths\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the test rids\n",
    "test_rids = pd.read_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"ms-diag/test_rids.txt\"), header=None).values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nan values in text: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_474/3360503076.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  remove_ids = kisim_diagnoses_to_remove.groupby(\"research_id\").apply(lambda x: x.loc[x[\"text\"].apply(len).idxmax()])[\"diagnosis_id\"]\n"
     ]
    }
   ],
   "source": [
    "# Kisim diagnoses\n",
    "kisim_diagnoses = pd.read_csv(os.path.join(paths.DATA_PATH_SEANTIS, \"kisim_diagnoses.csv\")).rename(columns={\"diagnosis_label\": \"text\"})\n",
    "\n",
    "# Some text will be doubled in dataset as doctors just append, and there is now way to know from this data what text belongs to what.\n",
    "# LastUpdateDateTime is shared with first part of diagnosis id and then the second part is the indicator of the individual texts so 4085680|1 for example\n",
    "\n",
    "# Number of nan values in text\n",
    "print(f\"Number of nan values in text: {kisim_diagnoses['text'].isna().sum()}\")\n",
    "kisim_diagnoses.dropna(subset=[\"text\"], inplace=True)\n",
    "\n",
    "# Split the text into lines\n",
    "kisim_diagnoses[\"text\"] = kisim_diagnoses[\"text\"].str.split(\"\\n\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove empty strings and whitespace-only strings\n",
    "    try:\n",
    "        lines = [str(item) for item in text if not (not item or item.isspace())]\n",
    "    except:\n",
    "        print(text)\n",
    "    # Add 'INDENT' to lines starting with '-', '·', '··', and remove '·'\n",
    "    lines = ['INDENT ' + item.replace('·', '') if item.startswith(('-', '·', '··')) else item for item in lines]\n",
    "    return lines\n",
    "\n",
    "kisim_diagnoses[\"text\"] = kisim_diagnoses[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# Select longest text for each research_id\n",
    "kisim_diagnoses_to_remove = kisim_diagnoses[kisim_diagnoses[\"research_id\"].isin(test_rids)]\n",
    "remove_ids = kisim_diagnoses_to_remove.groupby(\"research_id\").apply(lambda x: x.loc[x[\"text\"].apply(len).idxmax()])[\"diagnosis_id\"]\n",
    "\n",
    "kisim_diagnoses = kisim_diagnoses[~kisim_diagnoses[\"diagnosis_id\"].isin(remove_ids)]\n",
    "\n",
    "kisim_diagnoses[\"text\"] = kisim_diagnoses.apply(lambda x: \"\\n\".join(x[\"text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reports kisim diagnoses also contains more texts\n",
    "kisim_reports_diagnoses = pd.read_csv(os.path.join(paths.DATA_PATH_RSD, \"reports_kisim_diagnoses.csv\")).rename(columns={\"diagnosis_label\": \"text\"})\n",
    "kisim_reports_diagnoses[\"text\"] = kisim_reports_diagnoses[\"text\"].str.split(\"\\n\")\n",
    "kisim_reports_diagnoses.dropna(subset=[\"text\"], inplace=True)\n",
    "kisim_reports_diagnoses[\"text\"] = kisim_reports_diagnoses[\"text\"].apply(preprocess_text)\n",
    "kisim_reports_diagnoses[\"text\"] = kisim_reports_diagnoses.apply(lambda x: \"\\n\".join(x[\"text\"]), axis=1)\n",
    "\n",
    "# Combine the two datasets\n",
    "df_all = pd.concat([kisim_diagnoses, kisim_reports_diagnoses], axis=0)\n",
    "\n",
    "# Drop double diagnoses ids\n",
    "df_all.drop_duplicates(subset=\"diagnosis_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for training\n",
    "context_length = 128\n",
    "\n",
    "# tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(paths.MODEL_PATH/\"Llama2-MedTuned-13b\")\n",
    "\n",
    "# Tokenize the text\n",
    "def tokenize(example):\n",
    "    outputs = tokenizer(\n",
    "    example[\"text\"],\n",
    "    max_length = context_length,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_length = True,\n",
    "    truncation = True,\n",
    "    )\n",
    "    return outputs\n",
    "\n",
    "\n",
    "# outputs = tokenizer(\n",
    "#     df_all[\"text\"].tolist(),\n",
    "#     truncation=True,\n",
    "#     max_length=context_length,\n",
    "#     return_overflowing_tokens=True,\n",
    "#     return_length=True,\n",
    "# )\n",
    "\n",
    "from datasets import Dataset\n",
    "df = Dataset.from_dict({\"text\": df_all[\"text\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ceba843477405ea21d6a83261ecf5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.select(range(2)).map(tokenize, remove_columns=df.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs length: 2\n",
      "Input chunk lengths: [[128, 8], [70]]\n",
      "Chunk mapping: [[0, 0], [0]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input IDs length: {len(df['input_ids'])}\")\n",
    "print(f\"Input chunk lengths: {(df['length'])}\")\n",
    "print(f\"Chunk mapping: {df['overflow_to_sample_mapping']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37                                                                                               INDENT EDSS 08/2016: 3.0\n",
       "80                                                                                    2. Rezidivierende Uveitiden EM 1993\n",
       "81                                                                                    3. Lymphopenie Grad 1-2, ED 02/2018\n",
       "82                                                                 DD Interferon-/Rituximab-assoziiert, DD unklare Genese\n",
       "131                                                        INDENT Modasomil (10/2019 Valens), Fampyra, Lioresal (12/2019)\n",
       "                                                              ...                                                        \n",
       "899                                   INDENT Stomatitis aphthosa mit schmerzhafter Aphthe an Zungenspitze seit 06.03.2020\n",
       "900                                                                              INDENT Re-Soor-Stomatitis, ED 11.03.2020\n",
       "901                                                                                     Re-Soor-Stomatitis, ED 10.04.2020\n",
       "938    INDENT seit Anfang Juli 2018 Vitamin Substitution nach dem Coimbra-Protokoll (Vit D 80000U/d) geplant bis November\n",
       "940                                                                               Entzündliche ZNS-Erkrankung, EM 03/2016\n",
       "Name: text, Length: 77, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils import load_line_label_data\n",
    "# Comparison medication kisim reports\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "line_labels = pd.DataFrame(load_line_label_data()[\"train\"])\n",
    "line_labels[line_labels[\"class_agg\"] == \"medms\"][\"text\"].iloc[10]\n",
    "# It seems that in reports they don't have dosis and when, but more like start date and what medication\n",
    "line_labels[line_labels[\"class_agg\"] == \"medo_unk_do_so\"][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 OP Medrol 32 mg \t1-0-0\n",
      "2 OP Keppra 500 mg\t3-0-3\n",
      "1 OP Urbanyl 10 mg \t0-0-0.5 noch für eine Woche\n",
      "1 OP Rivotril 0.5 mg\t1-1-0 noch für eine Woche, dann 1-1-1\n"
     ]
    }
   ],
   "source": [
    "# Medications\n",
    "kisim_medications = pd.read_csv(os.path.join(paths.DATA_PATH_SEANTIS, \"kisim_medication.csv\"))\n",
    "kisim_medications_text = kisim_medications[\"medication_name\"]\n",
    "print(kisim_medications_text.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kisim_diagnoses_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Combining texts\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m texts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mkisim_diagnoses_text\u001b[49m, kisim_medications_text], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kisim_diagnoses_text' is not defined"
     ]
    }
   ],
   "source": [
    "# medications.csv not really helpful as of now\n",
    "medications = pd.read_csv(os.path.join(paths.DATA_PATH_SEANTIS, \"medications.csv\"))\n",
    "medications.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for unsupervised pretrain will only consist of kisim_diagnoses_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# I will adapt the code from original project, that also produced preprocessed data for previous tasks.\n",
    "# Then c\n",
    "\n",
    "def _get_diag_lines(diag):\n",
    "    \n",
    "    '''\n",
    "    get list of text lines for a kisim_diagnoses.csv 'diag_label' entry\n",
    "    \n",
    "    input:\n",
    "    - diag: str with text from one 'diag_label' entry\n",
    "    \n",
    "    ouptut:\n",
    "    - diag_lines: list of text lines\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    diag_lines = diag.splitlines()\n",
    "    diag_lines = [item for item in diag_lines if not (not item or item.isspace())]\n",
    "    diag_lines = ['INDENT ' + item.replace('·', '') if item.startswith(('-', '·', '··')) else item for item in diag_lines]\n",
    "    \n",
    "    return diag_lines\n",
    "\n",
    "\n",
    "def extract_longest_diag_per_rid(df, var_date, var_diag):\n",
    "    '''\n",
    "    function to extract longest lines of all diagnosis texts for each research id\n",
    "    \n",
    "    input:\n",
    "    - df: dataframe containing all information\n",
    "    - var_date: column name of date column\n",
    "    - var_diag: column name of diagnosis text column\n",
    "    \n",
    "    ouptut:\n",
    "    - dict_diags: dictionary of diagnosis text (key: research id-diag_index-date, value: list of text lines)   \n",
    "    '''\n",
    "    \n",
    "    dict_diags = dict()\n",
    "    list_vars = [var_date, var_diag]\n",
    "\n",
    "    for rid in df['research_id'].unique():\n",
    "\n",
    "        list_lines = list()\n",
    "        date = ''\n",
    "        _df = df[df['research_id'] == rid].sort_values([var_date])[list_vars]\n",
    "\n",
    "        for diag_index, row in _df.iterrows():\n",
    "\n",
    "            diag = row[var_diag]\n",
    "\n",
    "            if isinstance(diag, str):\n",
    "                \n",
    "                diag_lines = _get_diag_lines(diag)\n",
    "                \n",
    "                if len(diag_lines) >= len(list_lines):\n",
    "                    \n",
    "                    list_lines = diag_lines[:]\n",
    "                    date = str(row[var_date])[:11]\n",
    "                    \n",
    "        key = '_'.join((rid, str(diag_index), date))\n",
    "                \n",
    "        dict_diags[key] = list_lines\n",
    "\n",
    "    return dict_diags"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf-extr-BlECHwmE-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
