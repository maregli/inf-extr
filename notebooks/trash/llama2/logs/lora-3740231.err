/bin/bash: /cluster/customapps/biomed/grlab/users/eglimar/conda/envs/inf-extr/lib/libtinfo.so.6: no version information available (required by /bin/bash)
/cluster/home/eglimar/.env_bootstrap/dotfiles/shell/bashrc: line 17: module: command not found
/cluster/home/eglimar/.env_bootstrap/dotfiles/shell/bashrc: line 20: module: command not found
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [04:22<21:51, 262.37s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [08:56<17:57, 269.31s/it]Loading checkpoint shards:  50%|█████     | 3/6 [13:38<13:44, 274.92s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [18:03<09:02, 271.16s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [22:44<04:34, 274.74s/it]Loading checkpoint shards: 100%|██████████| 6/6 [24:39<00:00, 220.24s/it]Loading checkpoint shards: 100%|██████████| 6/6 [24:39<00:00, 246.53s/it]
Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at /cluster/dataset/midatams/inf-extr/resources/models/llama2 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Map:   0%|          | 0/59 [00:00<?, ? examples/s]Map: 100%|██████████| 59/59 [00:00<00:00, 81.90 examples/s]Map: 100%|██████████| 59/59 [00:00<00:00, 80.08 examples/s]
  0%|          | 0/43 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/cluster/customapps/biomed/grlab/users/eglimar/conda/envs/inf-extr/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/cluster/customapps/biomed/grlab/users/eglimar/conda/envs/inf-extr/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Epoch: 0, Loss: 2.4819:   0%|          | 0/43 [00:54<?, ?it/s]Epoch: 0, Loss: 2.4819:   2%|▏         | 1/43 [00:54<37:55, 54.18s/it]Epoch: 0, Loss: 2.0360:   2%|▏         | 1/43 [00:55<37:55, 54.18s/it]Epoch: 0, Loss: 2.0360:   5%|▍         | 2/43 [00:55<15:56, 23.34s/it]Epoch: 0, Loss: 1.5975:   5%|▍         | 2/43 [00:57<15:56, 23.34s/it]Epoch: 0, Loss: 1.5975:   7%|▋         | 3/43 [00:57<08:59, 13.48s/it]Epoch: 0, Loss: 3.2101:   7%|▋         | 3/43 [00:59<08:59, 13.48s/it]Epoch: 0, Loss: 3.2101:   9%|▉         | 4/43 [00:59<05:43,  8.82s/it]Epoch: 0, Loss: 1.3864:   9%|▉         | 4/43 [01:00<05:43,  8.82s/it]Epoch: 0, Loss: 1.3864:  12%|█▏        | 5/43 [01:01<03:57,  6.26s/it]Epoch: 0, Loss: 3.1864:  12%|█▏        | 5/43 [01:02<03:57,  6.26s/it]Epoch: 0, Loss: 3.1864:  14%|█▍        | 6/43 [01:02<02:54,  4.71s/it]Epoch: 0, Loss: 1.1185:  14%|█▍        | 6/43 [01:04<02:54,  4.71s/it]Epoch: 0, Loss: 1.1185:  16%|█▋        | 7/43 [01:04<02:13,  3.72s/it]Epoch: 0, Loss: 3.8853:  16%|█▋        | 7/43 [01:06<02:13,  3.72s/it]Epoch: 0, Loss: 3.8853:  19%|█▊        | 8/43 [01:06<01:47,  3.07s/it]Epoch: 0, Loss: 1.4752:  19%|█▊        | 8/43 [01:07<01:47,  3.07s/it]Epoch: 0, Loss: 1.4752:  21%|██        | 9/43 [01:07<01:28,  2.61s/it]Epoch: 0, Loss: 1.6054:  21%|██        | 9/43 [01:09<01:28,  2.61s/it]Epoch: 0, Loss: 1.6054:  23%|██▎       | 10/43 [01:09<01:16,  2.32s/it]Epoch: 0, Loss: 1.5770:  23%|██▎       | 10/43 [01:11<01:16,  2.32s/it]Epoch: 0, Loss: 1.5770:  26%|██▌       | 11/43 [01:11<01:08,  2.13s/it]Epoch: 0, Loss: 1.9231:  26%|██▌       | 11/43 [01:12<01:08,  2.13s/it]Epoch: 0, Loss: 1.9231:  28%|██▊       | 12/43 [01:12<01:01,  1.99s/it]Epoch: 0, Loss: 2.5328:  28%|██▊       | 12/43 [01:14<01:01,  1.99s/it]Epoch: 0, Loss: 2.5328:  30%|███       | 13/43 [01:14<00:57,  1.92s/it]Epoch: 0, Loss: 2.0867:  30%|███       | 13/43 [01:16<00:57,  1.92s/it]Epoch: 0, Loss: 2.0867:  33%|███▎      | 14/43 [01:16<00:53,  1.85s/it]Epoch: 0, Loss: 1.3236:  33%|███▎      | 14/43 [01:18<00:53,  1.85s/it]Epoch: 0, Loss: 1.3236:  35%|███▍      | 15/43 [01:18<00:51,  1.85s/it]Epoch: 0, Loss: 1.7653:  35%|███▍      | 15/43 [01:19<00:51,  1.85s/it]Epoch: 0, Loss: 1.7653:  37%|███▋      | 16/43 [01:19<00:49,  1.82s/it]Epoch: 0, Loss: 0.9831:  37%|███▋      | 16/43 [01:21<00:49,  1.82s/it]Epoch: 0, Loss: 0.9831:  40%|███▉      | 17/43 [01:21<00:46,  1.78s/it]Epoch: 0, Loss: 1.2553:  40%|███▉      | 17/43 [01:23<00:46,  1.78s/it]Epoch: 0, Loss: 1.2553:  42%|████▏     | 18/43 [01:23<00:43,  1.74s/it]Epoch: 0, Loss: 1.1196:  42%|████▏     | 18/43 [01:24<00:43,  1.74s/it]Epoch: 0, Loss: 1.1196:  44%|████▍     | 19/43 [01:24<00:41,  1.73s/it]Epoch: 0, Loss: 1.1124:  44%|████▍     | 19/43 [01:26<00:41,  1.73s/it]Epoch: 0, Loss: 1.1124:  47%|████▋     | 20/43 [01:26<00:39,  1.72s/it]Epoch: 0, Loss: 1.1421:  47%|████▋     | 20/43 [01:28<00:39,  1.72s/it]Epoch: 0, Loss: 1.1421:  49%|████▉     | 21/43 [01:28<00:37,  1.72s/it]Epoch: 0, Loss: 1.3835:  49%|████▉     | 21/43 [01:29<00:37,  1.72s/it]Epoch: 0, Loss: 1.3835:  51%|█████     | 22/43 [01:29<00:35,  1.69s/it]Epoch: 0, Loss: 0.8177:  51%|█████     | 22/43 [01:31<00:35,  1.69s/it]Epoch: 0, Loss: 0.8177:  53%|█████▎    | 23/43 [01:31<00:33,  1.68s/it]Epoch: 0, Loss: 0.3884:  53%|█████▎    | 23/43 [01:33<00:33,  1.68s/it]Epoch: 0, Loss: 0.3884:  56%|█████▌    | 24/43 [01:33<00:32,  1.70s/it]Epoch: 0, Loss: 0.5686:  56%|█████▌    | 24/43 [01:34<00:32,  1.70s/it]Epoch: 0, Loss: 0.5686:  58%|█████▊    | 25/43 [01:34<00:30,  1.69s/it]Epoch: 0, Loss: 0.9462:  58%|█████▊    | 25/43 [01:36<00:30,  1.69s/it]Epoch: 0, Loss: 0.9462:  60%|██████    | 26/43 [01:36<00:28,  1.70s/it]Epoch: 0, Loss: 1.4721:  60%|██████    | 26/43 [01:38<00:28,  1.70s/it]Epoch: 0, Loss: 1.4721:  63%|██████▎   | 27/43 [01:38<00:27,  1.69s/it]Epoch: 0, Loss: 0.8960:  63%|██████▎   | 27/43 [01:40<00:27,  1.69s/it]Epoch: 0, Loss: 0.8960:  65%|██████▌   | 28/43 [01:40<00:25,  1.72s/it]Epoch: 0, Loss: 1.1002:  65%|██████▌   | 28/43 [01:41<00:25,  1.72s/it]Epoch: 0, Loss: 1.1002:  67%|██████▋   | 29/43 [01:41<00:24,  1.76s/it]Epoch: 0, Loss: 1.8571:  67%|██████▋   | 29/43 [01:43<00:24,  1.76s/it]Epoch: 0, Loss: 1.8571:  70%|██████▉   | 30/43 [01:43<00:22,  1.76s/it]Epoch: 0, Loss: 1.7398:  70%|██████▉   | 30/43 [01:45<00:22,  1.76s/it]Epoch: 0, Loss: 1.7398:  72%|███████▏  | 31/43 [01:45<00:21,  1.80s/it]Epoch: 0, Loss: 1.9376:  72%|███████▏  | 31/43 [01:47<00:21,  1.80s/it]Epoch: 0, Loss: 1.9376:  74%|███████▍  | 32/43 [01:47<00:19,  1.76s/it]Epoch: 0, Loss: 0.8452:  74%|███████▍  | 32/43 [01:49<00:19,  1.76s/it]Epoch: 0, Loss: 0.8452:  77%|███████▋  | 33/43 [01:49<00:17,  1.75s/it]Epoch: 0, Loss: 1.2056:  77%|███████▋  | 33/43 [01:50<00:17,  1.75s/it]Epoch: 0, Loss: 1.2056:  79%|███████▉  | 34/43 [01:50<00:15,  1.72s/it]Epoch: 0, Loss: 1.6697:  79%|███████▉  | 34/43 [01:52<00:15,  1.72s/it]Epoch: 0, Loss: 1.6697:  81%|████████▏ | 35/43 [01:52<00:13,  1.72s/it]Epoch: 0, Loss: 0.8149:  81%|████████▏ | 35/43 [01:54<00:13,  1.72s/it]Epoch: 0, Loss: 0.8149:  84%|████████▎ | 36/43 [01:54<00:11,  1.70s/it]Epoch: 0, Loss: 1.5068:  84%|████████▎ | 36/43 [01:55<00:11,  1.70s/it]Epoch: 0, Loss: 1.5068:  86%|████████▌ | 37/43 [01:55<00:10,  1.69s/it]Epoch: 0, Loss: 1.0368:  86%|████████▌ | 37/43 [01:57<00:10,  1.69s/it]Epoch: 0, Loss: 1.0368:  88%|████████▊ | 38/43 [01:57<00:08,  1.68s/it]Epoch: 0, Loss: 0.4324:  88%|████████▊ | 38/43 [01:59<00:08,  1.68s/it]Epoch: 0, Loss: 0.4324:  91%|█████████ | 39/43 [01:59<00:06,  1.67s/it]Epoch: 0, Loss: 1.3579:  91%|█████████ | 39/43 [02:00<00:06,  1.67s/it]Epoch: 0, Loss: 1.3579:  93%|█████████▎| 40/43 [02:00<00:04,  1.66s/it]Epoch: 0, Loss: 1.8424:  93%|█████████▎| 40/43 [02:02<00:04,  1.66s/it]Epoch: 0, Loss: 1.8424:  95%|█████████▌| 41/43 [02:02<00:03,  1.66s/it]Epoch: 0, Loss: 1.2368:  95%|█████████▌| 41/43 [02:03<00:03,  1.66s/it]Epoch: 0, Loss: 1.2368:  98%|█████████▊| 42/43 [02:04<00:01,  1.68s/it]Epoch: 0, Loss: 0.7697:  98%|█████████▊| 42/43 [02:05<00:01,  1.68s/it]Epoch: 0, Loss: 0.7697: 100%|██████████| 43/43 [02:05<00:00,  1.61s/it]Epoch: 0, Loss: 0.7697: 100%|██████████| 43/43 [02:05<00:00,  2.92s/it]
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:01<00:01,  1.62s/it]100%|██████████| 2/2 [00:02<00:00,  1.46s/it]100%|██████████| 2/2 [00:03<00:00,  1.54s/it]
  0%|          | 0/43 [00:00<?, ?it/s]/cluster/customapps/biomed/grlab/users/eglimar/conda/envs/inf-extr/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/cluster/customapps/biomed/grlab/users/eglimar/conda/envs/inf-extr/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Epoch: 1, Loss: 0.5602:   0%|          | 0/43 [00:01<?, ?it/s]Epoch: 1, Loss: 0.5602:   2%|▏         | 1/43 [00:01<01:14,  1.77s/it]Epoch: 1, Loss: 0.3171:   2%|▏         | 1/43 [00:03<01:14,  1.77s/it]Epoch: 1, Loss: 0.3171:   5%|▍         | 2/43 [00:03<01:12,  1.78s/it]Epoch: 1, Loss: 0.2461:   5%|▍         | 2/43 [00:05<01:12,  1.78s/it]Epoch: 1, Loss: 0.2461:   7%|▋         | 3/43 [00:05<01:09,  1.74s/it]Epoch: 1, Loss: 0.4560:   7%|▋         | 3/43 [00:06<01:09,  1.74s/it]Epoch: 1, Loss: 0.4560:   9%|▉         | 4/43 [00:06<01:07,  1.74s/it]Epoch: 1, Loss: 0.7460:   9%|▉         | 4/43 [00:08<01:07,  1.74s/it]Epoch: 1, Loss: 0.7460:  12%|█▏        | 5/43 [00:08<01:05,  1.73s/it]Epoch: 1, Loss: 0.2441:  12%|█▏        | 5/43 [00:10<01:05,  1.73s/it]Epoch: 1, Loss: 0.2441:  14%|█▍        | 6/43 [00:10<01:04,  1.74s/it]Epoch: 1, Loss: 0.1016:  14%|█▍        | 6/43 [00:12<01:04,  1.74s/it]Epoch: 1, Loss: 0.1016:  16%|█▋        | 7/43 [00:12<01:01,  1.72s/it]Epoch: 1, Loss: 0.3221:  16%|█▋        | 7/43 [00:13<01:01,  1.72s/it]Epoch: 1, Loss: 0.3221:  19%|█▊        | 8/43 [00:13<00:59,  1.70s/it]Epoch: 1, Loss: 0.3335:  19%|█▊        | 8/43 [00:15<00:59,  1.70s/it]Epoch: 1, Loss: 0.3335:  21%|██        | 9/43 [00:15<00:58,  1.71s/it]Epoch: 1, Loss: 0.2635:  21%|██        | 9/43 [00:17<00:58,  1.71s/it]Epoch: 1, Loss: 0.2635:  23%|██▎       | 10/43 [00:17<00:56,  1.72s/it]Epoch: 1, Loss: 0.4211:  23%|██▎       | 10/43 [00:18<00:56,  1.72s/it]Epoch: 1, Loss: 0.4211:  26%|██▌       | 11/43 [00:18<00:54,  1.70s/it]Epoch: 1, Loss: 0.2087:  26%|██▌       | 11/43 [00:20<00:54,  1.70s/it]Epoch: 1, Loss: 0.2087:  28%|██▊       | 12/43 [00:20<00:52,  1.71s/it]Epoch: 1, Loss: 0.1293:  28%|██▊       | 12/43 [00:22<00:52,  1.71s/it]Epoch: 1, Loss: 0.1293:  30%|███       | 13/43 [00:22<00:51,  1.70s/it]Epoch: 1, Loss: 0.5556:  30%|███       | 13/43 [00:23<00:51,  1.70s/it]Epoch: 1, Loss: 0.5556:  33%|███▎      | 14/43 [00:24<00:49,  1.70s/it]Epoch: 1, Loss: 0.2767:  33%|███▎      | 14/43 [00:25<00:49,  1.70s/it]Epoch: 1, Loss: 0.2767:  35%|███▍      | 15/43 [00:25<00:48,  1.73s/it]Epoch: 1, Loss: 0.2115:  35%|███▍      | 15/43 [00:27<00:48,  1.73s/it]Epoch: 1, Loss: 0.2115:  37%|███▋      | 16/43 [00:27<00:47,  1.75s/it]Epoch: 1, Loss: 0.0991:  37%|███▋      | 16/43 [00:29<00:47,  1.75s/it]Epoch: 1, Loss: 0.0991:  40%|███▉      | 17/43 [00:29<00:46,  1.77s/it]Epoch: 1, Loss: 0.3358:  40%|███▉      | 17/43 [00:31<00:46,  1.77s/it]Epoch: 1, Loss: 0.3358:  42%|████▏     | 18/43 [00:31<00:43,  1.76s/it]Epoch: 1, Loss: 0.4545:  42%|████▏     | 18/43 [00:32<00:43,  1.76s/it]Epoch: 1, Loss: 0.4545:  44%|████▍     | 19/43 [00:32<00:41,  1.74s/it]Epoch: 1, Loss: 0.2838:  44%|████▍     | 19/43 [00:34<00:41,  1.74s/it]Epoch: 1, Loss: 0.2838:  47%|████▋     | 20/43 [00:34<00:39,  1.73s/it]Epoch: 1, Loss: 0.3822:  47%|████▋     | 20/43 [00:36<00:39,  1.73s/it]Epoch: 1, Loss: 0.3822:  49%|████▉     | 21/43 [00:36<00:38,  1.74s/it]Epoch: 1, Loss: 0.3953:  49%|████▉     | 21/43 [00:37<00:38,  1.74s/it]Epoch: 1, Loss: 0.3953:  51%|█████     | 22/43 [00:38<00:36,  1.74s/it]Epoch: 1, Loss: 0.6611:  51%|█████     | 22/43 [00:39<00:36,  1.74s/it]Epoch: 1, Loss: 0.6611:  53%|█████▎    | 23/43 [00:39<00:35,  1.78s/it]Epoch: 1, Loss: 0.2719:  53%|█████▎    | 23/43 [00:41<00:35,  1.78s/it]Epoch: 1, Loss: 0.2719:  56%|█████▌    | 24/43 [00:41<00:33,  1.74s/it]Epoch: 1, Loss: 0.2504:  56%|█████▌    | 24/43 [00:43<00:33,  1.74s/it]Epoch: 1, Loss: 0.2504:  58%|█████▊    | 25/43 [00:43<00:30,  1.72s/it]Epoch: 1, Loss: 0.3087:  58%|█████▊    | 25/43 [00:44<00:30,  1.72s/it]Epoch: 1, Loss: 0.3087:  60%|██████    | 26/43 [00:44<00:28,  1.70s/it]Epoch: 1, Loss: 0.5242:  60%|██████    | 26/43 [00:46<00:28,  1.70s/it]Epoch: 1, Loss: 0.5242:  63%|██████▎   | 27/43 [00:46<00:27,  1.72s/it]Epoch: 1, Loss: 0.3036:  63%|██████▎   | 27/43 [00:48<00:27,  1.72s/it]Epoch: 1, Loss: 0.3036:  65%|██████▌   | 28/43 [00:48<00:26,  1.73s/it]Epoch: 1, Loss: 0.2541:  65%|██████▌   | 28/43 [00:50<00:26,  1.73s/it]Epoch: 1, Loss: 0.2541:  67%|██████▋   | 29/43 [00:50<00:24,  1.75s/it]Epoch: 1, Loss: 0.3121:  67%|██████▋   | 29/43 [00:51<00:24,  1.75s/it]Epoch: 1, Loss: 0.3121:  70%|██████▉   | 30/43 [00:52<00:22,  1.77s/it]Epoch: 1, Loss: 0.2885:  70%|██████▉   | 30/43 [00:53<00:22,  1.77s/it]Epoch: 1, Loss: 0.2885:  72%|███████▏  | 31/43 [00:53<00:21,  1.76s/it]Epoch: 1, Loss: 0.7229:  72%|███████▏  | 31/43 [00:55<00:21,  1.76s/it]Epoch: 1, Loss: 0.7229:  74%|███████▍  | 32/43 [00:55<00:19,  1.78s/it]Epoch: 1, Loss: 0.3773:  74%|███████▍  | 32/43 [00:57<00:19,  1.78s/it]Epoch: 1, Loss: 0.3773:  77%|███████▋  | 33/43 [00:57<00:18,  1.80s/it]Epoch: 1, Loss: 0.2902:  77%|███████▋  | 33/43 [00:59<00:18,  1.80s/it]Epoch: 1, Loss: 0.2902:  79%|███████▉  | 34/43 [00:59<00:15,  1.77s/it]Epoch: 1, Loss: 0.0330:  79%|███████▉  | 34/43 [01:01<00:15,  1.77s/it]Epoch: 1, Loss: 0.0330:  81%|████████▏ | 35/43 [01:01<00:14,  1.80s/it]Epoch: 1, Loss: 0.3195:  81%|████████▏ | 35/43 [01:02<00:14,  1.80s/it]Epoch: 1, Loss: 0.3195:  84%|████████▎ | 36/43 [01:02<00:12,  1.79s/it]Epoch: 1, Loss: 0.2711:  84%|████████▎ | 36/43 [01:04<00:12,  1.79s/it]Epoch: 1, Loss: 0.2711:  86%|████████▌ | 37/43 [01:04<00:10,  1.76s/it]Epoch: 1, Loss: 0.3167:  86%|████████▌ | 37/43 [01:06<00:10,  1.76s/it]Epoch: 1, Loss: 0.3167:  88%|████████▊ | 38/43 [01:06<00:08,  1.77s/it]Epoch: 1, Loss: 0.4872:  88%|████████▊ | 38/43 [01:07<00:08,  1.77s/it]Epoch: 1, Loss: 0.4872:  91%|█████████ | 39/43 [01:07<00:07,  1.75s/it]Epoch: 1, Loss: 0.3200:  91%|█████████ | 39/43 [01:09<00:07,  1.75s/it]Epoch: 1, Loss: 0.3200:  93%|█████████▎| 40/43 [01:09<00:05,  1.77s/it]Epoch: 1, Loss: 0.5731:  93%|█████████▎| 40/43 [01:11<00:05,  1.77s/it]Epoch: 1, Loss: 0.5731:  95%|█████████▌| 41/43 [01:11<00:03,  1.80s/it]Epoch: 1, Loss: 0.2946:  95%|█████████▌| 41/43 [01:13<00:03,  1.80s/it]Epoch: 1, Loss: 0.2946:  98%|█████████▊| 42/43 [01:13<00:01,  1.79s/it]Epoch: 1, Loss: 0.4136:  98%|█████████▊| 42/43 [01:14<00:01,  1.79s/it]Epoch: 1, Loss: 0.4136: 100%|██████████| 43/43 [01:14<00:00,  1.71s/it]Epoch: 1, Loss: 0.4136: 100%|██████████| 43/43 [01:14<00:00,  1.74s/it]
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:01<00:01,  1.62s/it]100%|██████████| 2/2 [00:02<00:00,  1.46s/it]100%|██████████| 2/2 [00:02<00:00,  1.50s/it]
  0%|          | 0/43 [00:00<?, ?it/s]/cluster/customapps/biomed/grlab/users/eglimar/conda/envs/inf-extr/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/cluster/customapps/biomed/grlab/users/eglimar/conda/envs/inf-extr/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Epoch: 2, Loss: 0.1603:   0%|          | 0/43 [00:01<?, ?it/s]Epoch: 2, Loss: 0.1603:   2%|▏         | 1/43 [00:01<01:22,  1.97s/it]Epoch: 2, Loss: 0.0784:   2%|▏         | 1/43 [00:03<01:22,  1.97s/it]Epoch: 2, Loss: 0.0784:   5%|▍         | 2/43 [00:03<01:18,  1.91s/it]Epoch: 2, Loss: 0.2072:   5%|▍         | 2/43 [00:05<01:18,  1.91s/it]Epoch: 2, Loss: 0.2072:   7%|▋         | 3/43 [00:05<01:12,  1.80s/it]Epoch: 2, Loss: 0.3013:   7%|▋         | 3/43 [00:07<01:12,  1.80s/it]Epoch: 2, Loss: 0.3013:   9%|▉         | 4/43 [00:07<01:08,  1.76s/it]Epoch: 2, Loss: 0.1365:   9%|▉         | 4/43 [00:08<01:08,  1.76s/it]Epoch: 2, Loss: 0.1365:  12%|█▏        | 5/43 [00:09<01:08,  1.80s/it]Epoch: 2, Loss: 0.0360:  12%|█▏        | 5/43 [00:10<01:08,  1.80s/it]Epoch: 2, Loss: 0.0360:  14%|█▍        | 6/43 [00:10<01:06,  1.79s/it]Epoch: 2, Loss: 0.1062:  14%|█▍        | 6/43 [00:12<01:06,  1.79s/it]Epoch: 2, Loss: 0.1062:  16%|█▋        | 7/43 [00:12<01:04,  1.80s/it]Epoch: 2, Loss: 0.0879:  16%|█▋        | 7/43 [00:14<01:04,  1.80s/it]Epoch: 2, Loss: 0.0879:  19%|█▊        | 8/43 [00:14<01:01,  1.76s/it]Epoch: 2, Loss: 0.3109:  19%|█▊        | 8/43 [00:16<01:01,  1.76s/it]Epoch: 2, Loss: 0.3109:  21%|██        | 9/43 [00:16<01:01,  1.80s/it]Epoch: 2, Loss: 0.2338:  21%|██        | 9/43 [00:17<01:01,  1.80s/it]Epoch: 2, Loss: 0.2338:  23%|██▎       | 10/43 [00:17<00:58,  1.77s/it]Epoch: 2, Loss: 0.1581:  23%|██▎       | 10/43 [00:19<00:58,  1.77s/it]Epoch: 2, Loss: 0.1581:  26%|██▌       | 11/43 [00:19<00:55,  1.75s/it]Epoch: 2, Loss: 0.0232:  26%|██▌       | 11/43 [00:21<00:55,  1.75s/it]Epoch: 2, Loss: 0.0232:  28%|██▊       | 12/43 [00:21<00:53,  1.74s/it]Epoch: 2, Loss: 0.2205:  28%|██▊       | 12/43 [00:23<00:53,  1.74s/it]Epoch: 2, Loss: 0.2205:  30%|███       | 13/43 [00:23<00:51,  1.73s/it]Epoch: 2, Loss: 0.0706:  30%|███       | 13/43 [00:24<00:51,  1.73s/it]Epoch: 2, Loss: 0.0706:  33%|███▎      | 14/43 [00:24<00:50,  1.75s/it]Epoch: 2, Loss: 0.0748:  33%|███▎      | 14/43 [00:26<00:50,  1.75s/it]Epoch: 2, Loss: 0.0748:  35%|███▍      | 15/43 [00:26<00:48,  1.73s/it]Epoch: 2, Loss: 0.1165:  35%|███▍      | 15/43 [00:28<00:48,  1.73s/it]Epoch: 2, Loss: 0.1165:  37%|███▋      | 16/43 [00:28<00:47,  1.77s/it]Epoch: 2, Loss: 0.2939:  37%|███▋      | 16/43 [00:30<00:47,  1.77s/it]Epoch: 2, Loss: 0.2939:  40%|███▉      | 17/43 [00:30<00:45,  1.74s/it]Epoch: 2, Loss: 0.1636:  40%|███▉      | 17/43 [00:31<00:45,  1.74s/it]Epoch: 2, Loss: 0.1636:  42%|████▏     | 18/43 [00:31<00:43,  1.72s/it]Epoch: 2, Loss: 0.1586:  42%|████▏     | 18/43 [00:33<00:43,  1.72s/it]Epoch: 2, Loss: 0.1586:  44%|████▍     | 19/43 [00:33<00:41,  1.71s/it]Epoch: 2, Loss: 0.1360:  44%|████▍     | 19/43 [00:35<00:41,  1.71s/it]Epoch: 2, Loss: 0.1360:  47%|████▋     | 20/43 [00:35<00:39,  1.71s/it]Epoch: 2, Loss: 0.1545:  47%|████▋     | 20/43 [00:36<00:39,  1.71s/it]Epoch: 2, Loss: 0.1545:  49%|████▉     | 21/43 [00:36<00:37,  1.70s/it]Epoch: 2, Loss: 0.1724:  49%|████▉     | 21/43 [00:38<00:37,  1.70s/it]Epoch: 2, Loss: 0.1724:  51%|█████     | 22/43 [00:38<00:36,  1.72s/it]Epoch: 2, Loss: 0.0371:  51%|█████     | 22/43 [00:40<00:36,  1.72s/it]Epoch: 2, Loss: 0.0371:  53%|█████▎    | 23/43 [00:40<00:33,  1.70s/it]Epoch: 2, Loss: 0.1699:  53%|█████▎    | 23/43 [00:41<00:33,  1.70s/it]Epoch: 2, Loss: 0.1699:  56%|█████▌    | 24/43 [00:42<00:33,  1.75s/it]Epoch: 2, Loss: 0.0447:  56%|█████▌    | 24/43 [00:43<00:33,  1.75s/it]Epoch: 2, Loss: 0.0447:  58%|█████▊    | 25/43 [00:43<00:31,  1.73s/it]Epoch: 2, Loss: 0.2009:  58%|█████▊    | 25/43 [00:45<00:31,  1.73s/it]Epoch: 2, Loss: 0.2009:  60%|██████    | 26/43 [00:45<00:30,  1.80s/it]Epoch: 2, Loss: 0.1949:  60%|██████    | 26/43 [00:47<00:30,  1.80s/it]Epoch: 2, Loss: 0.1949:  63%|██████▎   | 27/43 [00:47<00:29,  1.87s/it]Epoch: 2, Loss: 0.2797:  63%|██████▎   | 27/43 [00:49<00:29,  1.87s/it]Epoch: 2, Loss: 0.2797:  65%|██████▌   | 28/43 [00:49<00:28,  1.87s/it]Epoch: 2, Loss: 0.0983:  65%|██████▌   | 28/43 [00:51<00:28,  1.87s/it]Epoch: 2, Loss: 0.0983:  67%|██████▋   | 29/43 [00:51<00:26,  1.92s/it]Epoch: 2, Loss: 0.2448:  67%|██████▋   | 29/43 [00:53<00:26,  1.92s/it]Epoch: 2, Loss: 0.2448:  70%|██████▉   | 30/43 [00:53<00:24,  1.87s/it]Epoch: 2, Loss: 0.2182:  70%|██████▉   | 30/43 [00:55<00:24,  1.87s/it]Epoch: 2, Loss: 0.2182:  72%|███████▏  | 31/43 [00:55<00:22,  1.84s/it]Epoch: 2, Loss: 0.5505:  72%|███████▏  | 31/43 [00:56<00:22,  1.84s/it]Epoch: 2, Loss: 0.5505:  74%|███████▍  | 32/43 [00:56<00:19,  1.80s/it]Epoch: 2, Loss: 0.0643:  74%|███████▍  | 32/43 [00:58<00:19,  1.80s/it]Epoch: 2, Loss: 0.0643:  77%|███████▋  | 33/43 [00:58<00:18,  1.80s/it]Epoch: 2, Loss: 0.3986:  77%|███████▋  | 33/43 [01:00<00:18,  1.80s/it]Epoch: 2, Loss: 0.3986:  79%|███████▉  | 34/43 [01:00<00:16,  1.79s/it]Epoch: 2, Loss: 0.2045:  79%|███████▉  | 34/43 [01:02<00:16,  1.79s/it]Epoch: 2, Loss: 0.2045:  81%|████████▏ | 35/43 [01:02<00:14,  1.80s/it]Epoch: 2, Loss: 0.0801:  81%|████████▏ | 35/43 [01:04<00:14,  1.80s/it]Epoch: 2, Loss: 0.0801:  84%|████████▎ | 36/43 [01:04<00:12,  1.83s/it]Epoch: 2, Loss: 0.1056:  84%|████████▎ | 36/43 [01:05<00:12,  1.83s/it]Epoch: 2, Loss: 0.1056:  86%|████████▌ | 37/43 [01:05<00:10,  1.78s/it]Epoch: 2, Loss: 0.0798:  86%|████████▌ | 37/43 [01:07<00:10,  1.78s/it]Epoch: 2, Loss: 0.0798:  88%|████████▊ | 38/43 [01:07<00:08,  1.77s/it]Epoch: 2, Loss: 0.0483:  88%|████████▊ | 38/43 [01:09<00:08,  1.77s/it]Epoch: 2, Loss: 0.0483:  91%|█████████ | 39/43 [01:09<00:06,  1.75s/it]Epoch: 2, Loss: 0.0975:  91%|█████████ | 39/43 [01:10<00:06,  1.75s/it]Epoch: 2, Loss: 0.0975:  93%|█████████▎| 40/43 [01:11<00:05,  1.73s/it]Epoch: 2, Loss: 0.1513:  93%|█████████▎| 40/43 [01:12<00:05,  1.73s/it]Epoch: 2, Loss: 0.1513:  95%|█████████▌| 41/43 [01:12<00:03,  1.73s/it]Epoch: 2, Loss: 0.0964:  95%|█████████▌| 41/43 [01:14<00:03,  1.73s/it]Epoch: 2, Loss: 0.0964:  98%|█████████▊| 42/43 [01:14<00:01,  1.73s/it]Epoch: 2, Loss: 0.1770:  98%|█████████▊| 42/43 [01:15<00:01,  1.73s/it]Epoch: 2, Loss: 0.1770: 100%|██████████| 43/43 [01:16<00:00,  1.68s/it]Epoch: 2, Loss: 0.1770: 100%|██████████| 43/43 [01:16<00:00,  1.77s/it]
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:01<00:01,  1.64s/it]100%|██████████| 2/2 [00:02<00:00,  1.44s/it]100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
  0%|          | 0/43 [00:00<?, ?it/s]/cluster/customapps/biomed/grlab/users/eglimar/conda/envs/inf-extr/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/cluster/customapps/biomed/grlab/users/eglimar/conda/envs/inf-extr/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Epoch: 3, Loss: 0.0964:   0%|          | 0/43 [00:01<?, ?it/s]Epoch: 3, Loss: 0.0964:   2%|▏         | 1/43 [00:01<01:16,  1.81s/it]Epoch: 3, Loss: 0.1142:   2%|▏         | 1/43 [00:03<01:16,  1.81s/it]Epoch: 3, Loss: 0.1142:   5%|▍         | 2/43 [00:03<01:14,  1.82s/it]Epoch: 3, Loss: 0.0723:   5%|▍         | 2/43 [00:05<01:14,  1.82s/it]Epoch: 3, Loss: 0.0723:   7%|▋         | 3/43 [00:05<01:10,  1.75s/it]Epoch: 3, Loss: 0.0419:   7%|▋         | 3/43 [00:06<01:10,  1.75s/it]Epoch: 3, Loss: 0.0419:   9%|▉         | 4/43 [00:07<01:08,  1.75s/it]Epoch: 3, Loss: 0.0629:   9%|▉         | 4/43 [00:08<01:08,  1.75s/it]Epoch: 3, Loss: 0.0629:  12%|█▏        | 5/43 [00:08<01:07,  1.77s/it]Epoch: 3, Loss: 0.1057:  12%|█▏        | 5/43 [00:10<01:07,  1.77s/it]Epoch: 3, Loss: 0.1057:  14%|█▍        | 6/43 [00:10<01:04,  1.74s/it]Epoch: 3, Loss: 0.1087:  14%|█▍        | 6/43 [00:12<01:04,  1.74s/it]Epoch: 3, Loss: 0.1087:  16%|█▋        | 7/43 [00:12<01:02,  1.73s/it]Epoch: 3, Loss: 0.3709:  16%|█▋        | 7/43 [00:13<01:02,  1.73s/it]Epoch: 3, Loss: 0.3709:  19%|█▊        | 8/43 [00:13<01:00,  1.73s/it]Epoch: 3, Loss: 0.0631:  19%|█▊        | 8/43 [00:15<01:00,  1.73s/it]Epoch: 3, Loss: 0.0631:  21%|██        | 9/43 [00:15<00:58,  1.73s/it]Epoch: 3, Loss: 0.1116:  21%|██        | 9/43 [00:17<00:58,  1.73s/it]Epoch: 3, Loss: 0.1116:  23%|██▎       | 10/43 [00:17<00:58,  1.76s/it]Epoch: 3, Loss: 0.1954:  23%|██▎       | 10/43 [00:19<00:58,  1.76s/it]Epoch: 3, Loss: 0.1954:  26%|██▌       | 11/43 [00:19<00:55,  1.74s/it]Epoch: 3, Loss: 0.1774:  26%|██▌       | 11/43 [00:20<00:55,  1.74s/it]Epoch: 3, Loss: 0.1774:  28%|██▊       | 12/43 [00:21<00:54,  1.75s/it]Epoch: 3, Loss: 0.0863:  28%|██▊       | 12/43 [00:22<00:54,  1.75s/it]Epoch: 3, Loss: 0.0863:  30%|███       | 13/43 [00:22<00:53,  1.77s/it]Epoch: 3, Loss: 0.1422:  30%|███       | 13/43 [00:24<00:53,  1.77s/it]Epoch: 3, Loss: 0.1422:  33%|███▎      | 14/43 [00:24<00:50,  1.74s/it]Epoch: 3, Loss: 0.0574:  33%|███▎      | 14/43 [00:26<00:50,  1.74s/it]Epoch: 3, Loss: 0.0574:  35%|███▍      | 15/43 [00:26<00:48,  1.75s/it]Epoch: 3, Loss: 0.0544:  35%|███▍      | 15/43 [00:27<00:48,  1.75s/it]Epoch: 3, Loss: 0.0544:  37%|███▋      | 16/43 [00:27<00:46,  1.74s/it]Epoch: 3, Loss: 0.1727:  37%|███▋      | 16/43 [00:29<00:46,  1.74s/it]Epoch: 3, Loss: 0.1727:  40%|███▉      | 17/43 [00:29<00:44,  1.72s/it]Epoch: 3, Loss: 0.0566:  40%|███▉      | 17/43 [00:31<00:44,  1.72s/it]Epoch: 3, Loss: 0.0566:  42%|████▏     | 18/43 [00:31<00:43,  1.75s/it]Epoch: 3, Loss: 0.1432:  42%|████▏     | 18/43 [00:33<00:43,  1.75s/it]Epoch: 3, Loss: 0.1432:  44%|████▍     | 19/43 [00:33<00:42,  1.77s/it]Epoch: 3, Loss: 0.1036:  44%|████▍     | 19/43 [00:34<00:42,  1.77s/it]Epoch: 3, Loss: 0.1036:  47%|████▋     | 20/43 [00:34<00:40,  1.74s/it]Epoch: 3, Loss: 0.1255:  47%|████▋     | 20/43 [00:36<00:40,  1.74s/it]Epoch: 3, Loss: 0.1255:  49%|████▉     | 21/43 [00:36<00:38,  1.73s/it]Epoch: 3, Loss: 0.0555:  49%|████▉     | 21/43 [00:38<00:38,  1.73s/it]Epoch: 3, Loss: 0.0555:  51%|█████     | 22/43 [00:38<00:36,  1.72s/it]Epoch: 3, Loss: 0.1317:  51%|█████     | 22/43 [00:40<00:36,  1.72s/it]Epoch: 3, Loss: 0.1317:  53%|█████▎    | 23/43 [00:40<00:35,  1.79s/it]Epoch: 3, Loss: 0.1178:  53%|█████▎    | 23/43 [00:42<00:35,  1.79s/it]Epoch: 3, Loss: 0.1178:  56%|█████▌    | 24/43 [00:42<00:36,  1.90s/it]Epoch: 3, Loss: 0.2202:  56%|█████▌    | 24/43 [00:44<00:36,  1.90s/it]Epoch: 3, Loss: 0.2202:  58%|█████▊    | 25/43 [00:44<00:33,  1.85s/it]Epoch: 3, Loss: 0.0496:  58%|█████▊    | 25/43 [00:45<00:33,  1.85s/it]Epoch: 3, Loss: 0.0496:  60%|██████    | 26/43 [00:45<00:30,  1.81s/it]Epoch: 3, Loss: 0.0340:  60%|██████    | 26/43 [00:47<00:30,  1.81s/it]Epoch: 3, Loss: 0.0340:  63%|██████▎   | 27/43 [00:47<00:29,  1.83s/it]Epoch: 3, Loss: 0.1050:  63%|██████▎   | 27/43 [00:49<00:29,  1.83s/it]Epoch: 3, Loss: 0.1050:  65%|██████▌   | 28/43 [00:49<00:27,  1.82s/it]Epoch: 3, Loss: 0.0923:  65%|██████▌   | 28/43 [00:51<00:27,  1.82s/it]Epoch: 3, Loss: 0.0923:  67%|██████▋   | 29/43 [00:51<00:24,  1.78s/it]Epoch: 3, Loss: 0.0444:  67%|██████▋   | 29/43 [00:53<00:24,  1.78s/it]Epoch: 3, Loss: 0.0444:  70%|██████▉   | 30/43 [00:53<00:22,  1.76s/it]Epoch: 3, Loss: 0.0471:  70%|██████▉   | 30/43 [00:54<00:22,  1.76s/it]Epoch: 3, Loss: 0.0471:  72%|███████▏  | 31/43 [00:54<00:21,  1.78s/it]Epoch: 3, Loss: 0.0900:  72%|███████▏  | 31/43 [00:56<00:21,  1.78s/it]Epoch: 3, Loss: 0.0900:  74%|███████▍  | 32/43 [00:56<00:19,  1.75s/it]Epoch: 3, Loss: 0.0538:  74%|███████▍  | 32/43 [00:58<00:19,  1.75s/it]Epoch: 3, Loss: 0.0538:  77%|███████▋  | 33/43 [00:58<00:17,  1.74s/it]Epoch: 3, Loss: 0.0593:  77%|███████▋  | 33/43 [00:59<00:17,  1.74s/it]Epoch: 3, Loss: 0.0593:  79%|███████▉  | 34/43 [01:00<00:15,  1.76s/it]Epoch: 3, Loss: 0.1478:  79%|███████▉  | 34/43 [01:01<00:15,  1.76s/it]Epoch: 3, Loss: 0.1478:  81%|████████▏ | 35/43 [01:01<00:14,  1.79s/it]Epoch: 3, Loss: 0.0794:  81%|████████▏ | 35/43 [01:03<00:14,  1.79s/it]Epoch: 3, Loss: 0.0794:  84%|████████▎ | 36/43 [01:03<00:12,  1.77s/it]Epoch: 3, Loss: 0.0957:  84%|████████▎ | 36/43 [01:05<00:12,  1.77s/it]Epoch: 3, Loss: 0.0957:  86%|████████▌ | 37/43 [01:05<00:10,  1.77s/it]Epoch: 3, Loss: 0.1812:  86%|████████▌ | 37/43 [01:07<00:10,  1.77s/it]Epoch: 3, Loss: 0.1812:  88%|████████▊ | 38/43 [01:07<00:08,  1.77s/it]Epoch: 3, Loss: 0.1358:  88%|████████▊ | 38/43 [01:08<00:08,  1.77s/it]Epoch: 3, Loss: 0.1358:  91%|█████████ | 39/43 [01:08<00:07,  1.77s/it]Epoch: 3, Loss: 0.1335:  91%|█████████ | 39/43 [01:10<00:07,  1.77s/it]Epoch: 3, Loss: 0.1335:  93%|█████████▎| 40/43 [01:10<00:05,  1.76s/it]Epoch: 3, Loss: 0.1945:  93%|█████████▎| 40/43 [01:12<00:05,  1.76s/it]Epoch: 3, Loss: 0.1945:  95%|█████████▌| 41/43 [01:12<00:03,  1.77s/it]Epoch: 3, Loss: 0.1028:  95%|█████████▌| 41/43 [01:14<00:03,  1.77s/it]Epoch: 3, Loss: 0.1028:  98%|█████████▊| 42/43 [01:14<00:01,  1.81s/it]Epoch: 3, Loss: 0.1118:  98%|█████████▊| 42/43 [01:15<00:01,  1.81s/it]Epoch: 3, Loss: 0.1118: 100%|██████████| 43/43 [01:15<00:00,  1.73s/it]Epoch: 3, Loss: 0.1118: 100%|██████████| 43/43 [01:15<00:00,  1.77s/it]
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:01<00:01,  1.64s/it]100%|██████████| 2/2 [00:02<00:00,  1.43s/it]100%|██████████| 2/2 [00:02<00:00,  1.49s/it]
