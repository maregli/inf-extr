/bin/bash: /cluster/customapps/biomed/grlab/users/eglimar/conda/envs/inf-extr/lib/libtinfo.so.6: no version information available (required by /bin/bash)
/cluster/home/eglimar/.env_bootstrap/dotfiles/shell/bashrc: line 17: module: command not found
/cluster/home/eglimar/.env_bootstrap/dotfiles/shell/bashrc: line 20: module: command not found
Map:   0%|          | 0/123 [00:00<?, ? examples/s]Map: 100%|██████████| 123/123 [00:00<00:00, 565.11 examples/s]Map: 100%|██████████| 123/123 [00:00<00:00, 556.52 examples/s]
Map:   0%|          | 0/14 [00:00<?, ? examples/s]Map: 100%|██████████| 14/14 [00:00<00:00, 535.14 examples/s]
Map:   0%|          | 0/59 [00:00<?, ? examples/s]Map: 100%|██████████| 59/59 [00:00<00:00, 623.02 examples/s]
Map:   0%|          | 0/220 [00:00<?, ? examples/s]Map: 100%|██████████| 220/220 [00:00<00:00, 824.12 examples/s]Map: 100%|██████████| 220/220 [00:00<00:00, 815.08 examples/s]
  0%|          | 0/15 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  7%|▋         | 1/15 [00:02<00:34,  2.47s/it] 33%|███▎      | 5/15 [00:02<00:03,  2.55it/s] 60%|██████    | 9/15 [00:02<00:01,  5.19it/s] 87%|████████▋ | 13/15 [00:02<00:00,  8.36it/s]100%|██████████| 15/15 [00:02<00:00,  5.26it/s]
Map:   0%|          | 0/123 [00:00<?, ? examples/s]Map: 100%|██████████| 123/123 [00:00<00:00, 668.24 examples/s]Map: 100%|██████████| 123/123 [00:00<00:00, 658.21 examples/s]
Map:   0%|          | 0/14 [00:00<?, ? examples/s]Map: 100%|██████████| 14/14 [00:00<00:00, 669.70 examples/s]
Map:   0%|          | 0/59 [00:00<?, ? examples/s]Map: 100%|██████████| 59/59 [00:00<00:00, 783.54 examples/s]
Map:   0%|          | 0/220 [00:00<?, ? examples/s]Map: 100%|██████████| 220/220 [00:00<00:00, 762.39 examples/s]Map: 100%|██████████| 220/220 [00:00<00:00, 750.01 examples/s]
  0%|          | 0/15 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  7%|▋         | 1/15 [00:00<00:09,  1.54it/s] 33%|███▎      | 5/15 [00:00<00:01,  8.24it/s] 60%|██████    | 9/15 [00:00<00:00, 14.53it/s] 93%|█████████▎| 14/15 [00:00<00:00, 21.34it/s]100%|██████████| 15/15 [00:01<00:00, 14.87it/s]
Map:   0%|          | 0/123 [00:00<?, ? examples/s]Map: 100%|██████████| 123/123 [00:00<00:00, 697.42 examples/s]Map: 100%|██████████| 123/123 [00:00<00:00, 685.61 examples/s]
Map:   0%|          | 0/14 [00:00<?, ? examples/s]Map: 100%|██████████| 14/14 [00:00<00:00, 547.90 examples/s]
Map:   0%|          | 0/59 [00:00<?, ? examples/s]Map: 100%|██████████| 59/59 [00:00<00:00, 622.99 examples/s]
Map:   0%|          | 0/220 [00:00<?, ? examples/s]Map: 100%|██████████| 220/220 [00:00<00:00, 823.74 examples/s]Map: 100%|██████████| 220/220 [00:00<00:00, 814.11 examples/s]
  0%|          | 0/15 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  7%|▋         | 1/15 [00:00<00:07,  1.81it/s] 40%|████      | 6/15 [00:00<00:00, 11.31it/s] 73%|███████▎  | 11/15 [00:00<00:00, 19.32it/s]100%|██████████| 15/15 [00:00<00:00, 17.31it/s]
