{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3218e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd()+\"/../..\")\n",
    "from src import paths\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from src.data import data_loader\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3737b0",
   "metadata": {},
   "source": [
    "## Kisim Diagnosis\n",
    "\n",
    "There are multiple subdirectotires relating to imports from different dates in the data/seantis directory. There seem to be two files of interest for the MS task: diagnoses.csv and kisim_diagnoses.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a82305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nested_csv(dir_name: str, file_name: str):\n",
    "    \"\"\"\n",
    "    Returns a joint pandas dataframe from the files matching file_name\n",
    "    in all the different import dates subdirectories of the directory\n",
    "    specified by dir_name\n",
    "    \n",
    "    :param dir_name: The name of the directory (e.g. \"seantis\")\n",
    "    :param file_name: The name of the csv file to be read. (e.g. \"diagnoses.csv\")\n",
    "    \"\"\"\n",
    "    list_dfs = []\n",
    "\n",
    "    for root, dirs, files in os.walk(os.path.join(paths.DATA_PATH_RAW, dir_name)):\n",
    "        \n",
    "        if root.split(os.sep)[-1].startswith(\"imported_\"):\n",
    "            try:\n",
    "                _df = pd.read_csv(os.path.join(root, file_name))\n",
    "                list_dfs.append(_df)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found in: {root}\")\n",
    "                continue\n",
    "            except UnicodeDecodeError:\n",
    "                print(f\"UnicodeDecodeError in: {root}\")\n",
    "                continue\n",
    "\n",
    "    df = pd.concat(list_dfs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2701d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnoses.csv files\n",
    "diagnoses = get_nested_csv(\"seantis\", \"diagnoses.csv\")\n",
    "display(diagnoses.head())\n",
    "\n",
    "# Count duplicate research ids\n",
    "print(\"Duplicate research_ids: \", diagnoses.research_id.duplicated().sum())\n",
    "\n",
    "# List unique diseases:\n",
    "print(\"Unique Diseases:\\n\", diagnoses.disease.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73540e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kisim Diagnoses \n",
    "kisim_diagnoses = get_nested_csv(\"seantis\", \"kisim_diagnoses.csv\")\n",
    "display(kisim_diagnoses.head())\n",
    "\n",
    "#Count duplicate diagnosis ids\n",
    "print(\"Duplicate diagnosis_id: \", kisim_diagnoses.diagnosis_id.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1629f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for a kisim_diagnosis\n",
    "kisim_diagnoses.diagnosis_label.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08bc592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reports diagnosis\n",
    "reports_kisim_diagnoses = get_nested_csv(\"reports_with_struct_data\",\n",
    "                                         \"reports_kisim_diagnoses.csv\")\n",
    "reports_kisim_diagnoses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa768742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if these are identical to kisim_diagnoses\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "reports_kisim_diagnoses[reports_kisim_diagnoses.diagnosis_id == kisim_diagnoses.diagnosis_id.iloc[0]].diagnosis_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ce5804",
   "metadata": {},
   "source": [
    "## Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43342f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(os.path.join(paths.DATA_PATH_RAW, \"reports_with_struct_data\", \"imported_20201612\", \"reports\", \"RNOSPOL02-29052941.json\")) as f:\n",
    "    reports_kisim_diagnoses_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e65ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(d, parent_key='', sep='_'):\n",
    "    \"\"\"\n",
    "    Flattens a nested JSON dict and handles the special case where there is an \"Item\" key with \"@num\" and \"CONTENT\" values.\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            # Handle special case where there is an \"Item\" key with \"@num\" and \"CONTENT\" values\n",
    "            if \"Item\" in v.keys():\n",
    "                try:\n",
    "                    item_num = v[\"Item\"][\"@num\"]\n",
    "                    item_content = v[\"Item\"][\"CONTENT\"]\n",
    "                    items.append((new_key + sep + \"Item_\" + item_num, item_content))\n",
    "                    del v[\"Item\"]\n",
    "                except TypeError:\n",
    "                    print(f\"TypeError in {new_key}\")\n",
    "                    continue\n",
    "                items.extend(flatten_json(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "        \n",
    "\n",
    "def get_nested_json(path: str):\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "    return flatten_json(data)\n",
    "\n",
    "\n",
    "def get_reports():\n",
    "    \"\"\"\n",
    "    Returns the reports dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    # research_id and filename are stored in reports_with_struct_data/reportfilename_researchid.csv files\n",
    "    rid_filename = get_nested_csv(\"reports_with_struct_data\", \"reportfilename_researchid.csv\")\n",
    "\n",
    "    # Reports are in JSON format in reports_with_struct_data/reports\n",
    "    # We need to 1) read the JSON files 2) flatten them to pd.DataFrame() format and 3) add the research_id from the csv files\n",
    "    ls_reports = []\n",
    "\n",
    "    for root, dirs, files in os.walk(os.path.join(paths.DATA_PATH_RAW, \"reports_with_struct_data\")):\n",
    "\n",
    "        # All reports are in the reports folder\n",
    "        if root.endswith(\"reports\"):\n",
    "            for file in files:\n",
    "                try: \n",
    "                    # Get the research_id from the csv file\n",
    "                    _rid = rid_filename[rid_filename.report_filename + \".json\" == file].research_id.iloc[0]\n",
    "\n",
    "                    # Read the JSON file\n",
    "                    with open(os.path.join(root, file)) as f:\n",
    "                        _json = json.load(f)\n",
    "                    _df = pd.json_normalize(_json)\n",
    "\n",
    "                    # Add the research_id\n",
    "                    _df[\"research_id\"] = _rid\n",
    "\n",
    "                    # Append _df to list\n",
    "                    ls_reports.append(_df)\n",
    "                \n",
    "                except IndexError:\n",
    "                    print(f\"No research_id found for {file}\")\n",
    "                    continue\n",
    "    \n",
    "    return pd.concat(ls_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c5c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reports = get_reports()\n",
    "df_reports.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2986e79b",
   "metadata": {},
   "source": [
    "## Questions\n",
    "### diagnoses.csv\n",
    "- What is the purpose of diagnoses.csv? \n",
    "- Is the diagnosis the disease in? How does it differ from the diagnosis_label in kisim_diagnosis?\n",
    "- Why are there duplicate research_ids? Are there multiple diagnoses per patient?\n",
    "- Are the unique labels all different diseases, or are they maybe coded differently for different imports?\n",
    "\n",
    "### kisim_diagnoses\n",
    "- What is the purpose of kisim_diagnosis? \n",
    "- Why are there duplicate diagnosis_ids (shouldn't they be unique)?\n",
    "\n",
    "### reports_with_struct_data/reports_kisim_diagnoses\n",
    "- Are these identical to the kisim_diagnoses? From the example it seems so\n",
    "\n",
    "### Reports\n",
    "- What exactly are the entries in the JSON that are of importance? ZUSATZ? FORM? Visum?\n",
    "\n",
    "### Goal\n",
    "- Do you want me to map from kisim_diagnosis.diagnosis_label (input) to a class in diagnoses.disease (output)? \n",
    "- How would I know which input corresponds to which output if there are multiple diagnoses_ids and research_ids?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
