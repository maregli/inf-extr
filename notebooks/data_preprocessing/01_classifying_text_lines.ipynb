{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying text lines\n",
    "\n",
    "A classifier is trained to classify single text lines of a report. For example, the lines can be classified as containing a diagnosis (`\"dm\"`) or history (`his`) of a patient. This task was used as a preprocessing step to later steps of structured information extraction. So that only lines classified as containing a diagnosis will be fed to a downstream classifier, extracting the exact diagnosis. This step might be unnecessary with modern transformers that can handle longer text inputs. But it could still help by only feeding relevant input. Even more important old approach only trained and evaluated classifier 2 (MS-Diag) on reports containing \"dm\", which gives a more accurate idea of the whole pipeline.\n",
    "\n",
    "The files containing the necessary information are inside the `data/raw/labelling` directory. It contains manually labelled reports from different sessions.\n",
    "\n",
    "The original classes per label are:\n",
    "\n",
    "| category    | subcategory       | abbreviation |\n",
    "|-------------|-------------------|--------------|\n",
    "| diagnosis   | MS diagnosis      | dm           |\n",
    "|             | other             | do           |\n",
    "| current state     |              | cu           |\n",
    "| history     |                   | his          |\n",
    "| symptoms    | MS related        | sym          |\n",
    "|             | other             | so           |\n",
    "| MRI | results                  | mr           |\n",
    "| lab | results                  | labr         |\n",
    "|             | other             | labo         |\n",
    "| medication  | MS related        | medms        |\n",
    "|             | other             | medo         |\n",
    "| test, treatment        | results | tr           |\n",
    "| header      |                   | head         |\n",
    "| unknown     |                   | unk          |\n",
    "\n",
    "I will group the classes according to the original approach, and drop observations with no text or label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd()+\"/../..\")\n",
    "\n",
    "from src import paths\n",
    "from src.utils import line_Label_label2id\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_line_labelling():\n",
    "    \"\"\"Loading the data from the nested csv files in the different \"imported_time\" directories. Labelled reports have a \"rev.csv\" ending\n",
    "    and are in a \"_Marc\" subdirectory. There should only be one entry per rid, that is labelled. Duplicates will be removed.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with columns: \"text\", \"class\", \"rid\"\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    rid_list = []\n",
    "\n",
    "    for root, dirs, files in os.walk(paths.DATA_PATH_LABELLED):\n",
    "        if \"Marc\" not in root:\n",
    "            continue\n",
    "        for file in files:\n",
    "\n",
    "            # Get the research id from filename\n",
    "            rid = file.split(\"_\")[0]\n",
    "            \n",
    "            # Check if the file is a labelled report (and not mri) and if the rid is already in the list\n",
    "            if (file.endswith(\"rev.csv\") and \"mri\" not in file and rid not in rid_list):\n",
    "                \n",
    "                # Append rid to rid list to keep track of which files have been added\n",
    "                rid_list.append(rid)\n",
    "\n",
    "                # Create a dataframe from the csv file\n",
    "                _df = pd.read_csv(os.path.join(root, file))\n",
    "                \n",
    "                # Add the rid to the dataframe\n",
    "                _df = _df.rename(columns={\"text\": \"text\", \"class\": \"class\"})\n",
    "                _df['rid'] = rid\n",
    "                \n",
    "                # Append the dataframe to the main dataframe\n",
    "                try: \n",
    "                    df_list.append(_df)\n",
    "                except:\n",
    "                    print(\"Error with file: \", file)\n",
    "                    print(\"df head: \", _df.head(5))\n",
    "                    print(\"_df head: \", _df.head(5))\n",
    "                    continue\n",
    "    print(\"Number of reports: \", len(df_list))\n",
    "    return pd.concat(df_list)[[\"text\", \"class\", \"rid\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line_text(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    For Transformer to work, there has to be text in the text column. If there is no text, the text column is removed.\n",
    "    \"\"\"\n",
    "    df = df.dropna(subset=[\"text\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_line_class(df: pd.DataFrame):\n",
    "    \"\"\"Cleans the dataframe labels in \"class\".\n",
    "    1) Removes whitespace from beginning and end of text\n",
    "    2) Correct spelling mistakes\n",
    "    3) Fill NaN values with \"unk\"\n",
    "    4) Create a new column \"class_agg\" with the aggregated classes of the original approach.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Class mapping spelling mistakes\n",
    "    class_mapping_spelling = {\n",
    "        'memds': 'medms',\n",
    "        'hs': 'his',\n",
    "        'm': 'mr',\n",
    "    }\n",
    "    class_mapping_agg = {\n",
    "        'his': 'his_sym_cu',\n",
    "        'sym': 'his_sym_cu',\n",
    "        'cu': 'his_sym_cu',\n",
    "        'labr': 'labr_labo',\n",
    "        'labo': 'labr_labo',\n",
    "        'to': 'to_tr',\n",
    "        'tr': 'to_tr',\n",
    "        'medo': 'medo_unk_do_so',\n",
    "        'unk': 'medo_unk_do_so',\n",
    "        'do': 'medo_unk_do_so',\n",
    "        'so': 'medo_unk_do_so',\n",
    "    }\n",
    "\n",
    "    # Cleaning the class column\n",
    "    df['class'] = df['class'].str.strip() \\\n",
    "                             .replace(class_mapping_spelling) \\\n",
    "                             .fillna(\"unk\") \n",
    "\n",
    "    # Creating a new column with the aggregated classes\n",
    "    df['class_agg'] = df['class'].replace(class_mapping_agg)\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_clean_line_df():\n",
    "    \"\"\"Loads and cleans the dataframe from the load_line_labelling function.\n",
    "    \"\"\"\n",
    "    df = load_line_labelling()\n",
    "    df = clean_line_text(df)\n",
    "    df = clean_line_class(df)\n",
    "\n",
    "    return df[[\"rid\", \"text\", \"class\", \"class_agg\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reports:  74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>class_agg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41</td>\n",
       "      <td>Schubf√∂rmige Multiple Sklerose (RRMS), (ES/ED ...</td>\n",
       "      <td>dm</td>\n",
       "      <td>dm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41</td>\n",
       "      <td>Klinisch:- residuell: spastisches Gangbild rec...</td>\n",
       "      <td>sym</td>\n",
       "      <td>his_sym_cu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41</td>\n",
       "      <td>Verlauf: - 05/1999- 08/2011 rezidivierende Sch...</td>\n",
       "      <td>his</td>\n",
       "      <td>his_sym_cu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41</td>\n",
       "      <td>Diagnostisch:</td>\n",
       "      <td>head</td>\n",
       "      <td>head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41</td>\n",
       "      <td>INDENT - 1998 Liquor: oligoklonale Banden posi...</td>\n",
       "      <td>labr</td>\n",
       "      <td>labr_labo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    rid  \\\n",
       "0  3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41   \n",
       "1  3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41   \n",
       "2  3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41   \n",
       "3  3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41   \n",
       "4  3A79B7BD-39B6-4AE5-82C5-ADAB09B34A41   \n",
       "\n",
       "                                                text class   class_agg  \n",
       "0  Schubf√∂rmige Multiple Sklerose (RRMS), (ES/ED ...    dm          dm  \n",
       "1  Klinisch:- residuell: spastisches Gangbild rec...   sym  his_sym_cu  \n",
       "2  Verlauf: - 05/1999- 08/2011 rezidivierende Sch...   his  his_sym_cu  \n",
       "3                                      Diagnostisch:  head        head  \n",
       "4  INDENT - 1998 Liquor: oligoklonale Banden posi...  labr   labr_labo  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_agg values:  class_agg\n",
      "his_sym_cu        312\n",
      "mr                270\n",
      "head              236\n",
      "medms             213\n",
      "labr_labo         184\n",
      "medo_unk_do_so    139\n",
      "to_tr             114\n",
      "dm                 74\n",
      "Name: count, dtype: int64\n",
      "class values:  class\n",
      "mr       270\n",
      "head     236\n",
      "medms    213\n",
      "his      210\n",
      "labr     166\n",
      "tr        77\n",
      "dm        74\n",
      "sym       61\n",
      "unk       50\n",
      "do        42\n",
      "cu        41\n",
      "to        37\n",
      "medo      35\n",
      "labo      18\n",
      "so        12\n",
      "Name: count, dtype: int64\n",
      "Number of reports with missing values in class_agg:  0\n"
     ]
    }
   ],
   "source": [
    "df = load_clean_line_df()\n",
    "display(df.head(5))\n",
    "\n",
    "# Class distribution\n",
    "print(\"class_agg values: \", df.class_agg.value_counts())\n",
    "print(\"class values: \", df[\"class\"].value_counts())\n",
    "\n",
    "# Number of reports with missing values in class_agg\n",
    "print(\"Number of reports with missing values in class_agg: \", df[df[\"class_agg\"].isnull()].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "df.to_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line-label/line-label_clean.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train test split by rid\n",
    "rids = df.rid.unique()\n",
    "rids_train, rids_test = train_test_split(rids, test_size=0.2, random_state=42)\n",
    "rids_train, rids_val = train_test_split(rids_train, test_size=0.2, random_state=42)\n",
    "\n",
    "df_train = df[df.rid.isin(rids_train)]\n",
    "df_val = df[df.rid.isin(rids_val)]\n",
    "df_test = df[df.rid.isin(rids_test)]\n",
    "\n",
    "# Save the train, val and test dataframes\n",
    "df_train.to_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line-label/line-label_clean_train.csv\"))\n",
    "\n",
    "df_val.to_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line-label/line-label_clean_val.csv\"))\n",
    "\n",
    "df_test.to_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line-label/line-label_clean_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>text</th>\n",
       "      <th>class_agg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>016B6D16-2BBA-4C05-A8E4-30F761C95813</td>\n",
       "      <td>Diagnosen allgemein</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>016B6D16-2BBA-4C05-A8E4-30F761C95813</td>\n",
       "      <td>INDENT Schubf√∂rmige Multiple Sklerose EM 03.06...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>016B6D16-2BBA-4C05-A8E4-30F761C95813</td>\n",
       "      <td>INDENT 03/2021: klinisch nicht aktiv, radiolog...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>016B6D16-2BBA-4C05-A8E4-30F761C95813</td>\n",
       "      <td>INDENT 06/2019 Schub mit Hyp√§sthesie der Beine...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>016B6D16-2BBA-4C05-A8E4-30F761C95813</td>\n",
       "      <td>INDENT MRI WS 06/2019: kontrastmittelaufnehmen...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5664</th>\n",
       "      <td>C3997B98-9A42-4A63-A6EE-FC2BEDB78D14</td>\n",
       "      <td>INDENT Soor-Stomatitis, ED 07.02.2020</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5665</th>\n",
       "      <td>C3997B98-9A42-4A63-A6EE-FC2BEDB78D14</td>\n",
       "      <td>INDENT Bakterieller Harnwegsinfekt, ED 11.02.2020</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5666</th>\n",
       "      <td>C3997B98-9A42-4A63-A6EE-FC2BEDB78D14</td>\n",
       "      <td>INDENT Stomatitis aphthosa mit schmerzhafter A...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5667</th>\n",
       "      <td>C3997B98-9A42-4A63-A6EE-FC2BEDB78D14</td>\n",
       "      <td>INDENT Re-Soor-Stomatitis, ED 11.03.2020</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5668</th>\n",
       "      <td>C3997B98-9A42-4A63-A6EE-FC2BEDB78D14</td>\n",
       "      <td>Re-Soor-Stomatitis, ED 10.04.2020</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5669 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       rid  \\\n",
       "0     016B6D16-2BBA-4C05-A8E4-30F761C95813   \n",
       "1     016B6D16-2BBA-4C05-A8E4-30F761C95813   \n",
       "2     016B6D16-2BBA-4C05-A8E4-30F761C95813   \n",
       "3     016B6D16-2BBA-4C05-A8E4-30F761C95813   \n",
       "4     016B6D16-2BBA-4C05-A8E4-30F761C95813   \n",
       "...                                    ...   \n",
       "5664  C3997B98-9A42-4A63-A6EE-FC2BEDB78D14   \n",
       "5665  C3997B98-9A42-4A63-A6EE-FC2BEDB78D14   \n",
       "5666  C3997B98-9A42-4A63-A6EE-FC2BEDB78D14   \n",
       "5667  C3997B98-9A42-4A63-A6EE-FC2BEDB78D14   \n",
       "5668  C3997B98-9A42-4A63-A6EE-FC2BEDB78D14   \n",
       "\n",
       "                                                   text class_agg  \n",
       "0                                   Diagnosen allgemein      None  \n",
       "1     INDENT Schubf√∂rmige Multiple Sklerose EM 03.06...      None  \n",
       "2     INDENT 03/2021: klinisch nicht aktiv, radiolog...      None  \n",
       "3     INDENT 06/2019 Schub mit Hyp√§sthesie der Beine...      None  \n",
       "4     INDENT MRI WS 06/2019: kontrastmittelaufnehmen...      None  \n",
       "...                                                 ...       ...  \n",
       "5664              INDENT Soor-Stomatitis, ED 07.02.2020      None  \n",
       "5665  INDENT Bakterieller Harnwegsinfekt, ED 11.02.2020      None  \n",
       "5666  INDENT Stomatitis aphthosa mit schmerzhafter A...      None  \n",
       "5667           INDENT Re-Soor-Stomatitis, ED 11.03.2020      None  \n",
       "5668                  Re-Soor-Stomatitis, ED 10.04.2020      None  \n",
       "\n",
       "[5669 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading all of the data for dataset clf2 construction\n",
    "df_all = pd.read_csv(paths.DATA_PATH_PREPROCESSED/\"midatams/seantis_kisim.csv\")\n",
    "df_all = df_all[[\"research_id\", \"text\"]].rename(columns={\"research_id\": \"rid\"})\n",
    "df_all[\"class_agg\"] = None\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bed19e28e3d46cb9bab975a4917ea7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c98a4809fc41efbb53fb0bde0450b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/258 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7df3ae2eae645038ff013f8d032a2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/367 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0117ffe8a3e4431fa8494401437d3524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5669 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8db7eaa0f44c758f55b04bc7164f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d8f5c7f91941ab9e0ddc0490282c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/258 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9529bc17b067416781022ae032fdce6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/367 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ed6bedeb5c4eeab5a274eaa5f6b2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5669 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create HuggingFace Dataset\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train),\n",
    "    \"val\": Dataset.from_pandas(df_val),\n",
    "    \"test\": Dataset.from_pandas(df_test),\n",
    "})\n",
    "\n",
    "# Drop unnecessary columns\n",
    "dataset = dataset.remove_columns([\"class\", \"__index_level_0__\"])\n",
    "\n",
    "# Add the all dataset\n",
    "dataset[\"all\"] = Dataset.from_pandas(df_all)\n",
    "\n",
    "# Create labels \n",
    "dataset = dataset.map(lambda example: {\"labels\":[line_Label_label2id.get(e, None) for e in example[\"class_agg\"]]}, batched=True)\n",
    "\n",
    "# Save the dataset\n",
    "dataset.save_to_disk(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line-label/line-label_clean_dataset\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
