{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "
   "execution_count": 15,
378913395e87ca5fd716fb17b9e17ceefbf92226
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import DatasetDict\n",
    "import transformers\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd()+\"/../..\")\n",
    "from src import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download model\n",
    "# checkpoint = \"meta-llama/Llama-2-7b-hf\"\n",
    "# model = AutoModelForCausalLM.from_pretrained(checkpoint)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "# # Save model\n",
    "# model.save_pretrained(paths.MODEL_PATH/'llama2')\n",
    "\n",
    "# # Save tokenizer\n",
    "# tokenizer.save_pretrained(paths.MODEL_PATH/'llama2')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
||||||| d90eaa8
   "execution_count": null,
=======
   "execution_count": 22,
>>>>>>> 378913395e87ca5fd716fb17b9e17ceefbf92226
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(paths.MODEL_PATH/'llama2', padding_side='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8a294861ea4b78956d666ca90cdb86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(paths.MODEL_PATH/'llama2', device_map=\"auto\", load_in_4bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device of model.embed_tokens.weight:  cuda:0\n",
      "Device of model.layers.0.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.0.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.0.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.0.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.0.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.0.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.0.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.0.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.0.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.1.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.1.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.1.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.1.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.1.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.1.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.1.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.1.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.1.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.2.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.2.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.2.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.2.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.2.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.2.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.2.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.2.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.2.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.3.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.3.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.3.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.3.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.3.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.3.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.3.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.3.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.3.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.4.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.4.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.4.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.4.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.4.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.4.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.4.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.4.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.4.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.5.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.5.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.5.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.5.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.5.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.5.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.5.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.5.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.5.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.6.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.6.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.6.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.6.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.6.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.6.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.6.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.6.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.6.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.7.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.7.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.7.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.7.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.7.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.7.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.7.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.7.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.7.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.8.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.8.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.8.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.8.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.8.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.8.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.8.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.8.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.8.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.9.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.9.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.9.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.9.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.9.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.9.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.9.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.9.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.9.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.10.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.10.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.10.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.10.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.10.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.10.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.10.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.10.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.10.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.11.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.11.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.11.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.11.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.11.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.11.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.11.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.11.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.11.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.12.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.12.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.12.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.12.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.12.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.12.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.12.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.12.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.12.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.13.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.13.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.13.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.13.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.13.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.13.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.13.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.13.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.13.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.14.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.14.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.14.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.14.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.14.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.14.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.14.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.14.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.14.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.15.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.15.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.15.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.15.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.15.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.15.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.15.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.15.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.15.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.16.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.16.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.16.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.16.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.16.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.16.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.16.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.16.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.16.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.17.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.17.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.17.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.17.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.17.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.17.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.17.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.17.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.17.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.18.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.18.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.18.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.18.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.18.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.18.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.18.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.18.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.18.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.19.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.19.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.19.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.19.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.19.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.19.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.19.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.19.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.19.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.20.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.20.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.20.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.20.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.20.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.20.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.20.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.20.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.20.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.21.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.21.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.21.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.21.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.21.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.21.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.21.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.21.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.21.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.22.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.22.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.22.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.22.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.22.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.22.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.22.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.22.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.22.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.23.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.23.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.23.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.23.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.23.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.23.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.23.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.23.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.23.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.24.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.24.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.24.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.24.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.24.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.24.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.24.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.24.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.24.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.25.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.25.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.25.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.25.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.25.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.25.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.25.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.25.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.25.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.26.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.26.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.26.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.26.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.26.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.26.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.26.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.26.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.26.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.27.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.27.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.27.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.27.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.27.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.27.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.27.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.27.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.27.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.28.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.28.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.28.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.28.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.28.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.28.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.28.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.28.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.28.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.29.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.29.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.29.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.29.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.29.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.29.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.29.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.29.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.29.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.30.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.30.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.30.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.30.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.30.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.30.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.30.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.30.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.30.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.layers.31.self_attn.q_proj.weight:  cuda:0\n",
      "Device of model.layers.31.self_attn.k_proj.weight:  cuda:0\n",
      "Device of model.layers.31.self_attn.v_proj.weight:  cuda:0\n",
      "Device of model.layers.31.self_attn.o_proj.weight:  cuda:0\n",
      "Device of model.layers.31.mlp.gate_proj.weight:  cuda:0\n",
      "Device of model.layers.31.mlp.up_proj.weight:  cuda:0\n",
      "Device of model.layers.31.mlp.down_proj.weight:  cuda:0\n",
      "Device of model.layers.31.input_layernorm.weight:  cuda:0\n",
      "Device of model.layers.31.post_attention_layernorm.weight:  cuda:0\n",
      "Device of model.norm.weight:  cuda:0\n",
      "Device of lm_head.weight:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Device of {name}: \", param.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict.load_from_disk(paths.DATA_PATH_PREPROCESSED/'line_labelling/line_labelling_clean_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946e4fb03bfd407cb0f1feefb7470bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"Categorize the following sentence into "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tokenizer(, return_tensors=\"pt\").to(\"cuda\")\n",
    "model_inputs = {k: v.to(torch.int32).to(\"cuda\") for k, v in model_inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs['input_ids'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = model.generate(**model_inputs, max_new_tokens=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A list of colors: red, blue, and yellow. профн.\\n1. The list of colors: red, blue, and'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 35,
||||||| d90eaa8
   "execution_count": null,
=======
   "execution_count": 17,
>>>>>>> 378913395e87ca5fd716fb17b9e17ceefbf92226
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: I liked \"Breaking Bad\" and \"Band of Brothers\". Do you have any recommendations of other shows I might like?\n",
      " Unterscheidung: Die Schlacht im Hürtgenwald. München: List, 2003.\n",
      "# 3\n",
      "# 1945\n",
      "Ich warf den Kopf auf die Seite und starrte auf den Boden. Die Erde war von einer schmutzigen, dicken Asche bedeckt. Das Blut von den Wunden, die ich auf der Stelle bekommen hatte, war von der Erde verblasst.\n",
      "Ich schlug die Augen wieder auf. Auf dem Boden vor mir lag ein Mann mit einem weißen Hemd, das mit Blut und Schmutz übersät war. Seine Hände lagen auf der Brust, die Augen waren geschlossen, und die Mundwinkel waren gesenkt. Ich scha\n"
     ]
    }
   ],
||||||| d90eaa8
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: I liked \"Breaking Bad\" and \"Band of Brothers\". Do you have any recommendations of other shows I might like?\n",
      "I've heard great things about \"Mad Men\" and \"The Wire\" but I'm not sure if they're my cup of tea.\n",
      "Post by: TacoShack on June 02, 2015, 02:26:46 PM\n",
      "I've heard great things about \"Mad Men\" and \"The Wire\" but I'm not sure if they're my cup of tea\n",
      "Post by: jinga nation on June 02, 2015, 02:35:17 PM\n",
      "I've been watching \"The Americans\" on FX. It's a spy thriller set in the 80's. It's really well done.\n",
      "Post by: jinga nation on June\n"
     ]
    }
   ],
>>>>>>> 378913395e87ca5fd716fb17b9e17ceefbf92226
   "source": [
    "sequences = pipeline(\n",
    "    'I liked \"Breaking Bad\" and \"Band of Brothers\". Do you have any recommendations of other shows I might like?\\n',\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_length=200,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
||||||| d90eaa8
   "execution_count": null,
=======
   "execution_count": 6,
>>>>>>> 378913395e87ca5fd716fb17b9e17ceefbf92226
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[535]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
||||||| d90eaa8
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3978]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 378913395e87ca5fd716fb17b9e17ceefbf92226
   "source": [
    "import subprocess as sp\n",
    "import os\n",
    "\n",
    "def get_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values\n",
    "\n",
    "get_gpu_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
