{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel, DataCollatorWithPadding, get_scheduler\n",
    "from datasets import load_dataset, concatenate_datasets, Dataset\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd()+\"/../..\")\n",
    "\n",
    "from src import paths\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import evaluate \n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artifical_data_for_label(label:str):\n",
    "    label_dict = {\n",
    "        \"rrms\": \"relapsing_remitting_multiple_sclerosis\",\n",
    "        \"ppms\": \"primary_progressive_multiple_sclerosis\",\n",
    "        \"spms\": \"secondary_progressive_multiple_sclerosis\"\n",
    "    }\n",
    "    generated_data = pd.read_csv(paths.DATA_PATH_PREPROCESSED/f'ms-diag/artificial_{label}.csv')\n",
    "    generated_data[\"labels\"] = label_dict[label]\n",
    "    generated_data = generated_data[[\"0\", \"labels\"]].rename(columns = {\"0\":\"text\"})\n",
    "\n",
    "    return generated_data\n",
    "\n",
    "def get_artifical_data_all():\n",
    "    artifical_data = []\n",
    "    for label in [\"rrms\", \"ppms\", \"spms\"]:\n",
    "        try: \n",
    "            artifical_data.append(get_artifical_data_for_label(label))\n",
    "        except:\n",
    "            print(f\"Could not find data for {label}\")\n",
    "    artifical_data = pd.concat(artifical_data)\n",
    "    artifical_data = Dataset.from_pandas(artifical_data).remove_columns('__index_level_0__')\n",
    "    return artifical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find data for rrms\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_files = {\"train\": \"ms-diag_clean_train.csv\", \"validation\": \"ms-diag_clean_val.csv\", \"test\": \"ms-diag_clean_test.csv\"}\n",
    "df = load_dataset(os.path.join(paths.DATA_PATH_PREPROCESSED,'ms-diag'), data_files = data_files)\n",
    "df[\"train\"] = concatenate_datasets([get_artifical_data_all(), df[\"train\"]])\n",
    "\n",
    "# Number of labels\n",
    "num_labels = len(set(df['train']['labels']))\n",
    "\n",
    "# Label to id\n",
    "label2id = {'primary_progressive_multiple_sclerosis': 0,\n",
    "            'relapsing_remitting_multiple_sclerosis': 1,\n",
    "            'secondary_progressive_multiple_sclerosis': 2}\n",
    "id2label = {v:k for k,v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run this cell if you want to download and fine-tune the model\n",
    "# from huggingface_hub import notebook_login\n",
    "\n",
    "# # Login to Hugging Face Hub as model is gated\n",
    "# notebook_login()\n",
    "\n",
    "# # Checkpoint\n",
    "# checkpoint = \"GerMedBERT/medbert-512\"\n",
    "\n",
    "# # Load tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "# # Save tokenizer\n",
    "# tokenizer.save_pretrained(paths.MODEL_PATH/'medbert')\n",
    "\n",
    "# # Load model for embedding\n",
    "# model = AutoModel.from_pretrained(checkpoint)\n",
    "\n",
    "# # Save model\n",
    "# model.save_pretrained(paths.MODEL_PATH/'medbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /cluster/dataset/midatams/inf-extr/resources/models/medbert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(paths.MODEL_PATH/'medbert')\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(paths.MODEL_PATH/'medbert', num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    \n",
    "    # Label\n",
    "    data['labels'] = [label2id[label] for label in data['labels']]\n",
    "\n",
    "    # Tokenize\n",
    "    # data[\"text\"] = [text[:256] for text in data[\"text\"]]\n",
    "    data = tokenizer(data['text'], padding=True, truncation=True, return_tensors='pt', max_length = 256)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Tokenize dataset\n",
    "dataset = df.map(prepare_data, batched=True, remove_columns=['rid', 'text', 'date'], batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Training arguments\n",
    "EPOCHS = 12\n",
    "BATCH_SIZE = 16\n",
    "TRAIN_STEPS = EPOCHS * len(dataset['train']) // BATCH_SIZE\n",
    "\n",
    "# Collator\n",
    "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer, padding=True, return_tensors='pt')\n",
    "\n",
    "# Dataloader\n",
    "train_loader = DataLoader(dataset['train'], batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)\n",
    "val_loader = DataLoader(dataset['validation'], batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False)\n",
    "test_loader = DataLoader(dataset['test'], batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False)\n",
    "\n",
    "# Accelerator\n",
    "accelerator = Accelerator(mixed_precision='fp16')\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optim = AdamW(model.parameters(), lr=1e-4)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optim,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=TRAIN_STEPS\n",
    ")\n",
    "\n",
    "# Prepare with accelerator\n",
    "model, optim, train_loader, val_loader, test_loader = accelerator.prepare(\n",
    "    model, optim, train_loader, val_loader, test_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "288it [02:05,  2.29it/s]00:00<?, ?it/s]\u001b[A\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "\n",
      "  0%|          | 1/287 [00:00<00:43,  6.57it/s]\u001b[A\n",
      "  1%|          | 2/287 [00:00<00:39,  7.19it/s]\u001b[A\n",
      "  1%|          | 3/287 [00:00<00:38,  7.41it/s]\u001b[A\n",
      "  1%|▏         | 4/287 [00:00<00:37,  7.51it/s]\u001b[A\n",
      "  2%|▏         | 5/287 [00:00<00:37,  7.55it/s]\u001b[A\n",
      "  2%|▏         | 6/287 [00:00<00:37,  7.59it/s]\u001b[A\n",
      "  2%|▏         | 7/287 [00:00<00:36,  7.61it/s]\u001b[A\n",
      "  3%|▎         | 8/287 [00:01<00:36,  7.61it/s]\u001b[A\n",
      "  3%|▎         | 9/287 [00:01<00:36,  7.61it/s]\u001b[A\n",
      "  3%|▎         | 10/287 [00:01<00:36,  7.61it/s]\u001b[A\n",
      "  4%|▍         | 11/287 [00:01<00:36,  7.62it/s]\u001b[A\n",
      "  4%|▍         | 12/287 [00:01<00:36,  7.61it/s]\u001b[A\n",
      "  5%|▍         | 13/287 [00:01<00:35,  7.61it/s]\u001b[A\n",
      "  5%|▍         | 14/287 [00:01<00:35,  7.62it/s]\u001b[A\n",
      "  5%|▌         | 15/287 [00:01<00:35,  7.61it/s]\u001b[A\n",
      "  6%|▌         | 16/287 [00:02<00:35,  7.57it/s]\u001b[A\n",
      "  6%|▌         | 17/287 [00:02<00:35,  7.60it/s]\u001b[A\n",
      "  6%|▋         | 18/287 [00:02<00:35,  7.60it/s]\u001b[A\n",
      "  7%|▋         | 19/287 [00:02<00:35,  7.62it/s]\u001b[A\n",
      "  7%|▋         | 20/287 [00:02<00:35,  7.63it/s]\u001b[A\n",
      "  7%|▋         | 21/287 [00:02<00:34,  7.63it/s]\u001b[A\n",
      "  8%|▊         | 22/287 [00:02<00:34,  7.64it/s]\u001b[A\n",
      "  8%|▊         | 23/287 [00:03<00:34,  7.64it/s]\u001b[A\n",
      "  8%|▊         | 24/287 [00:03<00:33,  7.83it/s]\u001b[A\n",
      "  9%|▊         | 25/287 [00:03<00:36,  7.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: F1 score: 0.30769230769230765 Loss: 0.5312107801437378 Accuracy: 0.8571428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 26/287 [00:03<00:36,  7.25it/s]\u001b[A\n",
      "  9%|▉         | 27/287 [00:03<00:35,  7.35it/s]\u001b[A\n",
      " 10%|▉         | 28/287 [00:03<00:34,  7.42it/s]\u001b[A\n",
      " 10%|█         | 29/287 [00:03<00:34,  7.47it/s]\u001b[A\n",
      " 10%|█         | 30/287 [00:03<00:34,  7.51it/s]\u001b[A\n",
      " 11%|█         | 31/287 [00:04<00:33,  7.54it/s]\u001b[A\n",
      " 11%|█         | 32/287 [00:04<00:33,  7.57it/s]\u001b[A\n",
      " 11%|█▏        | 33/287 [00:04<00:33,  7.58it/s]\u001b[A\n",
      " 12%|█▏        | 34/287 [00:04<00:33,  7.58it/s]\u001b[A\n",
      " 12%|█▏        | 35/287 [00:04<00:33,  7.58it/s]\u001b[A\n",
      " 13%|█▎        | 36/287 [00:04<00:33,  7.59it/s]\u001b[A\n",
      " 13%|█▎        | 37/287 [00:04<00:32,  7.60it/s]\u001b[A\n",
      " 13%|█▎        | 38/287 [00:05<00:32,  7.60it/s]\u001b[A\n",
      " 14%|█▎        | 39/287 [00:05<00:32,  7.60it/s]\u001b[A\n",
      " 14%|█▍        | 40/287 [00:05<00:32,  7.61it/s]\u001b[A\n",
      " 14%|█▍        | 41/287 [00:05<00:32,  7.61it/s]\u001b[A\n",
      " 15%|█▍        | 42/287 [00:05<00:32,  7.62it/s]\u001b[A\n",
      " 15%|█▍        | 43/287 [00:05<00:32,  7.62it/s]\u001b[A\n",
      " 15%|█▌        | 44/287 [00:05<00:31,  7.63it/s]\u001b[A\n",
      " 16%|█▌        | 45/287 [00:05<00:32,  7.56it/s]\u001b[A\n",
      " 16%|█▌        | 46/287 [00:06<00:31,  7.58it/s]\u001b[A\n",
      " 16%|█▋        | 47/287 [00:06<00:31,  7.59it/s]\u001b[A\n",
      " 17%|█▋        | 48/287 [00:06<00:30,  7.77it/s]\u001b[A\n",
      " 17%|█▋        | 49/287 [00:06<00:34,  6.94it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: F1 score: 0.30769230769230765 Loss: 0.630799412727356 Accuracy: 0.8571428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 50/287 [00:06<00:33,  7.09it/s]\u001b[A\n",
      " 18%|█▊        | 51/287 [00:06<00:32,  7.25it/s]\u001b[A\n",
      " 18%|█▊        | 52/287 [00:06<00:31,  7.36it/s]\u001b[A\n",
      " 18%|█▊        | 53/287 [00:07<00:31,  7.44it/s]\u001b[A\n",
      " 19%|█▉        | 54/287 [00:07<00:31,  7.50it/s]\u001b[A\n",
      " 19%|█▉        | 55/287 [00:07<00:30,  7.53it/s]\u001b[A\n",
      " 20%|█▉        | 56/287 [00:07<00:30,  7.55it/s]\u001b[A\n",
      " 20%|█▉        | 57/287 [00:07<00:30,  7.57it/s]\u001b[A\n",
      " 20%|██        | 58/287 [00:07<00:30,  7.57it/s]\u001b[A\n",
      " 21%|██        | 59/287 [00:07<00:30,  7.59it/s]\u001b[A\n",
      " 21%|██        | 60/287 [00:07<00:29,  7.60it/s]\u001b[A\n",
      " 21%|██▏       | 61/287 [00:08<00:29,  7.61it/s]\u001b[A\n",
      " 22%|██▏       | 62/287 [00:08<00:29,  7.62it/s]\u001b[A\n",
      " 22%|██▏       | 63/287 [00:08<00:29,  7.63it/s]\u001b[A\n",
      " 22%|██▏       | 64/287 [00:08<00:29,  7.63it/s]\u001b[A\n",
      " 23%|██▎       | 65/287 [00:08<00:29,  7.63it/s]\u001b[A\n",
      " 23%|██▎       | 66/287 [00:08<00:28,  7.63it/s]\u001b[A\n",
      " 23%|██▎       | 67/287 [00:08<00:28,  7.63it/s]\u001b[A\n",
      " 24%|██▎       | 68/287 [00:09<00:28,  7.63it/s]\u001b[A\n",
      " 24%|██▍       | 69/287 [00:09<00:28,  7.62it/s]\u001b[A\n",
      " 24%|██▍       | 70/287 [00:09<00:28,  7.61it/s]\u001b[A\n",
      " 25%|██▍       | 71/287 [00:09<00:28,  7.62it/s]\u001b[A\n",
      " 25%|██▌       | 72/287 [00:09<00:27,  7.81it/s]\u001b[A\n",
      " 25%|██▌       | 73/287 [00:09<00:30,  7.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: F1 score: 0.6533333333333333 Loss: 0.3763735592365265 Accuracy: 0.9285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 74/287 [00:09<00:29,  7.24it/s]\u001b[A\n",
      " 26%|██▌       | 75/287 [00:09<00:29,  7.30it/s]\u001b[A\n",
      " 26%|██▋       | 76/287 [00:10<00:28,  7.39it/s]\u001b[A\n",
      " 27%|██▋       | 77/287 [00:10<00:28,  7.46it/s]\u001b[A\n",
      " 27%|██▋       | 78/287 [00:10<00:27,  7.50it/s]\u001b[A\n",
      " 28%|██▊       | 79/287 [00:10<00:27,  7.54it/s]\u001b[A\n",
      " 28%|██▊       | 80/287 [00:10<00:27,  7.57it/s]\u001b[A\n",
      " 28%|██▊       | 81/287 [00:10<00:27,  7.59it/s]\u001b[A\n",
      " 29%|██▊       | 82/287 [00:10<00:26,  7.69it/s]\u001b[A\n",
      " 29%|██▉       | 83/287 [00:11<00:26,  7.82it/s]\u001b[A\n",
      " 29%|██▉       | 84/287 [00:11<00:26,  7.77it/s]\u001b[A\n",
      " 30%|██▉       | 85/287 [00:11<00:26,  7.72it/s]\u001b[A\n",
      " 30%|██▉       | 86/287 [00:11<00:26,  7.69it/s]\u001b[A\n",
      " 30%|███       | 87/287 [00:11<00:26,  7.67it/s]\u001b[A\n",
      " 31%|███       | 88/287 [00:11<00:25,  7.66it/s]\u001b[A\n",
      " 31%|███       | 89/287 [00:11<00:25,  7.65it/s]\u001b[A\n",
      " 31%|███▏      | 90/287 [00:11<00:25,  7.64it/s]\u001b[A\n",
      " 32%|███▏      | 91/287 [00:12<00:25,  7.64it/s]\u001b[A\n",
      " 32%|███▏      | 92/287 [00:12<00:25,  7.55it/s]\u001b[A\n",
      " 32%|███▏      | 93/287 [00:12<00:25,  7.56it/s]\u001b[A\n",
      " 33%|███▎      | 94/287 [00:12<00:25,  7.59it/s]\u001b[A\n",
      " 33%|███▎      | 95/287 [00:12<00:25,  7.60it/s]\u001b[A\n",
      " 33%|███▎      | 96/287 [00:12<00:24,  7.80it/s]\u001b[A\n",
      " 34%|███▍      | 97/287 [00:12<00:26,  7.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: F1 score: 0.6533333333333333 Loss: 0.2975933849811554 Accuracy: 0.9285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 34%|███▍      | 98/287 [00:13<00:26,  7.23it/s]\u001b[A\n",
      " 34%|███▍      | 99/287 [00:13<00:25,  7.35it/s]\u001b[A\n",
      " 35%|███▍      | 100/287 [00:13<00:25,  7.43it/s]\u001b[A\n",
      " 35%|███▌      | 101/287 [00:13<00:24,  7.49it/s]\u001b[A\n",
      " 36%|███▌      | 102/287 [00:13<00:24,  7.52it/s]\u001b[A\n",
      " 36%|███▌      | 103/287 [00:13<00:24,  7.55it/s]\u001b[A\n",
      " 36%|███▌      | 104/287 [00:13<00:24,  7.57it/s]\u001b[A\n",
      " 37%|███▋      | 105/287 [00:13<00:23,  7.59it/s]\u001b[A\n",
      " 37%|███▋      | 106/287 [00:14<00:23,  7.61it/s]\u001b[A\n",
      " 37%|███▋      | 107/287 [00:14<00:23,  7.60it/s]\u001b[A\n",
      " 38%|███▊      | 108/287 [00:14<00:23,  7.60it/s]\u001b[A\n",
      " 38%|███▊      | 109/287 [00:14<00:23,  7.60it/s]\u001b[A\n",
      " 38%|███▊      | 110/287 [00:14<00:23,  7.61it/s]\u001b[A\n",
      " 39%|███▊      | 111/287 [00:14<00:23,  7.61it/s]\u001b[A\n",
      " 39%|███▉      | 112/287 [00:14<00:22,  7.61it/s]\u001b[A\n",
      " 39%|███▉      | 113/287 [00:14<00:22,  7.61it/s]\u001b[A\n",
      " 40%|███▉      | 114/287 [00:15<00:22,  7.61it/s]\u001b[A\n",
      " 40%|████      | 115/287 [00:15<00:22,  7.61it/s]\u001b[A\n",
      " 40%|████      | 116/287 [00:15<00:22,  7.60it/s]\u001b[A\n",
      " 41%|████      | 117/287 [00:15<00:22,  7.60it/s]\u001b[A\n",
      " 41%|████      | 118/287 [00:15<00:22,  7.60it/s]\u001b[A\n",
      " 41%|████▏     | 119/287 [00:15<00:22,  7.61it/s]\u001b[A\n",
      " 42%|████▏     | 120/287 [00:15<00:21,  7.80it/s]\u001b[A\n",
      " 42%|████▏     | 121/287 [00:16<01:05,  2.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: F1 score: 0.32 Loss: 0.6541276574134827 Accuracy: 0.8571428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████▎     | 122/287 [00:17<00:52,  3.15it/s]\u001b[A\n",
      " 43%|████▎     | 123/287 [00:17<00:42,  3.83it/s]\u001b[A\n",
      " 43%|████▎     | 124/287 [00:17<00:36,  4.50it/s]\u001b[A\n",
      " 44%|████▎     | 125/287 [00:17<00:31,  5.13it/s]\u001b[A\n",
      " 44%|████▍     | 126/287 [00:17<00:28,  5.67it/s]\u001b[A\n",
      " 44%|████▍     | 127/287 [00:17<00:26,  6.14it/s]\u001b[A\n",
      " 45%|████▍     | 128/287 [00:17<00:24,  6.51it/s]\u001b[A\n",
      " 45%|████▍     | 129/287 [00:17<00:23,  6.79it/s]\u001b[A\n",
      " 45%|████▌     | 130/287 [00:18<00:22,  7.01it/s]\u001b[A\n",
      " 46%|████▌     | 131/287 [00:18<00:21,  7.18it/s]\u001b[A\n",
      " 46%|████▌     | 132/287 [00:18<00:21,  7.27it/s]\u001b[A\n",
      " 46%|████▋     | 133/287 [00:18<00:20,  7.37it/s]\u001b[A\n",
      " 47%|████▋     | 134/287 [00:18<00:20,  7.44it/s]\u001b[A\n",
      " 47%|████▋     | 135/287 [00:18<00:20,  7.50it/s]\u001b[A\n",
      " 47%|████▋     | 136/287 [00:18<00:20,  7.52it/s]\u001b[A\n",
      " 48%|████▊     | 137/287 [00:19<00:19,  7.55it/s]\u001b[A\n",
      " 48%|████▊     | 138/287 [00:19<00:19,  7.57it/s]\u001b[A\n",
      " 48%|████▊     | 139/287 [00:19<00:19,  7.57it/s]\u001b[A\n",
      " 49%|████▉     | 140/287 [00:19<00:19,  7.58it/s]\u001b[A\n",
      " 49%|████▉     | 141/287 [00:19<00:19,  7.59it/s]\u001b[A\n",
      " 49%|████▉     | 142/287 [00:19<00:19,  7.60it/s]\u001b[A\n",
      " 50%|████▉     | 143/287 [00:19<00:18,  7.62it/s]\u001b[A\n",
      " 50%|█████     | 144/287 [00:19<00:18,  7.80it/s]\u001b[A\n",
      " 51%|█████     | 145/287 [00:20<00:20,  7.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: F1 score: 0.32 Loss: 0.651219367980957 Accuracy: 0.8571428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 51%|█████     | 146/287 [00:20<00:19,  7.23it/s]\u001b[A\n",
      " 51%|█████     | 147/287 [00:20<00:19,  7.33it/s]\u001b[A\n",
      " 52%|█████▏    | 148/287 [00:20<00:18,  7.41it/s]\u001b[A\n",
      " 52%|█████▏    | 149/287 [00:20<00:18,  7.46it/s]\u001b[A\n",
      " 52%|█████▏    | 150/287 [00:20<00:18,  7.49it/s]\u001b[A\n",
      " 53%|█████▎    | 151/287 [00:20<00:18,  7.52it/s]\u001b[A\n",
      " 53%|█████▎    | 152/287 [00:21<00:17,  7.55it/s]\u001b[A\n",
      " 53%|█████▎    | 153/287 [00:21<00:17,  7.57it/s]\u001b[A\n",
      " 54%|█████▎    | 154/287 [00:21<00:17,  7.58it/s]\u001b[A\n",
      " 54%|█████▍    | 155/287 [00:21<00:17,  7.59it/s]\u001b[A\n",
      " 54%|█████▍    | 156/287 [00:21<00:17,  7.59it/s]\u001b[A\n",
      " 55%|█████▍    | 157/287 [00:21<00:17,  7.59it/s]\u001b[A\n",
      " 55%|█████▌    | 158/287 [00:21<00:16,  7.60it/s]\u001b[A\n",
      " 55%|█████▌    | 159/287 [00:21<00:16,  7.60it/s]\u001b[A\n",
      " 56%|█████▌    | 160/287 [00:22<00:16,  7.56it/s]\u001b[A\n",
      " 56%|█████▌    | 161/287 [00:22<00:16,  7.61it/s]\u001b[A\n",
      " 56%|█████▋    | 162/287 [00:22<00:16,  7.61it/s]\u001b[A\n",
      " 57%|█████▋    | 163/287 [00:22<00:16,  7.57it/s]\u001b[A\n",
      " 57%|█████▋    | 164/287 [00:22<00:16,  7.57it/s]\u001b[A\n",
      " 57%|█████▋    | 165/287 [00:22<00:16,  7.57it/s]\u001b[A\n",
      " 58%|█████▊    | 166/287 [00:22<00:15,  7.58it/s]\u001b[A\n",
      " 58%|█████▊    | 167/287 [00:22<00:15,  7.58it/s]\u001b[A\n",
      " 59%|█████▊    | 168/287 [00:23<00:15,  7.77it/s]\u001b[A\n",
      " 59%|█████▉    | 169/287 [00:23<00:16,  7.06it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: F1 score: 0.32 Loss: 0.6652919054031372 Accuracy: 0.8571428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 59%|█████▉    | 170/287 [00:23<00:16,  7.21it/s]\u001b[A\n",
      " 60%|█████▉    | 171/287 [00:23<00:15,  7.32it/s]\u001b[A\n",
      " 60%|█████▉    | 172/287 [00:23<00:15,  7.41it/s]\u001b[A\n",
      " 60%|██████    | 173/287 [00:23<00:15,  7.47it/s]\u001b[A\n",
      " 61%|██████    | 174/287 [00:23<00:15,  7.51it/s]\u001b[A\n",
      " 61%|██████    | 175/287 [00:24<00:14,  7.54it/s]\u001b[A\n",
      " 61%|██████▏   | 176/287 [00:24<00:14,  7.54it/s]\u001b[A\n",
      " 62%|██████▏   | 177/287 [00:24<00:14,  7.57it/s]\u001b[A\n",
      " 62%|██████▏   | 178/287 [00:24<00:14,  7.57it/s]\u001b[A\n",
      " 62%|██████▏   | 179/287 [00:24<00:14,  7.58it/s]\u001b[A\n",
      " 63%|██████▎   | 180/287 [00:24<00:14,  7.58it/s]\u001b[A\n",
      " 63%|██████▎   | 181/287 [00:24<00:13,  7.58it/s]\u001b[A\n",
      " 63%|██████▎   | 182/287 [00:25<00:13,  7.58it/s]\u001b[A\n",
      " 64%|██████▍   | 183/287 [00:25<00:13,  7.58it/s]\u001b[A\n",
      " 64%|██████▍   | 184/287 [00:25<00:13,  7.58it/s]\u001b[A\n",
      " 64%|██████▍   | 185/287 [00:25<00:13,  7.59it/s]\u001b[A\n",
      " 65%|██████▍   | 186/287 [00:25<00:13,  7.58it/s]\u001b[A\n",
      " 65%|██████▌   | 187/287 [00:25<00:13,  7.58it/s]\u001b[A\n",
      " 66%|██████▌   | 188/287 [00:25<00:13,  7.58it/s]\u001b[A\n",
      " 66%|██████▌   | 189/287 [00:25<00:12,  7.58it/s]\u001b[A\n",
      " 66%|██████▌   | 190/287 [00:26<00:12,  7.58it/s]\u001b[A\n",
      " 67%|██████▋   | 191/287 [00:26<00:12,  7.60it/s]\u001b[A\n",
      " 67%|██████▋   | 192/287 [00:26<00:12,  7.80it/s]\u001b[A\n",
      " 67%|██████▋   | 193/287 [00:27<00:35,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: F1 score: 0.6533333333333333 Loss: 0.38120657205581665 Accuracy: 0.9285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 68%|██████▊   | 194/287 [00:27<00:28,  3.25it/s]\u001b[A\n",
      " 68%|██████▊   | 195/287 [00:27<00:23,  3.93it/s]\u001b[A\n",
      " 68%|██████▊   | 196/287 [00:27<00:19,  4.59it/s]\u001b[A\n",
      " 69%|██████▊   | 197/287 [00:27<00:17,  5.21it/s]\u001b[A\n",
      " 69%|██████▉   | 198/287 [00:27<00:15,  5.75it/s]\u001b[A\n",
      " 69%|██████▉   | 199/287 [00:28<00:14,  6.20it/s]\u001b[A\n",
      " 70%|██████▉   | 200/287 [00:28<00:13,  6.56it/s]\u001b[A\n",
      " 70%|███████   | 201/287 [00:28<00:12,  6.84it/s]\u001b[A\n",
      " 70%|███████   | 202/287 [00:28<00:12,  7.05it/s]\u001b[A\n",
      " 71%|███████   | 203/287 [00:28<00:11,  7.17it/s]\u001b[A\n",
      " 71%|███████   | 204/287 [00:28<00:11,  7.29it/s]\u001b[A\n",
      " 71%|███████▏  | 205/287 [00:28<00:11,  7.38it/s]\u001b[A\n",
      " 72%|███████▏  | 206/287 [00:29<00:10,  7.45it/s]\u001b[A\n",
      " 72%|███████▏  | 207/287 [00:29<00:10,  7.50it/s]\u001b[A\n",
      " 72%|███████▏  | 208/287 [00:29<00:10,  7.53it/s]\u001b[A\n",
      " 73%|███████▎  | 209/287 [00:29<00:10,  7.54it/s]\u001b[A\n",
      " 73%|███████▎  | 210/287 [00:29<00:10,  7.56it/s]\u001b[A\n",
      " 74%|███████▎  | 211/287 [00:29<00:10,  7.57it/s]\u001b[A\n",
      " 74%|███████▍  | 212/287 [00:29<00:09,  7.58it/s]\u001b[A\n",
      " 74%|███████▍  | 213/287 [00:29<00:09,  7.59it/s]\u001b[A\n",
      " 75%|███████▍  | 214/287 [00:30<00:09,  7.59it/s]\u001b[A\n",
      " 75%|███████▍  | 215/287 [00:30<00:09,  7.60it/s]\u001b[A\n",
      " 75%|███████▌  | 216/287 [00:30<00:09,  7.78it/s]\u001b[A\n",
      " 76%|███████▌  | 217/287 [00:31<00:27,  2.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: F1 score: 0.6533333333333333 Loss: 0.3927749991416931 Accuracy: 0.9285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 76%|███████▌  | 218/287 [00:31<00:21,  3.22it/s]\u001b[A\n",
      " 76%|███████▋  | 219/287 [00:31<00:17,  3.89it/s]\u001b[A\n",
      " 77%|███████▋  | 220/287 [00:31<00:14,  4.56it/s]\u001b[A\n",
      " 77%|███████▋  | 221/287 [00:31<00:12,  5.18it/s]\u001b[A\n",
      " 77%|███████▋  | 222/287 [00:31<00:11,  5.73it/s]\u001b[A\n",
      " 78%|███████▊  | 223/287 [00:32<00:10,  6.19it/s]\u001b[A\n",
      " 78%|███████▊  | 224/287 [00:32<00:09,  6.54it/s]\u001b[A\n",
      " 78%|███████▊  | 225/287 [00:32<00:09,  6.78it/s]\u001b[A\n",
      " 79%|███████▊  | 226/287 [00:32<00:08,  6.99it/s]\u001b[A\n",
      " 79%|███████▉  | 227/287 [00:32<00:08,  7.15it/s]\u001b[A\n",
      " 79%|███████▉  | 228/287 [00:32<00:08,  7.24it/s]\u001b[A\n",
      " 80%|███████▉  | 229/287 [00:32<00:07,  7.32it/s]\u001b[A\n",
      " 80%|████████  | 230/287 [00:33<00:07,  7.39it/s]\u001b[A\n",
      " 80%|████████  | 231/287 [00:33<00:07,  7.42it/s]\u001b[A\n",
      " 81%|████████  | 232/287 [00:33<00:07,  7.45it/s]\u001b[A\n",
      " 81%|████████  | 233/287 [00:33<00:07,  7.49it/s]\u001b[A\n",
      " 82%|████████▏ | 234/287 [00:33<00:07,  7.51it/s]\u001b[A\n",
      " 82%|████████▏ | 235/287 [00:33<00:06,  7.53it/s]\u001b[A\n",
      " 82%|████████▏ | 236/287 [00:33<00:06,  7.54it/s]\u001b[A\n",
      " 83%|████████▎ | 237/287 [00:33<00:06,  7.55it/s]\u001b[A\n",
      " 83%|████████▎ | 238/287 [00:34<00:06,  7.56it/s]\u001b[A\n",
      " 83%|████████▎ | 239/287 [00:34<00:06,  7.58it/s]\u001b[A\n",
      " 84%|████████▎ | 240/287 [00:34<00:06,  7.77it/s]\u001b[A\n",
      " 84%|████████▍ | 241/287 [00:34<00:06,  7.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: F1 score: 0.6533333333333333 Loss: 0.4009776711463928 Accuracy: 0.9285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 84%|████████▍ | 242/287 [00:34<00:06,  7.22it/s]\u001b[A\n",
      " 85%|████████▍ | 243/287 [00:34<00:06,  7.32it/s]\u001b[A\n",
      " 85%|████████▌ | 244/287 [00:34<00:05,  7.39it/s]\u001b[A\n",
      " 85%|████████▌ | 245/287 [00:35<00:05,  7.44it/s]\u001b[A\n",
      " 86%|████████▌ | 246/287 [00:35<00:05,  7.48it/s]\u001b[A\n",
      " 86%|████████▌ | 247/287 [00:35<00:05,  7.50it/s]\u001b[A\n",
      " 86%|████████▋ | 248/287 [00:35<00:05,  7.52it/s]\u001b[A\n",
      " 87%|████████▋ | 249/287 [00:35<00:05,  7.54it/s]\u001b[A\n",
      " 87%|████████▋ | 250/287 [00:35<00:04,  7.55it/s]\u001b[A\n",
      " 87%|████████▋ | 251/287 [00:35<00:04,  7.55it/s]\u001b[A\n",
      " 88%|████████▊ | 252/287 [00:35<00:04,  7.55it/s]\u001b[A\n",
      " 88%|████████▊ | 253/287 [00:36<00:04,  7.56it/s]\u001b[A\n",
      " 89%|████████▊ | 254/287 [00:36<00:04,  7.56it/s]\u001b[A\n",
      " 89%|████████▉ | 255/287 [00:36<00:04,  7.55it/s]\u001b[A\n",
      " 89%|████████▉ | 256/287 [00:36<00:04,  7.56it/s]\u001b[A\n",
      " 90%|████████▉ | 257/287 [00:36<00:03,  7.55it/s]\u001b[A\n",
      " 90%|████████▉ | 258/287 [00:36<00:03,  7.55it/s]\u001b[A\n",
      " 90%|█████████ | 259/287 [00:36<00:03,  7.50it/s]\u001b[A\n",
      " 91%|█████████ | 260/287 [00:37<00:03,  7.53it/s]\u001b[A\n",
      " 91%|█████████ | 261/287 [00:37<00:03,  7.54it/s]\u001b[A\n",
      " 91%|█████████▏| 262/287 [00:37<00:03,  7.55it/s]\u001b[A\n",
      " 92%|█████████▏| 263/287 [00:37<00:03,  7.56it/s]\u001b[A\n",
      " 92%|█████████▏| 264/287 [00:37<00:02,  7.75it/s]\u001b[A\n",
      " 92%|█████████▏| 265/287 [00:37<00:03,  7.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: F1 score: 0.6533333333333333 Loss: 0.4016144573688507 Accuracy: 0.9285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93%|█████████▎| 266/287 [00:37<00:02,  7.19it/s]\u001b[A\n",
      " 93%|█████████▎| 267/287 [00:37<00:02,  7.29it/s]\u001b[A\n",
      " 93%|█████████▎| 268/287 [00:38<00:02,  7.32it/s]\u001b[A\n",
      " 94%|█████████▎| 269/287 [00:38<00:02,  7.38it/s]\u001b[A\n",
      " 94%|█████████▍| 270/287 [00:38<00:02,  7.38it/s]\u001b[A\n",
      " 94%|█████████▍| 271/287 [00:38<00:02,  7.43it/s]\u001b[A\n",
      " 95%|█████████▍| 272/287 [00:38<00:02,  7.47it/s]\u001b[A\n",
      " 95%|█████████▌| 273/287 [00:38<00:01,  7.49it/s]\u001b[A\n",
      " 95%|█████████▌| 274/287 [00:38<00:01,  7.50it/s]\u001b[A\n",
      " 96%|█████████▌| 275/287 [00:39<00:01,  7.52it/s]\u001b[A\n",
      " 96%|█████████▌| 276/287 [00:39<00:01,  7.53it/s]\u001b[A\n",
      " 97%|█████████▋| 277/287 [00:39<00:01,  7.54it/s]\u001b[A\n",
      " 97%|█████████▋| 278/287 [00:39<00:01,  7.55it/s]\u001b[A\n",
      " 97%|█████████▋| 279/287 [00:39<00:01,  7.55it/s]\u001b[A\n",
      " 98%|█████████▊| 280/287 [00:39<00:00,  7.55it/s]\u001b[A\n",
      " 98%|█████████▊| 281/287 [00:39<00:00,  7.56it/s]\u001b[A\n",
      " 98%|█████████▊| 282/287 [00:39<00:00,  7.56it/s]\u001b[A\n",
      " 99%|█████████▊| 283/287 [00:40<00:00,  7.51it/s]\u001b[A\n",
      " 99%|█████████▉| 284/287 [00:40<00:00,  7.52it/s]\u001b[A\n",
      " 99%|█████████▉| 285/287 [00:40<00:00,  7.53it/s]\u001b[A\n",
      "100%|█████████▉| 286/287 [00:40<00:00,  7.54it/s]\u001b[A\n",
      "100%|██████████| 287/287 [00:40<00:00,  7.54it/s]\u001b[A\n",
      "288it [00:40,  7.72it/s]                         \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: F1 score: 0.6533333333333333 Loss: 0.4023922383785248 Accuracy: 0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "progress_bar = tqdm.tqdm(range(TRAIN_STEPS))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        optim.zero_grad()\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "        optim.step()\n",
    "        lr_scheduler.step()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = []\n",
    "        labels = []\n",
    "        val_loss = 0\n",
    "        acc = 0\n",
    "        for batch in val_loader:\n",
    "            outputs = model(**batch)\n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "            \n",
    "            val_loss += outputs.loss\n",
    "            acc += (predictions == batch['labels']).sum().item()\n",
    "            \n",
    "            preds.extend(predictions.tolist())\n",
    "            labels.extend(batch['labels'].tolist())\n",
    "\n",
    "    f1 = f1_score(labels, preds, average='macro')\n",
    "    if epoch == 0:\n",
    "            min_val_loss = val_loss\n",
    "            largest_f1 = f1\n",
    "    elif (epoch > 3) & (val_loss < min_val_loss):\n",
    "        min_val_loss = val_loss\n",
    "        model.save_pretrained(paths.MODEL_PATH/'ms_diag_medbert_valloss')\n",
    "    elif (epoch > 3) & (largest_f1 < f1):\n",
    "        largest_f1 = f1\n",
    "        model.save_pretrained(paths.MODEL_PATH/'ms_diag_medbert_f1')\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: F1 score: {f1} Loss: {val_loss/len(val_loader)} Accuracy: {acc/len(dataset['validation'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
