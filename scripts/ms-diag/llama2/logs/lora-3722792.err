/bin/bash: /cluster/customapps/biomed/grlab/users/eglimar/conda/envs/inf-extr/lib/libtinfo.so.6: no version information available (required by /bin/bash)
/cluster/home/eglimar/.env_bootstrap/dotfiles/shell/bashrc: line 17: module: command not found
/cluster/home/eglimar/.env_bootstrap/dotfiles/shell/bashrc: line 20: module: command not found
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [04:20<21:42, 260.47s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [08:54<17:54, 268.57s/it]Loading checkpoint shards:  50%|█████     | 3/6 [13:39<13:48, 276.04s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [18:25<09:19, 279.81s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [23:09<04:41, 281.28s/it]Loading checkpoint shards: 100%|██████████| 6/6 [25:15<00:00, 228.59s/it]Loading checkpoint shards: 100%|██████████| 6/6 [25:15<00:00, 252.57s/it]
Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at /cluster/dataset/midatams/inf-extr/resources/models/llama2 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Map:   0%|          | 0/220 [00:00<?, ? examples/s]Map: 100%|██████████| 220/220 [00:00<00:00, 275.02 examples/s]Map: 100%|██████████| 220/220 [00:00<00:00, 269.06 examples/s]
  0%|          | 0/43 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/cluster/customapps/biomed/grlab/users/eglimar/conda/envs/inf-extr/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/cluster/customapps/biomed/grlab/users/eglimar/conda/envs/inf-extr/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Epoch: 0, Loss: 2.1848:   0%|          | 0/43 [00:15<?, ?it/s]Epoch: 0, Loss: 2.1848:   2%|▏         | 1/43 [00:15<10:59, 15.71s/it]Epoch: 0, Loss: 1.4175:   2%|▏         | 1/43 [00:20<10:59, 15.71s/it]Epoch: 0, Loss: 1.4175:   5%|▍         | 2/43 [00:20<06:10,  9.05s/it]Epoch: 0, Loss: 1.1739:   5%|▍         | 2/43 [00:24<06:10,  9.05s/it]Epoch: 0, Loss: 1.1739:   7%|▋         | 3/43 [00:24<04:36,  6.91s/it]Epoch: 0, Loss: 2.1599:   7%|▋         | 3/43 [00:28<04:36,  6.91s/it]Epoch: 0, Loss: 2.1599:   9%|▉         | 4/43 [00:28<03:50,  5.91s/it]Epoch: 0, Loss: 1.3433:   9%|▉         | 4/43 [00:33<03:50,  5.91s/it]Epoch: 0, Loss: 1.3433:  12%|█▏        | 5/43 [00:33<03:23,  5.36s/it]Epoch: 0, Loss: 1.2583:  12%|█▏        | 5/43 [00:37<03:23,  5.36s/it]Epoch: 0, Loss: 1.2583:  14%|█▍        | 6/43 [00:37<03:05,  5.03s/it]Epoch: 0, Loss: 2.8747:  14%|█▍        | 6/43 [00:41<03:05,  5.03s/it]Epoch: 0, Loss: 2.8747:  16%|█▋        | 7/43 [00:41<02:53,  4.82s/it]Epoch: 0, Loss: 1.3709:  16%|█▋        | 7/43 [00:46<02:53,  4.82s/it]Epoch: 0, Loss: 1.3709:  19%|█▊        | 8/43 [00:46<02:43,  4.66s/it]Epoch: 0, Loss: 1.3652:  19%|█▊        | 8/43 [00:50<02:43,  4.66s/it]Epoch: 0, Loss: 1.3652:  21%|██        | 9/43 [00:50<02:35,  4.58s/it]Epoch: 0, Loss: 1.8690:  21%|██        | 9/43 [00:55<02:35,  4.58s/it]Epoch: 0, Loss: 1.8690:  23%|██▎       | 10/43 [00:55<02:29,  4.53s/it]Epoch: 0, Loss: 0.5734:  23%|██▎       | 10/43 [00:59<02:29,  4.53s/it]Epoch: 0, Loss: 0.5734:  26%|██▌       | 11/43 [00:59<02:23,  4.49s/it]Epoch: 0, Loss: 2.1853:  26%|██▌       | 11/43 [01:03<02:23,  4.49s/it]Epoch: 0, Loss: 2.1853:  28%|██▊       | 12/43 [01:03<02:18,  4.46s/it]Epoch: 0, Loss: 1.7002:  28%|██▊       | 12/43 [01:08<02:18,  4.46s/it]Epoch: 0, Loss: 1.7002:  30%|███       | 13/43 [01:08<02:13,  4.45s/it]Epoch: 0, Loss: 0.9868:  30%|███       | 13/43 [01:12<02:13,  4.45s/it]Epoch: 0, Loss: 0.9868:  33%|███▎      | 14/43 [01:12<02:08,  4.42s/it]Epoch: 0, Loss: 1.2144:  33%|███▎      | 14/43 [01:17<02:08,  4.42s/it]Epoch: 0, Loss: 1.2144:  35%|███▍      | 15/43 [01:17<02:03,  4.42s/it]Epoch: 0, Loss: 0.7668:  35%|███▍      | 15/43 [01:21<02:03,  4.42s/it]Epoch: 0, Loss: 0.7668:  37%|███▋      | 16/43 [01:21<01:59,  4.42s/it]Epoch: 0, Loss: 1.5008:  37%|███▋      | 16/43 [01:25<01:59,  4.42s/it]Epoch: 0, Loss: 1.5008:  40%|███▉      | 17/43 [01:25<01:54,  4.42s/it]Epoch: 0, Loss: 2.1233:  40%|███▉      | 17/43 [01:30<01:54,  4.42s/it]Epoch: 0, Loss: 2.1233:  42%|████▏     | 18/43 [01:30<01:49,  4.40s/it]Epoch: 0, Loss: 1.2989:  42%|████▏     | 18/43 [01:34<01:49,  4.40s/it]Epoch: 0, Loss: 1.2989:  44%|████▍     | 19/43 [01:34<01:45,  4.41s/it]Epoch: 0, Loss: 0.5117:  44%|████▍     | 19/43 [01:39<01:45,  4.41s/it]Epoch: 0, Loss: 0.5117:  47%|████▋     | 20/43 [01:39<01:41,  4.42s/it]Epoch: 0, Loss: 1.2952:  47%|████▋     | 20/43 [01:43<01:41,  4.42s/it]Epoch: 0, Loss: 1.2952:  49%|████▉     | 21/43 [01:43<01:37,  4.42s/it]Epoch: 0, Loss: 1.8826:  49%|████▉     | 21/43 [01:48<01:37,  4.42s/it]Epoch: 0, Loss: 1.8826:  51%|█████     | 22/43 [01:48<01:32,  4.42s/it]Epoch: 0, Loss: 1.1644:  51%|█████     | 22/43 [01:52<01:32,  4.42s/it]Epoch: 0, Loss: 1.1644:  53%|█████▎    | 23/43 [01:52<01:28,  4.43s/it]Epoch: 0, Loss: 1.1506:  53%|█████▎    | 23/43 [01:56<01:28,  4.43s/it]Epoch: 0, Loss: 1.1506:  56%|█████▌    | 24/43 [01:56<01:24,  4.43s/it]Epoch: 0, Loss: 0.9097:  56%|█████▌    | 24/43 [02:01<01:24,  4.43s/it]Epoch: 0, Loss: 0.9097:  58%|█████▊    | 25/43 [02:01<01:19,  4.43s/it]Epoch: 0, Loss: 1.2585:  58%|█████▊    | 25/43 [02:05<01:19,  4.43s/it]Epoch: 0, Loss: 1.2585:  60%|██████    | 26/43 [02:05<01:15,  4.43s/it]Epoch: 0, Loss: 2.6858:  60%|██████    | 26/43 [02:10<01:15,  4.43s/it]Epoch: 0, Loss: 2.6858:  63%|██████▎   | 27/43 [02:10<01:10,  4.43s/it]Epoch: 0, Loss: 0.0970:  63%|██████▎   | 27/43 [02:14<01:10,  4.43s/it]Epoch: 0, Loss: 0.0970:  65%|██████▌   | 28/43 [02:14<01:06,  4.43s/it]Epoch: 0, Loss: 1.2383:  65%|██████▌   | 28/43 [02:19<01:06,  4.43s/it]Epoch: 0, Loss: 1.2383:  67%|██████▋   | 29/43 [02:19<01:01,  4.43s/it]Epoch: 0, Loss: 1.0655:  67%|██████▋   | 29/43 [02:23<01:01,  4.43s/it]Epoch: 0, Loss: 1.0655:  70%|██████▉   | 30/43 [02:23<00:57,  4.43s/it]Epoch: 0, Loss: 0.9872:  70%|██████▉   | 30/43 [02:27<00:57,  4.43s/it]Epoch: 0, Loss: 0.9872:  72%|███████▏  | 31/43 [02:27<00:52,  4.40s/it]Epoch: 0, Loss: 0.7857:  72%|███████▏  | 31/43 [02:32<00:52,  4.40s/it]Epoch: 0, Loss: 0.7857:  74%|███████▍  | 32/43 [02:32<00:48,  4.41s/it]Epoch: 0, Loss: 0.4629:  74%|███████▍  | 32/43 [02:36<00:48,  4.41s/it]Epoch: 0, Loss: 0.4629:  77%|███████▋  | 33/43 [02:36<00:44,  4.42s/it]Epoch: 0, Loss: 1.0012:  77%|███████▋  | 33/43 [02:41<00:44,  4.42s/it]Epoch: 0, Loss: 1.0012:  79%|███████▉  | 34/43 [02:41<00:39,  4.42s/it]Epoch: 0, Loss: 1.0229:  79%|███████▉  | 34/43 [02:45<00:39,  4.42s/it]Epoch: 0, Loss: 1.0229:  81%|████████▏ | 35/43 [02:45<00:35,  4.43s/it]Epoch: 0, Loss: 1.2298:  81%|████████▏ | 35/43 [02:49<00:35,  4.43s/it]Epoch: 0, Loss: 1.2298:  84%|████████▎ | 36/43 [02:49<00:31,  4.43s/it]Epoch: 0, Loss: 1.2654:  84%|████████▎ | 36/43 [02:54<00:31,  4.43s/it]Epoch: 0, Loss: 1.2654:  86%|████████▌ | 37/43 [02:54<00:26,  4.43s/it]Epoch: 0, Loss: 0.8343:  86%|████████▌ | 37/43 [02:58<00:26,  4.43s/it]Epoch: 0, Loss: 0.8343:  88%|████████▊ | 38/43 [02:58<00:22,  4.41s/it]Epoch: 0, Loss: 1.5500:  88%|████████▊ | 38/43 [03:03<00:22,  4.41s/it]Epoch: 0, Loss: 1.5500:  91%|█████████ | 39/43 [03:03<00:17,  4.42s/it]Epoch: 0, Loss: 1.0566:  91%|█████████ | 39/43 [03:07<00:17,  4.42s/it]Epoch: 0, Loss: 1.0566:  93%|█████████▎| 40/43 [03:07<00:13,  4.40s/it]Epoch: 0, Loss: 1.0984:  93%|█████████▎| 40/43 [03:12<00:13,  4.40s/it]Epoch: 0, Loss: 1.0984:  95%|█████████▌| 41/43 [03:12<00:08,  4.43s/it]Epoch: 0, Loss: 1.2561:  95%|█████████▌| 41/43 [03:16<00:08,  4.43s/it]Epoch: 0, Loss: 1.2561:  98%|█████████▊| 42/43 [03:16<00:04,  4.44s/it]Epoch: 0, Loss: 1.2207:  98%|█████████▊| 42/43 [03:20<00:04,  4.44s/it]Epoch: 0, Loss: 1.2207: 100%|██████████| 43/43 [03:20<00:00,  4.27s/it]Epoch: 0, Loss: 1.2207: 100%|██████████| 43/43 [03:20<00:00,  4.66s/it]
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:04<00:04,  4.46s/it]100%|██████████| 2/2 [00:07<00:00,  3.78s/it]100%|██████████| 2/2 [00:07<00:00,  3.88s/it]
  0%|          | 0/43 [00:00<?, ?it/s]/cluster/customapps/biomed/grlab/users/eglimar/conda/envs/inf-extr/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/cluster/customapps/biomed/grlab/users/eglimar/conda/envs/inf-extr/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Epoch: 1, Loss: 0.1710:   0%|          | 0/43 [00:04<?, ?it/s]Epoch: 1, Loss: 0.1710:   2%|▏         | 1/43 [00:04<03:07,  4.46s/it]Epoch: 1, Loss: 0.2303:   2%|▏         | 1/43 [00:08<03:07,  4.46s/it]Epoch: 1, Loss: 0.2303:   5%|▍         | 2/43 [00:08<03:02,  4.44s/it]Epoch: 1, Loss: 0.1074:   5%|▍         | 2/43 [00:13<03:02,  4.44s/it]Epoch: 1, Loss: 0.1074:   7%|▋         | 3/43 [00:13<02:57,  4.44s/it]Epoch: 1, Loss: 0.4247:   7%|▋         | 3/43 [00:17<02:57,  4.44s/it]Epoch: 1, Loss: 0.4247:   9%|▉         | 4/43 [00:17<02:52,  4.44s/it]Epoch: 1, Loss: 0.0800:   9%|▉         | 4/43 [00:22<02:52,  4.44s/it]Epoch: 1, Loss: 0.0800:  12%|█▏        | 5/43 [00:22<02:48,  4.43s/it]Epoch: 1, Loss: 0.0572:  12%|█▏        | 5/43 [00:26<02:48,  4.43s/it]Epoch: 1, Loss: 0.0572:  14%|█▍        | 6/43 [00:26<02:44,  4.43s/it]Epoch: 1, Loss: 0.2416:  14%|█▍        | 6/43 [00:30<02:44,  4.43s/it]Epoch: 1, Loss: 0.2416:  16%|█▋        | 7/43 [00:30<02:38,  4.41s/it]Epoch: 1, Loss: 0.3093:  16%|█▋        | 7/43 [00:35<02:38,  4.41s/it]Epoch: 1, Loss: 0.3093:  19%|█▊        | 8/43 [00:35<02:34,  4.42s/it]Epoch: 1, Loss: 0.5644:  19%|█▊        | 8/43 [00:39<02:34,  4.42s/it]Epoch: 1, Loss: 0.5644:  21%|██        | 9/43 [00:39<02:29,  4.39s/it]Epoch: 1, Loss: 0.2453:  21%|██        | 9/43 [00:44<02:29,  4.39s/it]Epoch: 1, Loss: 0.2453:  23%|██▎       | 10/43 [00:44<02:25,  4.41s/it]Epoch: 1, Loss: 0.1987:  23%|██▎       | 10/43 [00:48<02:25,  4.41s/it]Epoch: 1, Loss: 0.1987:  26%|██▌       | 11/43 [00:48<02:21,  4.41s/it]Epoch: 1, Loss: 0.0606:  26%|██▌       | 11/43 [00:53<02:21,  4.41s/it]Epoch: 1, Loss: 0.0606:  28%|██▊       | 12/43 [00:53<02:17,  4.42s/it]Epoch: 1, Loss: 0.0510:  28%|██▊       | 12/43 [00:57<02:17,  4.42s/it]Epoch: 1, Loss: 0.0510:  30%|███       | 13/43 [00:57<02:12,  4.42s/it]Epoch: 1, Loss: 0.2842:  30%|███       | 13/43 [01:01<02:12,  4.42s/it]Epoch: 1, Loss: 0.2842:  33%|███▎      | 14/43 [01:01<02:08,  4.43s/it]Epoch: 1, Loss: 0.2685:  33%|███▎      | 14/43 [01:06<02:08,  4.43s/it]Epoch: 1, Loss: 0.2685:  35%|███▍      | 15/43 [01:06<02:03,  4.40s/it]Epoch: 1, Loss: 0.2358:  35%|███▍      | 15/43 [01:10<02:03,  4.40s/it]Epoch: 1, Loss: 0.2358:  37%|███▋      | 16/43 [01:10<01:59,  4.41s/it]Epoch: 1, Loss: 0.4618:  37%|███▋      | 16/43 [01:15<01:59,  4.41s/it]Epoch: 1, Loss: 0.4618:  40%|███▉      | 17/43 [01:15<01:54,  4.40s/it]Epoch: 1, Loss: 0.0779:  40%|███▉      | 17/43 [01:19<01:54,  4.40s/it]Epoch: 1, Loss: 0.0779:  42%|████▏     | 18/43 [01:19<01:50,  4.41s/it]Epoch: 1, Loss: 0.2550:  42%|████▏     | 18/43 [01:23<01:50,  4.41s/it]Epoch: 1, Loss: 0.2550:  44%|████▍     | 19/43 [01:23<01:46,  4.42s/it]Epoch: 1, Loss: 0.3186:  44%|████▍     | 19/43 [01:28<01:46,  4.42s/it]Epoch: 1, Loss: 0.3186:  47%|████▋     | 20/43 [01:28<01:41,  4.40s/it]Epoch: 1, Loss: 0.1110:  47%|████▋     | 20/43 [01:32<01:41,  4.40s/it]Epoch: 1, Loss: 0.1110:  49%|████▉     | 21/43 [01:32<01:37,  4.41s/it]Epoch: 1, Loss: 0.2987:  49%|████▉     | 21/43 [01:37<01:37,  4.41s/it]Epoch: 1, Loss: 0.2987:  51%|█████     | 22/43 [01:37<01:32,  4.42s/it]Epoch: 1, Loss: 0.8958:  51%|█████     | 22/43 [01:41<01:32,  4.42s/it]Epoch: 1, Loss: 0.8958:  53%|█████▎    | 23/43 [01:41<01:27,  4.40s/it]Epoch: 1, Loss: 0.1394:  53%|█████▎    | 23/43 [01:45<01:27,  4.40s/it]Epoch: 1, Loss: 0.1394:  56%|█████▌    | 24/43 [01:45<01:23,  4.38s/it]Epoch: 1, Loss: 0.0702:  56%|█████▌    | 24/43 [01:50<01:23,  4.38s/it]Epoch: 1, Loss: 0.0702:  58%|█████▊    | 25/43 [01:50<01:19,  4.40s/it]Epoch: 1, Loss: 0.3933:  58%|█████▊    | 25/43 [01:54<01:19,  4.40s/it]Epoch: 1, Loss: 0.3933:  60%|██████    | 26/43 [01:54<01:14,  4.41s/it]Epoch: 1, Loss: 0.6638:  60%|██████    | 26/43 [01:59<01:14,  4.41s/it]Epoch: 1, Loss: 0.6638:  63%|██████▎   | 27/43 [01:59<01:10,  4.42s/it]Epoch: 1, Loss: 0.2194:  63%|██████▎   | 27/43 [02:03<01:10,  4.42s/it]Epoch: 1, Loss: 0.2194:  65%|██████▌   | 28/43 [02:03<01:06,  4.43s/it]Epoch: 1, Loss: 0.1976:  65%|██████▌   | 28/43 [02:08<01:06,  4.43s/it]Epoch: 1, Loss: 0.1976:  67%|██████▋   | 29/43 [02:08<01:02,  4.43s/it]Epoch: 1, Loss: 0.1019:  67%|██████▋   | 29/43 [02:12<01:02,  4.43s/it]Epoch: 1, Loss: 0.1019:  70%|██████▉   | 30/43 [02:12<00:57,  4.43s/it]Epoch: 1, Loss: 0.3957:  70%|██████▉   | 30/43 [02:16<00:57,  4.43s/it]Epoch: 1, Loss: 0.3957:  72%|███████▏  | 31/43 [02:16<00:52,  4.41s/it]Epoch: 1, Loss: 0.1396:  72%|███████▏  | 31/43 [02:21<00:52,  4.41s/it]Epoch: 1, Loss: 0.1396:  74%|███████▍  | 32/43 [02:21<00:48,  4.39s/it]Epoch: 1, Loss: 0.1684:  74%|███████▍  | 32/43 [02:25<00:48,  4.39s/it]Epoch: 1, Loss: 0.1684:  77%|███████▋  | 33/43 [02:25<00:43,  4.38s/it]Epoch: 1, Loss: 0.1867:  77%|███████▋  | 33/43 [02:30<00:43,  4.38s/it]Epoch: 1, Loss: 0.1867:  79%|███████▉  | 34/43 [02:30<00:39,  4.40s/it]Epoch: 1, Loss: 0.5331:  79%|███████▉  | 34/43 [02:34<00:39,  4.40s/it]Epoch: 1, Loss: 0.5331:  81%|████████▏ | 35/43 [02:34<00:35,  4.39s/it]Epoch: 1, Loss: 0.4315:  81%|████████▏ | 35/43 [02:38<00:35,  4.39s/it]Epoch: 1, Loss: 0.4315:  84%|████████▎ | 36/43 [02:38<00:30,  4.40s/it]Epoch: 1, Loss: 0.1078:  84%|████████▎ | 36/43 [02:43<00:30,  4.40s/it]Epoch: 1, Loss: 0.1078:  86%|████████▌ | 37/43 [02:43<00:26,  4.42s/it]Epoch: 1, Loss: 0.0368:  86%|████████▌ | 37/43 [02:47<00:26,  4.42s/it]Epoch: 1, Loss: 0.0368:  88%|████████▊ | 38/43 [02:47<00:22,  4.43s/it]Epoch: 1, Loss: 0.2949:  88%|████████▊ | 38/43 [02:52<00:22,  4.43s/it]Epoch: 1, Loss: 0.2949:  91%|█████████ | 39/43 [02:52<00:17,  4.43s/it]Epoch: 1, Loss: 0.0649:  91%|█████████ | 39/43 [02:56<00:17,  4.43s/it]Epoch: 1, Loss: 0.0649:  93%|█████████▎| 40/43 [02:56<00:13,  4.43s/it]Epoch: 1, Loss: 0.0609:  93%|█████████▎| 40/43 [03:01<00:13,  4.43s/it]Epoch: 1, Loss: 0.0609:  95%|█████████▌| 41/43 [03:01<00:08,  4.44s/it]Epoch: 1, Loss: 0.1530:  95%|█████████▌| 41/43 [03:05<00:08,  4.44s/it]Epoch: 1, Loss: 0.1530:  98%|█████████▊| 42/43 [03:05<00:04,  4.44s/it]Epoch: 1, Loss: 0.9967:  98%|█████████▊| 42/43 [03:09<00:04,  4.44s/it]Epoch: 1, Loss: 0.9967: 100%|██████████| 43/43 [03:09<00:00,  4.25s/it]Epoch: 1, Loss: 0.9967: 100%|██████████| 43/43 [03:09<00:00,  4.40s/it]
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:04<00:04,  4.42s/it]100%|██████████| 2/2 [00:07<00:00,  3.76s/it]100%|██████████| 2/2 [00:07<00:00,  3.86s/it]
  0%|          | 0/43 [00:00<?, ?it/s]/cluster/customapps/biomed/grlab/users/eglimar/conda/envs/inf-extr/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/cluster/customapps/biomed/grlab/users/eglimar/conda/envs/inf-extr/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Epoch: 2, Loss: 0.1047:   0%|          | 0/43 [00:04<?, ?it/s]Epoch: 2, Loss: 0.1047:   2%|▏         | 1/43 [00:04<03:06,  4.45s/it]Epoch: 2, Loss: 0.0731:   2%|▏         | 1/43 [00:08<03:06,  4.45s/it]Epoch: 2, Loss: 0.0731:   5%|▍         | 2/43 [00:08<03:02,  4.46s/it]Epoch: 2, Loss: 0.0648:   5%|▍         | 2/43 [00:13<03:02,  4.46s/it]Epoch: 2, Loss: 0.0648:   7%|▋         | 3/43 [00:13<02:58,  4.46s/it]Epoch: 2, Loss: 0.0573:   7%|▋         | 3/43 [00:17<02:58,  4.46s/it]Epoch: 2, Loss: 0.0573:   9%|▉         | 4/43 [00:17<02:53,  4.46s/it]Epoch: 2, Loss: 0.0484:   9%|▉         | 4/43 [00:22<02:53,  4.46s/it]Epoch: 2, Loss: 0.0484:  12%|█▏        | 5/43 [00:22<02:47,  4.42s/it]Epoch: 2, Loss: 0.1462:  12%|█▏        | 5/43 [00:26<02:47,  4.42s/it]Epoch: 2, Loss: 0.1462:  14%|█▍        | 6/43 [00:26<02:43,  4.43s/it]Epoch: 2, Loss: 0.3524:  14%|█▍        | 6/43 [00:31<02:43,  4.43s/it]Epoch: 2, Loss: 0.3524:  16%|█▋        | 7/43 [00:31<02:39,  4.44s/it]Epoch: 2, Loss: 0.0461:  16%|█▋        | 7/43 [00:35<02:39,  4.44s/it]Epoch: 2, Loss: 0.0461:  19%|█▊        | 8/43 [00:35<02:35,  4.44s/it]Epoch: 2, Loss: 0.1319:  19%|█▊        | 8/43 [00:39<02:35,  4.44s/it]Epoch: 2, Loss: 0.1319:  21%|██        | 9/43 [00:39<02:31,  4.44s/it]Epoch: 2, Loss: 0.0433:  21%|██        | 9/43 [00:44<02:31,  4.44s/it]Epoch: 2, Loss: 0.0433:  23%|██▎       | 10/43 [00:44<02:25,  4.42s/it]Epoch: 2, Loss: 0.4449:  23%|██▎       | 10/43 [00:48<02:25,  4.42s/it]Epoch: 2, Loss: 0.4449:  26%|██▌       | 11/43 [00:48<02:21,  4.42s/it]Epoch: 2, Loss: 0.1444:  26%|██▌       | 11/43 [00:53<02:21,  4.42s/it]Epoch: 2, Loss: 0.1444:  28%|██▊       | 12/43 [00:53<02:17,  4.43s/it]Epoch: 2, Loss: 0.3908:  28%|██▊       | 12/43 [00:57<02:17,  4.43s/it]Epoch: 2, Loss: 0.3908:  30%|███       | 13/43 [00:57<02:13,  4.43s/it]Epoch: 2, Loss: 0.1698:  30%|███       | 13/43 [01:02<02:13,  4.43s/it]Epoch: 2, Loss: 0.1698:  33%|███▎      | 14/43 [01:02<02:08,  4.44s/it]Epoch: 2, Loss: 0.0590:  33%|███▎      | 14/43 [01:06<02:08,  4.44s/it]Epoch: 2, Loss: 0.0590:  35%|███▍      | 15/43 [01:06<02:04,  4.44s/it]Epoch: 2, Loss: 0.0770:  35%|███▍      | 15/43 [01:11<02:04,  4.44s/it]Epoch: 2, Loss: 0.0770:  37%|███▋      | 16/43 [01:11<01:59,  4.44s/it]Epoch: 2, Loss: 0.0824:  37%|███▋      | 16/43 [01:15<01:59,  4.44s/it]Epoch: 2, Loss: 0.0824:  40%|███▉      | 17/43 [01:15<01:55,  4.45s/it]Epoch: 2, Loss: 0.0730:  40%|███▉      | 17/43 [01:19<01:55,  4.45s/it]Epoch: 2, Loss: 0.0730:  42%|████▏     | 18/43 [01:19<01:51,  4.45s/it]Epoch: 2, Loss: 0.2893:  42%|████▏     | 18/43 [01:24<01:51,  4.45s/it]Epoch: 2, Loss: 0.2893:  44%|████▍     | 19/43 [01:24<01:46,  4.45s/it]Epoch: 2, Loss: 0.0453:  44%|████▍     | 19/43 [01:28<01:46,  4.45s/it]Epoch: 2, Loss: 0.0453:  47%|████▋     | 20/43 [01:28<01:42,  4.45s/it]Epoch: 2, Loss: 0.1154:  47%|████▋     | 20/43 [01:33<01:42,  4.45s/it]Epoch: 2, Loss: 0.1154:  49%|████▉     | 21/43 [01:33<01:37,  4.42s/it]Epoch: 2, Loss: 0.3627:  49%|████▉     | 21/43 [01:37<01:37,  4.42s/it]Epoch: 2, Loss: 0.3627:  51%|█████     | 22/43 [01:37<01:33,  4.44s/it]Epoch: 2, Loss: 0.0529:  51%|█████     | 22/43 [01:42<01:33,  4.44s/it]Epoch: 2, Loss: 0.0529:  53%|█████▎    | 23/43 [01:42<01:28,  4.44s/it]Epoch: 2, Loss: 0.0630:  53%|█████▎    | 23/43 [01:46<01:28,  4.44s/it]Epoch: 2, Loss: 0.0630:  56%|█████▌    | 24/43 [01:46<01:24,  4.45s/it]Epoch: 2, Loss: 0.0726:  56%|█████▌    | 24/43 [01:50<01:24,  4.45s/it]Epoch: 2, Loss: 0.0726:  58%|█████▊    | 25/43 [01:50<01:20,  4.45s/it]Epoch: 2, Loss: 0.0594:  58%|█████▊    | 25/43 [01:55<01:20,  4.45s/it]Epoch: 2, Loss: 0.0594:  60%|██████    | 26/43 [01:55<01:15,  4.42s/it]Epoch: 2, Loss: 0.0075:  60%|██████    | 26/43 [01:59<01:15,  4.42s/it]Epoch: 2, Loss: 0.0075:  63%|██████▎   | 27/43 [01:59<01:10,  4.43s/it]Epoch: 2, Loss: 0.0598:  63%|██████▎   | 27/43 [02:04<01:10,  4.43s/it]Epoch: 2, Loss: 0.0598:  65%|██████▌   | 28/43 [02:04<01:06,  4.41s/it]Epoch: 2, Loss: 0.1412:  65%|██████▌   | 28/43 [02:08<01:06,  4.41s/it]Epoch: 2, Loss: 0.1412:  67%|██████▋   | 29/43 [02:08<01:01,  4.39s/it]Epoch: 2, Loss: 0.2496:  67%|██████▋   | 29/43 [02:12<01:01,  4.39s/it]Epoch: 2, Loss: 0.2496:  70%|██████▉   | 30/43 [02:12<00:57,  4.41s/it]Epoch: 2, Loss: 0.3657:  70%|██████▉   | 30/43 [02:17<00:57,  4.41s/it]Epoch: 2, Loss: 0.3657:  72%|███████▏  | 31/43 [02:17<00:53,  4.42s/it]Epoch: 2, Loss: 0.4182:  72%|███████▏  | 31/43 [02:21<00:53,  4.42s/it]Epoch: 2, Loss: 0.4182:  74%|███████▍  | 32/43 [02:21<00:48,  4.40s/it]Epoch: 2, Loss: 0.2587:  74%|███████▍  | 32/43 [02:26<00:48,  4.40s/it]Epoch: 2, Loss: 0.2587:  77%|███████▋  | 33/43 [02:26<00:44,  4.42s/it]Epoch: 2, Loss: 0.1283:  77%|███████▋  | 33/43 [02:30<00:44,  4.42s/it]Epoch: 2, Loss: 0.1283:  79%|███████▉  | 34/43 [02:30<00:39,  4.43s/it]Epoch: 2, Loss: 0.1021:  79%|███████▉  | 34/43 [02:35<00:39,  4.43s/it]Epoch: 2, Loss: 0.1021:  81%|████████▏ | 35/43 [02:35<00:35,  4.43s/it]Epoch: 2, Loss: 0.1065:  81%|████████▏ | 35/43 [02:39<00:35,  4.43s/it]Epoch: 2, Loss: 0.1065:  84%|████████▎ | 36/43 [02:39<00:31,  4.44s/it]Epoch: 2, Loss: 0.1858:  84%|████████▎ | 36/43 [02:44<00:31,  4.44s/it]Epoch: 2, Loss: 0.1858:  86%|████████▌ | 37/43 [02:44<00:26,  4.44s/it]Epoch: 2, Loss: 0.0386:  86%|████████▌ | 37/43 [02:48<00:26,  4.44s/it]Epoch: 2, Loss: 0.0386:  88%|████████▊ | 38/43 [02:48<00:22,  4.45s/it]Epoch: 2, Loss: 0.1473:  88%|████████▊ | 38/43 [02:52<00:22,  4.45s/it]Epoch: 2, Loss: 0.1473:  91%|█████████ | 39/43 [02:52<00:17,  4.42s/it]Epoch: 2, Loss: 0.2857:  91%|█████████ | 39/43 [02:57<00:17,  4.42s/it]Epoch: 2, Loss: 0.2857:  93%|█████████▎| 40/43 [02:57<00:13,  4.43s/it]Epoch: 2, Loss: 0.2422:  93%|█████████▎| 40/43 [03:01<00:13,  4.43s/it]Epoch: 2, Loss: 0.2422:  95%|█████████▌| 41/43 [03:01<00:08,  4.44s/it]Epoch: 2, Loss: 0.0549:  95%|█████████▌| 41/43 [03:06<00:08,  4.44s/it]Epoch: 2, Loss: 0.0549:  98%|█████████▊| 42/43 [03:06<00:04,  4.44s/it]Epoch: 2, Loss: 0.2852:  98%|█████████▊| 42/43 [03:10<00:04,  4.44s/it]Epoch: 2, Loss: 0.2852: 100%|██████████| 43/43 [03:10<00:00,  4.28s/it]Epoch: 2, Loss: 0.2852: 100%|██████████| 43/43 [03:10<00:00,  4.42s/it]
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:04<00:04,  4.42s/it]100%|██████████| 2/2 [00:07<00:00,  3.77s/it]100%|██████████| 2/2 [00:07<00:00,  3.87s/it]
  0%|          | 0/43 [00:00<?, ?it/s]/cluster/customapps/biomed/grlab/users/eglimar/conda/envs/inf-extr/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/cluster/customapps/biomed/grlab/users/eglimar/conda/envs/inf-extr/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Epoch: 3, Loss: 0.0653:   0%|          | 0/43 [00:04<?, ?it/s]Epoch: 3, Loss: 0.0653:   2%|▏         | 1/43 [00:04<03:06,  4.45s/it]Epoch: 3, Loss: 0.1984:   2%|▏         | 1/43 [00:08<03:06,  4.45s/it]Epoch: 3, Loss: 0.1984:   5%|▍         | 2/43 [00:08<03:02,  4.45s/it]Epoch: 3, Loss: 0.1025:   5%|▍         | 2/43 [00:13<03:02,  4.45s/it]Epoch: 3, Loss: 0.1025:   7%|▋         | 3/43 [00:13<02:58,  4.46s/it]Epoch: 3, Loss: 0.0673:   7%|▋         | 3/43 [00:17<02:58,  4.46s/it]Epoch: 3, Loss: 0.0673:   9%|▉         | 4/43 [00:17<02:53,  4.46s/it]Epoch: 3, Loss: 0.0247:   9%|▉         | 4/43 [00:22<02:53,  4.46s/it]Epoch: 3, Loss: 0.0247:  12%|█▏        | 5/43 [00:22<02:49,  4.46s/it]Epoch: 3, Loss: 0.0349:  12%|█▏        | 5/43 [00:26<02:49,  4.46s/it]Epoch: 3, Loss: 0.0349:  14%|█▍        | 6/43 [00:26<02:44,  4.45s/it]Epoch: 3, Loss: 0.0810:  14%|█▍        | 6/43 [00:31<02:44,  4.45s/it]Epoch: 3, Loss: 0.0810:  16%|█▋        | 7/43 [00:31<02:40,  4.45s/it]Epoch: 3, Loss: 0.1306:  16%|█▋        | 7/43 [00:35<02:40,  4.45s/it]Epoch: 3, Loss: 0.1306:  19%|█▊        | 8/43 [00:35<02:34,  4.42s/it]Epoch: 3, Loss: 0.0854:  19%|█▊        | 8/43 [00:39<02:34,  4.42s/it]Epoch: 3, Loss: 0.0854:  21%|██        | 9/43 [00:39<02:30,  4.43s/it]Epoch: 3, Loss: 0.0808:  21%|██        | 9/43 [00:44<02:30,  4.43s/it]Epoch: 3, Loss: 0.0808:  23%|██▎       | 10/43 [00:44<02:27,  4.46s/it]Epoch: 3, Loss: 0.1953:  23%|██▎       | 10/43 [00:48<02:27,  4.46s/it]Epoch: 3, Loss: 0.1953:  26%|██▌       | 11/43 [00:48<02:21,  4.43s/it]Epoch: 3, Loss: 0.0343:  26%|██▌       | 11/43 [00:53<02:21,  4.43s/it]Epoch: 3, Loss: 0.0343:  28%|██▊       | 12/43 [00:53<02:17,  4.44s/it]Epoch: 3, Loss: 0.1219:  28%|██▊       | 12/43 [00:57<02:17,  4.44s/it]Epoch: 3, Loss: 0.1219:  30%|███       | 13/43 [00:57<02:13,  4.44s/it]Epoch: 3, Loss: 0.0516:  30%|███       | 13/43 [01:02<02:13,  4.44s/it]Epoch: 3, Loss: 0.0516:  33%|███▎      | 14/43 [01:02<02:10,  4.49s/it]Epoch: 3, Loss: 0.0478:  33%|███▎      | 14/43 [01:06<02:10,  4.49s/it]Epoch: 3, Loss: 0.0478:  35%|███▍      | 15/43 [01:06<02:05,  4.48s/it]Epoch: 3, Loss: 0.0806:  35%|███▍      | 15/43 [01:11<02:05,  4.48s/it]Epoch: 3, Loss: 0.0806:  37%|███▋      | 16/43 [01:11<02:00,  4.47s/it]Epoch: 3, Loss: 0.0699:  37%|███▋      | 16/43 [01:15<02:00,  4.47s/it]Epoch: 3, Loss: 0.0699:  40%|███▉      | 17/43 [01:15<01:56,  4.47s/it]Epoch: 3, Loss: 0.0598:  40%|███▉      | 17/43 [01:20<01:56,  4.47s/it]Epoch: 3, Loss: 0.0598:  42%|████▏     | 18/43 [01:20<01:51,  4.46s/it]Epoch: 3, Loss: 0.1970:  42%|████▏     | 18/43 [01:24<01:51,  4.46s/it]Epoch: 3, Loss: 0.1970:  44%|████▍     | 19/43 [01:24<01:47,  4.46s/it]Epoch: 3, Loss: 0.0350:  44%|████▍     | 19/43 [01:29<01:47,  4.46s/it]Epoch: 3, Loss: 0.0350:  47%|████▋     | 20/43 [01:29<01:42,  4.45s/it]Epoch: 3, Loss: 0.0507:  47%|████▋     | 20/43 [01:33<01:42,  4.45s/it]Epoch: 3, Loss: 0.0507:  49%|████▉     | 21/43 [01:33<01:37,  4.45s/it]Epoch: 3, Loss: 0.1127:  49%|████▉     | 21/43 [01:37<01:37,  4.45s/it]Epoch: 3, Loss: 0.1127:  51%|█████     | 22/43 [01:37<01:33,  4.45s/it]Epoch: 3, Loss: 0.0179:  51%|█████     | 22/43 [01:42<01:33,  4.45s/it]Epoch: 3, Loss: 0.0179:  53%|█████▎    | 23/43 [01:42<01:29,  4.45s/it]Epoch: 3, Loss: 0.0394:  53%|█████▎    | 23/43 [01:46<01:29,  4.45s/it]Epoch: 3, Loss: 0.0394:  56%|█████▌    | 24/43 [01:46<01:24,  4.45s/it]Epoch: 3, Loss: 0.1236:  56%|█████▌    | 24/43 [01:51<01:24,  4.45s/it]Epoch: 3, Loss: 0.1236:  58%|█████▊    | 25/43 [01:51<01:20,  4.45s/it]Epoch: 3, Loss: 0.0685:  58%|█████▊    | 25/43 [01:55<01:20,  4.45s/it]Epoch: 3, Loss: 0.0685:  60%|██████    | 26/43 [01:55<01:15,  4.45s/it]Epoch: 3, Loss: 0.0467:  60%|██████    | 26/43 [02:00<01:15,  4.45s/it]Epoch: 3, Loss: 0.0467:  63%|██████▎   | 27/43 [02:00<01:11,  4.45s/it]Epoch: 3, Loss: 0.0329:  63%|██████▎   | 27/43 [02:04<01:11,  4.45s/it]Epoch: 3, Loss: 0.0329:  65%|██████▌   | 28/43 [02:04<01:06,  4.42s/it]Epoch: 3, Loss: 0.0847:  65%|██████▌   | 28/43 [02:09<01:06,  4.42s/it]Epoch: 3, Loss: 0.0847:  67%|██████▋   | 29/43 [02:09<01:01,  4.43s/it]Epoch: 3, Loss: 0.1724:  67%|██████▋   | 29/43 [02:13<01:01,  4.43s/it]Epoch: 3, Loss: 0.1724:  70%|██████▉   | 30/43 [02:13<00:57,  4.43s/it]Epoch: 3, Loss: 0.0908:  70%|██████▉   | 30/43 [02:17<00:57,  4.43s/it]Epoch: 3, Loss: 0.0908:  72%|███████▏  | 31/43 [02:17<00:53,  4.44s/it]Epoch: 3, Loss: 0.0880:  72%|███████▏  | 31/43 [02:22<00:53,  4.44s/it]Epoch: 3, Loss: 0.0880:  74%|███████▍  | 32/43 [02:22<00:48,  4.44s/it]Epoch: 3, Loss: 0.0239:  74%|███████▍  | 32/43 [02:26<00:48,  4.44s/it]Epoch: 3, Loss: 0.0239:  77%|███████▋  | 33/43 [02:26<00:44,  4.44s/it]Epoch: 3, Loss: 0.0732:  77%|███████▋  | 33/43 [02:31<00:44,  4.44s/it]Epoch: 3, Loss: 0.0732:  79%|███████▉  | 34/43 [02:31<00:39,  4.44s/it]Epoch: 3, Loss: 0.1129:  79%|███████▉  | 34/43 [02:35<00:39,  4.44s/it]Epoch: 3, Loss: 0.1129:  81%|████████▏ | 35/43 [02:35<00:35,  4.44s/it]Epoch: 3, Loss: 0.0502:  81%|████████▏ | 35/43 [02:40<00:35,  4.44s/it]Epoch: 3, Loss: 0.0502:  84%|████████▎ | 36/43 [02:40<00:31,  4.45s/it]Epoch: 3, Loss: 0.1341:  84%|████████▎ | 36/43 [02:44<00:31,  4.45s/it]Epoch: 3, Loss: 0.1341:  86%|████████▌ | 37/43 [02:44<00:26,  4.45s/it]Epoch: 3, Loss: 0.1463:  86%|████████▌ | 37/43 [02:48<00:26,  4.45s/it]Epoch: 3, Loss: 0.1463:  88%|████████▊ | 38/43 [02:48<00:22,  4.42s/it]Epoch: 3, Loss: 0.0728:  88%|████████▊ | 38/43 [02:53<00:22,  4.42s/it]Epoch: 3, Loss: 0.0728:  91%|█████████ | 39/43 [02:53<00:17,  4.43s/it]Epoch: 3, Loss: 0.1438:  91%|█████████ | 39/43 [02:57<00:17,  4.43s/it]Epoch: 3, Loss: 0.1438:  93%|█████████▎| 40/43 [02:57<00:13,  4.41s/it]Epoch: 3, Loss: 0.0630:  93%|█████████▎| 40/43 [03:02<00:13,  4.41s/it]Epoch: 3, Loss: 0.0630:  95%|█████████▌| 41/43 [03:02<00:08,  4.42s/it]Epoch: 3, Loss: 0.1455:  95%|█████████▌| 41/43 [03:06<00:08,  4.42s/it]Epoch: 3, Loss: 0.1455:  98%|█████████▊| 42/43 [03:06<00:04,  4.41s/it]Epoch: 3, Loss: 0.0487:  98%|█████████▊| 42/43 [03:10<00:04,  4.41s/it]Epoch: 3, Loss: 0.0487: 100%|██████████| 43/43 [03:10<00:00,  4.23s/it]Epoch: 3, Loss: 0.0487: 100%|██████████| 43/43 [03:10<00:00,  4.43s/it]
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:04<00:04,  4.42s/it]100%|██████████| 2/2 [00:07<00:00,  3.77s/it]100%|██████████| 2/2 [00:07<00:00,  3.86s/it]
