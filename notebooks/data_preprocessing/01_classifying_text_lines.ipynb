{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying text lines\n",
    "\n",
    "A classifier is trained to classify single text lines of a report. For example, the lines can be classified as containing a diagnosis (`\"dm\"`) or history (`his`) of a patient. This task was used as a preprocessing step to later steps of structured information extraction. So that only lines classified as containing a diagnosis will be fed to a downstream classifier, extracting the exact diagnosis. This step might be unnecessary with modern transformers that can handle longer text inputs. But it could still help by only feeding relevant input. Even more important old approach only trained and evaluated classifier 2 (MS-Diag) on reports containing \"dm\", which gives a more accurate idea of the whole pipeline.\n",
    "\n",
    "The files containing the necessary information are inside the `data/raw/labelling` directory. It contains manually labelled reports from different sessions.\n",
    "\n",
    "The original classes per label are:\n",
    "\n",
    "| category    | subcategory       | abbreviation |\n",
    "|-------------|-------------------|--------------|\n",
    "| diagnosis   | MS diagnosis      | dm           |\n",
    "|             | other             | do           |\n",
    "| current state     |              | cu           |\n",
    "| history     |                   | his          |\n",
    "| symptoms    | MS related        | sym          |\n",
    "|             | other             | so           |\n",
    "| MRI | results                  | mr           |\n",
    "| lab | results                  | labr         |\n",
    "|             | other             | labo         |\n",
    "| medication  | MS related        | medms        |\n",
    "|             | other             | medo         |\n",
    "| test, treatment        | results | tr           |\n",
    "| header      |                   | head         |\n",
    "| unknown     |                   | unk          |\n",
    "\n",
    "I will group the classes according to the original approach, and drop observations with no text or label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd()+\"/../..\")\n",
    "\n",
    "from src import paths\n",
    "from src.utils import line_Label_label2id\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_line_labelling():\n",
    "    \"\"\"Loading the data from the nested csv files in the different \"imported_time\" directories. Labelled reports have a \"rev.csv\" ending\n",
    "    and are in a \"_Marc\" subdirectory. There should only be one entry per rid, that is labelled. Duplicates will be removed.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with columns: \"text\", \"class\", \"rid\"\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    rid_list = []\n",
    "\n",
    "    for root, dirs, files in os.walk(paths.DATA_PATH_LABELLED):\n",
    "        if \"Marc\" not in root:\n",
    "            continue\n",
    "        for file in files:\n",
    "\n",
    "            # Get the research id from filename\n",
    "            rid = file.split(\"_\")[0]\n",
    "            \n",
    "            # Check if the file is a labelled report (and not mri) and if the rid is already in the list\n",
    "            if (file.endswith(\"rev.csv\") and \"mri\" not in file and rid not in rid_list):\n",
    "                \n",
    "                # Append rid to rid list to keep track of which files have been added\n",
    "                rid_list.append(rid)\n",
    "\n",
    "                # Create a dataframe from the csv file\n",
    "                _df = pd.read_csv(os.path.join(root, file))\n",
    "                \n",
    "                # Add the rid to the dataframe\n",
    "                _df = _df.rename(columns={\"text\": \"text\", \"class\": \"class\"})\n",
    "                _df['rid'] = rid\n",
    "                \n",
    "                # Append the dataframe to the main dataframe\n",
    "                try: \n",
    "                    df_list.append(_df)\n",
    "                except:\n",
    "                    print(\"Error with file: \", file)\n",
    "                    print(\"df head: \", _df.head(5))\n",
    "                    print(\"_df head: \", _df.head(5))\n",
    "                    continue\n",
    "    print(\"Number of reports: \", len(df_list))\n",
    "    return pd.concat(df_list)[[\"text\", \"class\", \"rid\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line_text(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    For Transformer to work, there has to be text in the text column. If there is no text, the text column is removed.\n",
    "    \"\"\"\n",
    "    df = df.dropna(subset=[\"text\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_line_class(df: pd.DataFrame):\n",
    "    \"\"\"Cleans the dataframe labels in \"class\".\n",
    "    1) Removes whitespace from beginning and end of text\n",
    "    2) Correct spelling mistakes\n",
    "    3) Fill NaN values with \"unk\"\n",
    "    4) Create a new column \"class_agg\" with the aggregated classes of the original approach.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Class mapping spelling mistakes\n",
    "    class_mapping_spelling = {\n",
    "        'memds': 'medms',\n",
    "        'hs': 'his',\n",
    "        'm': 'mr',\n",
    "    }\n",
    "    class_mapping_agg = {\n",
    "        'his': 'his_sym_cu',\n",
    "        'sym': 'his_sym_cu',\n",
    "        'cu': 'his_sym_cu',\n",
    "        'labr': 'labr_labo',\n",
    "        'labo': 'labr_labo',\n",
    "        'to': 'to_tr',\n",
    "        'tr': 'to_tr',\n",
    "        'medo': 'medo_unk_do_so',\n",
    "        'unk': 'medo_unk_do_so',\n",
    "        'do': 'medo_unk_do_so',\n",
    "        'so': 'medo_unk_do_so',\n",
    "    }\n",
    "\n",
    "    # Cleaning the class column\n",
    "    df['class'] = df['class'].str.strip() \\\n",
    "                             .replace(class_mapping_spelling) \\\n",
    "                             .fillna(\"unk\") \n",
    "\n",
    "    # Creating a new column with the aggregated classes\n",
    "    df['class_agg'] = df['class'].replace(class_mapping_agg)\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_clean_line_df():\n",
    "    \"\"\"Loads and cleans the dataframe from the load_line_labelling function.\n",
    "    \"\"\"\n",
    "    df = load_line_labelling()\n",
    "    df = clean_line_text(df)\n",
    "    df = clean_line_class(df)\n",
    "\n",
    "    return df[[\"rid\", \"text\", \"class\", \"class_agg\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reports:  74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>class_agg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>014673E3-8EBF-4408-96E0-79BE34341EB5</td>\n",
       "      <td>Schubförmige Multiple Sklerose (RRMS), EDSS 3.5</td>\n",
       "      <td>dm</td>\n",
       "      <td>dm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>014673E3-8EBF-4408-96E0-79BE34341EB5</td>\n",
       "      <td>(ES 04/1992, ED 07/1998 (USZ))</td>\n",
       "      <td>do</td>\n",
       "      <td>medo_unk_do_so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>014673E3-8EBF-4408-96E0-79BE34341EB5</td>\n",
       "      <td>Verlauf:</td>\n",
       "      <td>head</td>\n",
       "      <td>head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>014673E3-8EBF-4408-96E0-79BE34341EB5</td>\n",
       "      <td>INDENT 04/1992 Kribbelparästhesien bd. Füsse, ...</td>\n",
       "      <td>his</td>\n",
       "      <td>his_sym_cu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>014673E3-8EBF-4408-96E0-79BE34341EB5</td>\n",
       "      <td>INDENT 1997 Fühl- und auch Kraftminderung des ...</td>\n",
       "      <td>his</td>\n",
       "      <td>his_sym_cu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    rid  \\\n",
       "0  014673E3-8EBF-4408-96E0-79BE34341EB5   \n",
       "1  014673E3-8EBF-4408-96E0-79BE34341EB5   \n",
       "2  014673E3-8EBF-4408-96E0-79BE34341EB5   \n",
       "3  014673E3-8EBF-4408-96E0-79BE34341EB5   \n",
       "4  014673E3-8EBF-4408-96E0-79BE34341EB5   \n",
       "\n",
       "                                                text class       class_agg  \n",
       "0    Schubförmige Multiple Sklerose (RRMS), EDSS 3.5    dm              dm  \n",
       "1                     (ES 04/1992, ED 07/1998 (USZ))    do  medo_unk_do_so  \n",
       "2                                           Verlauf:  head            head  \n",
       "3  INDENT 04/1992 Kribbelparästhesien bd. Füsse, ...   his      his_sym_cu  \n",
       "4  INDENT 1997 Fühl- und auch Kraftminderung des ...   his      his_sym_cu  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_agg values:  class_agg\n",
      "his_sym_cu        312\n",
      "mr                270\n",
      "head              236\n",
      "medms             213\n",
      "labr_labo         184\n",
      "medo_unk_do_so    139\n",
      "to_tr             114\n",
      "dm                 74\n",
      "Name: count, dtype: int64\n",
      "class values:  class\n",
      "mr       270\n",
      "head     236\n",
      "medms    213\n",
      "his      210\n",
      "labr     166\n",
      "tr        77\n",
      "dm        74\n",
      "sym       62\n",
      "unk       50\n",
      "do        42\n",
      "cu        40\n",
      "to        37\n",
      "medo      35\n",
      "labo      18\n",
      "so        12\n",
      "Name: count, dtype: int64\n",
      "Number of reports with missing values in class_agg:  0\n"
     ]
    }
   ],
   "source": [
    "df = load_clean_line_df()\n",
    "display(df.head(5))\n",
    "\n",
    "# Class distribution\n",
    "print(\"class_agg values: \", df.class_agg.value_counts())\n",
    "print(\"class values: \", df[\"class\"].value_counts())\n",
    "\n",
    "# Number of reports with missing values in class_agg\n",
    "print(\"Number of reports with missing values in class_agg: \", df[df[\"class_agg\"].isnull()].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "df.to_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line_labelling/line_labelling_clean.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train test split by rid\n",
    "rids = df.rid.unique()\n",
    "rids_train, rids_test = train_test_split(rids, test_size=0.2, random_state=42)\n",
    "rids_train, rids_val = train_test_split(rids_train, test_size=0.2, random_state=42)\n",
    "\n",
    "df_train = df[df.rid.isin(rids_train)]\n",
    "df_val = df[df.rid.isin(rids_val)]\n",
    "df_test = df[df.rid.isin(rids_test)]\n",
    "\n",
    "# Save the train, val and test dataframes\n",
    "df_train.to_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line_labelling/line_labelling_clean_train.csv\"))\n",
    "\n",
    "df_val.to_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line_labelling/line_labelling_clean_val.csv\"))\n",
    "\n",
    "df_test.to_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line_labelling/line_labelling_clean_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92c1c998b76454893a424a0ed4ffcca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/948 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da38ead71742457f8257c83543e5d718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/249 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc0b392279b47c197cd29755209d42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9047c8803ef7499b9416d82c3ac05e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/948 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473eac98248d435693900db8e38b8cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/249 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b00fd5a295a47dcb032c072d1b821ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create HuggingFace Dataset\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train),\n",
    "    \"val\": Dataset.from_pandas(df_val),\n",
    "    \"test\": Dataset.from_pandas(df_test),\n",
    "})\n",
    "\n",
    "# Map the labels to ids\n",
    "dataset = dataset.map(lambda e: {\"labels\": [line_Label_label2id[l] for l in e[\"class_agg\"]]}, batched=True)\n",
    "\n",
    "# Drop __index_level_0__ column\n",
    "dataset = dataset.remove_columns([\"__index_level_0__\", \"rid\", \"class\", \"class_agg\"])\n",
    "\n",
    "# Save the dataset\n",
    "dataset.save_to_disk(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line_labelling/line_labelling_clean_dataset\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf-extr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
