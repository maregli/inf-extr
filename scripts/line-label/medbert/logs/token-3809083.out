=====================================================================
                   Welcome to Leonhard Med v.2.0.1                    

 * Documentation:  https://unlimited.ethz.ch/display/LEOMED2
 * Support:        leomed-support@id.ethz.ch
 * Software stack: type "enable_modules" to use Modules

Tenant name: BIOMED
OS: Ubuntu 20.04.6 LTS x86_64 
Uptime: 5 days, 2 hours, 2 mins 
CPU: Intel Xeon (Cascadelake) (34) @ 2.599GHz 
CPU Usage: 63% 
GPU: NVIDIA GeForce RTX 2080 Ti 
GPU: NVIDIA GeForce RTX 2080 Ti 
GPU: NVIDIA GeForce RTX 2080 Ti 
GPU: NVIDIA GeForce RTX 2080 Ti 
GPU: NVIDIA GeForce RTX 2080 Ti 
GPU: NVIDIA GeForce RTX 2080 Ti 
GPU: NVIDIA GeForce RTX 2080 Ti 
GPU: NVIDIA GeForce RTX 2080 Ti 
Memory: 112376MiB / 365879MiB (30%) 

=====================================================================
Parsed Arguments:
job_id: unknown
model_name: medbert-512
quantization: None
task_type: token
batch_size: 8
lr: 2e-05
num_epochs: 20
gradient_accumulation_steps: 1
peft_config: None
attn_implementation: None
GPU 0: NVIDIA GeForce RTX 2080 Ti
   Total Memory: 10.75 GB
   Free Memory: 10.20 GB
   Allocated Memory : 0.00 GB
   Reserved Memory : 0.00 GB
Loaded Data
Added special token [BRK] to tokenizer
Tokenizer pad token ID: 0
Tokenizer special tokens: {'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]', 'additional_special_tokens': ['[BRK]']}
Model pad token ID: 0
Loaded Model and Tokenizer
Got Optimizer, Scheduler and DataCollator
Starting Training
{'eval_loss': 1.808927059173584, 'eval_precision': 0.039473684210526314, 'eval_recall': 0.12857142857142856, 'eval_f1': 0.060402684563758385, 'eval_accuracy': 0.5065312046444121, 'eval_runtime': 0.1471, 'eval_samples_per_second': 27.186, 'eval_steps_per_second': 6.796, 'epoch': 1.0}
{'loss': 2.098, 'learning_rate': 1.8333333333333333e-05, 'epoch': 1.43}
{'eval_loss': 1.2477729320526123, 'eval_precision': 0.08791208791208792, 'eval_recall': 0.22857142857142856, 'eval_f1': 0.126984126984127, 'eval_accuracy': 0.6444121915820029, 'eval_runtime': 0.1264, 'eval_samples_per_second': 31.645, 'eval_steps_per_second': 7.911, 'epoch': 2.0}
{'loss': 1.1249, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.86}
{'eval_loss': 0.8081253170967102, 'eval_precision': 0.1694915254237288, 'eval_recall': 0.2857142857142857, 'eval_f1': 0.21276595744680848, 'eval_accuracy': 0.7851959361393324, 'eval_runtime': 0.0894, 'eval_samples_per_second': 44.742, 'eval_steps_per_second': 11.186, 'epoch': 3.0}
{'eval_loss': 0.6250548362731934, 'eval_precision': 0.2, 'eval_recall': 0.32857142857142857, 'eval_f1': 0.24864864864864863, 'eval_accuracy': 0.8040638606676342, 'eval_runtime': 0.08, 'eval_samples_per_second': 50.0, 'eval_steps_per_second': 12.5, 'epoch': 4.0}
{'loss': 0.6801, 'learning_rate': 1.5000000000000002e-05, 'epoch': 4.29}
{'eval_loss': 0.4995880722999573, 'eval_precision': 0.29906542056074764, 'eval_recall': 0.45714285714285713, 'eval_f1': 0.36158192090395475, 'eval_accuracy': 0.841799709724238, 'eval_runtime': 0.0943, 'eval_samples_per_second': 42.401, 'eval_steps_per_second': 10.6, 'epoch': 5.0}
{'loss': 0.4673, 'learning_rate': 1.3333333333333333e-05, 'epoch': 5.71}
{'eval_loss': 0.4023757874965668, 'eval_precision': 0.4174757281553398, 'eval_recall': 0.6142857142857143, 'eval_f1': 0.4971098265895954, 'eval_accuracy': 0.865021770682148, 'eval_runtime': 0.0936, 'eval_samples_per_second': 42.741, 'eval_steps_per_second': 10.685, 'epoch': 6.0}
{'eval_loss': 0.3651283085346222, 'eval_precision': 0.4791666666666667, 'eval_recall': 0.6571428571428571, 'eval_f1': 0.5542168674698795, 'eval_accuracy': 0.8679245283018868, 'eval_runtime': 0.0803, 'eval_samples_per_second': 49.783, 'eval_steps_per_second': 12.446, 'epoch': 7.0}
{'loss': 0.3177, 'learning_rate': 1.1666666666666668e-05, 'epoch': 7.14}
{'eval_loss': 0.2997884452342987, 'eval_precision': 0.5888888888888889, 'eval_recall': 0.7571428571428571, 'eval_f1': 0.6625, 'eval_accuracy': 0.9114658925979681, 'eval_runtime': 0.0959, 'eval_samples_per_second': 41.711, 'eval_steps_per_second': 10.428, 'epoch': 8.0}
{'loss': 0.2417, 'learning_rate': 1e-05, 'epoch': 8.57}
{'eval_loss': 0.2865269184112549, 'eval_precision': 0.627906976744186, 'eval_recall': 0.7714285714285715, 'eval_f1': 0.6923076923076923, 'eval_accuracy': 0.9172714078374455, 'eval_runtime': 0.1696, 'eval_samples_per_second': 23.578, 'eval_steps_per_second': 5.895, 'epoch': 9.0}
{'loss': 0.2005, 'learning_rate': 8.333333333333334e-06, 'epoch': 10.0}
{'eval_loss': 0.30342617630958557, 'eval_precision': 0.632183908045977, 'eval_recall': 0.7857142857142857, 'eval_f1': 0.7006369426751593, 'eval_accuracy': 0.9114658925979681, 'eval_runtime': 0.1167, 'eval_samples_per_second': 34.269, 'eval_steps_per_second': 8.567, 'epoch': 10.0}
{'eval_loss': 0.27675801515579224, 'eval_precision': 0.6746987951807228, 'eval_recall': 0.8, 'eval_f1': 0.7320261437908497, 'eval_accuracy': 0.918722786647315, 'eval_runtime': 0.0966, 'eval_samples_per_second': 41.407, 'eval_steps_per_second': 10.352, 'epoch': 11.0}
{'loss': 0.1454, 'learning_rate': 6.666666666666667e-06, 'epoch': 11.43}
{'eval_loss': 0.28327372670173645, 'eval_precision': 0.6627906976744186, 'eval_recall': 0.8142857142857143, 'eval_f1': 0.7307692307692307, 'eval_accuracy': 0.9085631349782293, 'eval_runtime': 0.1132, 'eval_samples_per_second': 35.321, 'eval_steps_per_second': 8.83, 'epoch': 12.0}
{'loss': 0.1106, 'learning_rate': 5e-06, 'epoch': 12.86}
{'eval_loss': 0.28440266847610474, 'eval_precision': 0.7283950617283951, 'eval_recall': 0.8428571428571429, 'eval_f1': 0.7814569536423841, 'eval_accuracy': 0.9114658925979681, 'eval_runtime': 0.0828, 'eval_samples_per_second': 48.288, 'eval_steps_per_second': 12.072, 'epoch': 13.0}
{'eval_loss': 0.2678559720516205, 'eval_precision': 0.7023809523809523, 'eval_recall': 0.8428571428571429, 'eval_f1': 0.7662337662337663, 'eval_accuracy': 0.9158200290275762, 'eval_runtime': 0.1045, 'eval_samples_per_second': 38.274, 'eval_steps_per_second': 9.568, 'epoch': 14.0}
{'loss': 0.1067, 'learning_rate': 3.3333333333333333e-06, 'epoch': 14.29}
{'eval_loss': 0.2692091763019562, 'eval_precision': 0.7195121951219512, 'eval_recall': 0.8428571428571429, 'eval_f1': 0.7763157894736842, 'eval_accuracy': 0.9143686502177069, 'eval_runtime': 0.1234, 'eval_samples_per_second': 32.403, 'eval_steps_per_second': 8.101, 'epoch': 15.0}
{'loss': 0.0891, 'learning_rate': 1.6666666666666667e-06, 'epoch': 15.71}
{'eval_loss': 0.2812301218509674, 'eval_precision': 0.6705882352941176, 'eval_recall': 0.8142857142857143, 'eval_f1': 0.7354838709677418, 'eval_accuracy': 0.9114658925979681, 'eval_runtime': 0.083, 'eval_samples_per_second': 48.19, 'eval_steps_per_second': 12.048, 'epoch': 16.0}
{'eval_loss': 0.28073903918266296, 'eval_precision': 0.6705882352941176, 'eval_recall': 0.8142857142857143, 'eval_f1': 0.7354838709677418, 'eval_accuracy': 0.9129172714078374, 'eval_runtime': 0.1021, 'eval_samples_per_second': 39.188, 'eval_steps_per_second': 9.797, 'epoch': 17.0}
{'loss': 0.0861, 'learning_rate': 0.0, 'epoch': 17.14}
{'eval_loss': 0.28062349557876587, 'eval_precision': 0.6705882352941176, 'eval_recall': 0.8142857142857143, 'eval_f1': 0.7354838709677418, 'eval_accuracy': 0.9129172714078374, 'eval_runtime': 0.1317, 'eval_samples_per_second': 30.376, 'eval_steps_per_second': 7.594, 'epoch': 18.0}
{'loss': 0.0785, 'learning_rate': 0.0, 'epoch': 18.57}
{'eval_loss': 0.28062349557876587, 'eval_precision': 0.6705882352941176, 'eval_recall': 0.8142857142857143, 'eval_f1': 0.7354838709677418, 'eval_accuracy': 0.9129172714078374, 'eval_runtime': 0.1052, 'eval_samples_per_second': 38.026, 'eval_steps_per_second': 9.506, 'epoch': 19.0}
{'loss': 0.0847, 'learning_rate': 0.0, 'epoch': 20.0}
{'eval_loss': 0.28062349557876587, 'eval_precision': 0.6705882352941176, 'eval_recall': 0.8142857142857143, 'eval_f1': 0.7354838709677418, 'eval_accuracy': 0.9129172714078374, 'eval_runtime': 0.1215, 'eval_samples_per_second': 32.912, 'eval_steps_per_second': 8.228, 'epoch': 20.0}
{'train_runtime': 128.7578, 'train_samples_per_second': 8.543, 'train_steps_per_second': 1.087, 'train_loss': 0.41653164454868863, 'epoch': 20.0}
Finished Training
Saving Model at: /cluster/dataset/midatams/inf-extr/resources/models/line-label_medbert-512_token_finetuned
Saving Tokenizer at: /cluster/dataset/midatams/inf-extr/resources/models/line-label_medbert-512_token_finetuned
Job finished
