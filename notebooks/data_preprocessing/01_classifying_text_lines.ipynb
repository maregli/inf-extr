{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying text lines\n",
    "\n",
    "A classifier is trained to classify single text lines of a report. For example, the lines can be classified as containing a diagnosis (`\"dm\"`) or history (`his`) of a patient. This task was used as a preprocessing step to later steps of structured information extraction. So that only lines classified as containing a diagnosis will be fed to a downstream classifier, extracting the exact diagnosis. This step might be unnecessary with modern transformers that can handle longer text inputs.\n",
    "\n",
    "The files containing the necessary information are inside the `data/raw/labelling` directory. It contains manually labelled reports from different sessions.\n",
    "\n",
    "The original classes per label are:\n",
    "\n",
    "| category    | subcategory       | abbreviation |\n",
    "|-------------|-------------------|--------------|\n",
    "| diagnosis   | MS diagnosis      | dm           |\n",
    "|             | other             | do           |\n",
    "| current state     |              | cu           |\n",
    "| history     |                   | his          |\n",
    "| symptoms    | MS related        | sym          |\n",
    "|             | other             | so           |\n",
    "| MRI | results                  | mr           |\n",
    "| lab | results                  | labr         |\n",
    "|             | other             | labo         |\n",
    "| medication  | MS related        | medms        |\n",
    "|             | other             | medo         |\n",
    "| test, treatment        | results | tr           |\n",
    "| header      |                   | head         |\n",
    "| unknown     |                   | unk          |\n",
    "\n",
    "I will group the classes according to the original approach, and drop observations with no text or label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd()+\"/../..\")\n",
    "from src import paths\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_line_labelling():\n",
    "    \"\"\"Loading the data from the nested csv files in the different \"imported_time\" directories. Labelled reports have a \"rev.csv\" ending\n",
    "    and are in a \"_Marc\" subdirectory. There should only be one entry per rid, that is labelled. Duplicates will be removed.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with columns: \"text\", \"class\", \"rid\"\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    rid_list = []\n",
    "\n",
    "    for root, dirs, files in os.walk(paths.DATA_PATH_LABELLED):\n",
    "        if \"Marc\" not in root:\n",
    "            continue\n",
    "        for file in files:\n",
    "\n",
    "            # Get the research id from filename\n",
    "            rid = file.split(\"_\")[0]\n",
    "            \n",
    "            # Check if the file is a labelled report (and not mri) and if the rid is already in the list\n",
    "            if (file.endswith(\"rev.csv\") and \"mri\" not in file and rid not in rid_list):\n",
    "                \n",
    "                # Append rid to rid list to keep track of which files have been added\n",
    "                rid_list.append(rid)\n",
    "\n",
    "                # Create a dataframe from the csv file\n",
    "                _df = pd.read_csv(os.path.join(root, file))\n",
    "                \n",
    "                # Add the rid to the dataframe\n",
    "                _df = _df.rename(columns={\"text\": \"text\", \"class\": \"class\"})\n",
    "                _df['rid'] = rid\n",
    "                \n",
    "                # Append the dataframe to the main dataframe\n",
    "                try: \n",
    "                    df_list.append(_df)\n",
    "                except:\n",
    "                    print(\"Error with file: \", file)\n",
    "                    print(\"df head: \", _df.head(5))\n",
    "                    print(\"_df head: \", _df.head(5))\n",
    "                    continue\n",
    "    print(\"Number of reports: \", len(df_list))\n",
    "    return pd.concat(df_list)[[\"text\", \"class\", \"rid\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line_text(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    For Transformer to work, there has to be text in the text column. If there is no text, the text column is removed.\n",
    "    \"\"\"\n",
    "    df = df.dropna(subset=[\"text\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_line_class(df: pd.DataFrame):\n",
    "    \"\"\"Cleans the dataframe labels in \"class\".\n",
    "    1) Removes whitespace from beginning and end of text\n",
    "    2) Correct spelling mistakes\n",
    "    3) Fill NaN values with \"unk\"\n",
    "    4) Create a new column \"class_agg\" with the aggregated classes of the original approach.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Class mapping spelling mistakes\n",
    "    class_mapping_spelling = {\n",
    "        'memds': 'medms',\n",
    "        'hs': 'his',\n",
    "        'm': 'mr',\n",
    "    }\n",
    "\n",
    "    # Classes of original approach abbreviation\n",
    "    # classes_orig = [\"dm\", \"do\", \"cu\", \"his\", \"sym\", \"so\", \"mr\", \"labr\", \"labo\", \"medms\", \"medo\", \"tr\", \"head\", \"unk\"]\n",
    "\n",
    "    # Class mapping of original approach\n",
    "    # df = df.assign(class2 = df['class'])\n",
    "    # df.loc[(df['class'] == 'his') | (df['class'] == 'sym') | (df['class'] == 'cu'), 'class2'] = 'his_sym_cu'\n",
    "    # df.loc[(df['class'] == 'labr') | (df['class'] == 'labo'), 'class2'] = 'labr_labo'\n",
    "    # df.loc[(df['class'] == 'to') | (df['class'] == 'tr'), 'class2'] = 'to_tr'\n",
    "    # df.loc[(df['class'] == 'medo') | (df['class'] == 'unk') | (df['class'] == 'do') | (df['class'] == 'so'), 'class2'] = 'medo_unk_do_so'\n",
    "    \n",
    "    class_mapping_agg = {\n",
    "        'his': 'his_sym_cu',\n",
    "        'sym': 'his_sym_cu',\n",
    "        'cu': 'his_sym_cu',\n",
    "        'labr': 'labr_labo',\n",
    "        'labo': 'labr_labo',\n",
    "        'to': 'to_tr',\n",
    "        'tr': 'to_tr',\n",
    "        'medo': 'medo_unk_do_so',\n",
    "        'unk': 'medo_unk_do_so',\n",
    "        'do': 'medo_unk_do_so',\n",
    "        'so': 'medo_unk_do_so',\n",
    "    }\n",
    "\n",
    "    # Cleaning the class column\n",
    "    df['class'] = df['class'].str.strip() \\\n",
    "                             .replace(class_mapping_spelling) \\\n",
    "                             .fillna(\"unk\") \n",
    "\n",
    "    # Creating a new column with the aggregated classes\n",
    "    df['class_agg'] = df['class'].replace(class_mapping_agg)\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_clean_line_df():\n",
    "    \"\"\"Loads and cleans the dataframe from the load_line_labelling function.\n",
    "    \"\"\"\n",
    "    df = load_line_labelling()\n",
    "    df = clean_line_text(df)\n",
    "    df = clean_line_class(df)\n",
    "\n",
    "    return df[[\"rid\", \"text\", \"class\", \"class_agg\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reports:  74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>class_agg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>014673E3-8EBF-4408-96E0-79BE34341EB5</td>\n",
       "      <td>Schubförmige Multiple Sklerose (RRMS), EDSS 3.5</td>\n",
       "      <td>dm</td>\n",
       "      <td>dm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>014673E3-8EBF-4408-96E0-79BE34341EB5</td>\n",
       "      <td>(ES 04/1992, ED 07/1998 (USZ))</td>\n",
       "      <td>do</td>\n",
       "      <td>medo_unk_do_so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>014673E3-8EBF-4408-96E0-79BE34341EB5</td>\n",
       "      <td>Verlauf:</td>\n",
       "      <td>head</td>\n",
       "      <td>head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>014673E3-8EBF-4408-96E0-79BE34341EB5</td>\n",
       "      <td>INDENT 04/1992 Kribbelparästhesien bd. Füsse, ...</td>\n",
       "      <td>his</td>\n",
       "      <td>his_sym_cu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>014673E3-8EBF-4408-96E0-79BE34341EB5</td>\n",
       "      <td>INDENT 1997 Fühl- und auch Kraftminderung des ...</td>\n",
       "      <td>his</td>\n",
       "      <td>his_sym_cu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    rid  \\\n",
       "0  014673E3-8EBF-4408-96E0-79BE34341EB5   \n",
       "1  014673E3-8EBF-4408-96E0-79BE34341EB5   \n",
       "2  014673E3-8EBF-4408-96E0-79BE34341EB5   \n",
       "3  014673E3-8EBF-4408-96E0-79BE34341EB5   \n",
       "4  014673E3-8EBF-4408-96E0-79BE34341EB5   \n",
       "\n",
       "                                                text class       class_agg  \n",
       "0    Schubförmige Multiple Sklerose (RRMS), EDSS 3.5    dm              dm  \n",
       "1                     (ES 04/1992, ED 07/1998 (USZ))    do  medo_unk_do_so  \n",
       "2                                           Verlauf:  head            head  \n",
       "3  INDENT 04/1992 Kribbelparästhesien bd. Füsse, ...   his      his_sym_cu  \n",
       "4  INDENT 1997 Fühl- und auch Kraftminderung des ...   his      his_sym_cu  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_agg values:  class_agg\n",
      "his_sym_cu        312\n",
      "mr                270\n",
      "head              236\n",
      "medms             213\n",
      "labr_labo         184\n",
      "medo_unk_do_so    139\n",
      "to_tr             114\n",
      "dm                 74\n",
      "Name: count, dtype: int64\n",
      "class values:  class\n",
      "mr       270\n",
      "head     236\n",
      "medms    213\n",
      "his      210\n",
      "labr     166\n",
      "tr        77\n",
      "dm        74\n",
      "sym       62\n",
      "unk       50\n",
      "do        42\n",
      "cu        40\n",
      "to        37\n",
      "medo      35\n",
      "labo      18\n",
      "so        12\n",
      "Name: count, dtype: int64\n",
      "Number of reports with missing values in class_agg:  0\n"
     ]
    }
   ],
   "source": [
    "df = load_clean_line_df()\n",
    "display(df.head(5))\n",
    "\n",
    "# Class distribution\n",
    "print(\"class_agg values: \", df.class_agg.value_counts())\n",
    "print(\"class values: \", df[\"class\"].value_counts())\n",
    "\n",
    "# Number of reports with missing values in class_agg\n",
    "print(\"Number of reports with missing values in class_agg: \", df[df[\"class_agg\"].isnull()].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "df.to_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line_labelling/line_labelling_clean.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train test split by rid\n",
    "rids = df.rid.unique()\n",
    "rids_train, rids_test = train_test_split(rids, test_size=0.2, random_state=42)\n",
    "rids_train, rids_val = train_test_split(rids_train, test_size=0.2, random_state=42)\n",
    "\n",
    "df_train = df[df.rid.isin(rids_train)]\n",
    "df_val = df[df.rid.isin(rids_val)]\n",
    "df_test = df[df.rid.isin(rids_test)]\n",
    "\n",
    "# Save the train, val and test dataframes\n",
    "df_train.to_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line_labelling/line_labelling_clean_train.csv\"))\n",
    "\n",
    "df_val.to_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line_labelling/line_labelling_clean_val.csv\"))\n",
    "\n",
    "df_test.to_csv(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line_labelling/line_labelling_clean_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa390ada76e84ba5b5c286b3b2b5564b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/948 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67814ac432c495289e46505adfefb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/249 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b9ead321a84f70af5f341b85d5f113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7908206a76d743969d7f51af4adb633c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/948 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10651da594224b4d868326eeb3b66fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/249 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a61f42bc6a4db1a1fe6807845c9f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create HuggingFace Dataset\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train),\n",
    "    \"val\": Dataset.from_pandas(df_val),\n",
    "    \"test\": Dataset.from_pandas(df_test),\n",
    "})\n",
    "\n",
    "# Drop __index_level_0__ column\n",
    "dataset = dataset.remove_columns(\"__index_level_0__\")\n",
    "\n",
    "# Encode the labels\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "enc.fit(np.stack(dataset[\"train\"][\"class_agg\"]).reshape(-1, 1))\n",
    "dataset = dataset.map(lambda e: {\"labels\": enc.transform(np.stack(e[\"class_agg\"]).reshape(-1, 1)).astype(int)}, batched=True)\n",
    "\n",
    "# Save the dataset\n",
    "dataset.save_to_disk(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line_labelling/line_labelling_clean_dataset\"))\n",
    "\n",
    "# Save the class mapping in a json file\n",
    "class_mapping = {i: c for i, c in enumerate(enc.categories_[0])}\n",
    "with open(os.path.join(paths.DATA_PATH_PREPROCESSED, \"line_labelling/line_labelling_clean_class_mapping.json\"), 'w') as fp:\n",
    "    json.dump(class_mapping, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf-extr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
