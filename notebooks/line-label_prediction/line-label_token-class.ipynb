{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification, TrainingArguments, Trainer\n",
    "from datasets import DatasetDict, load_dataset, Dataset, concatenate_datasets\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd()+\"/../..\")\n",
    "from src import paths\n",
    "from src.utils import (load_model_and_tokenizer, \n",
    "                       load_line_label_token_data, \n",
    "                       line_label_token_label2id, \n",
    "                       line_label_token_id2label, \n",
    "                       tokenize_and_align_labels,\n",
    ")\n",
    "import tqdm\n",
    "import accelerate\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import evaluate\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_token = load_line_label_token_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer pad token ID: 0\n",
      "Tokenizer special tokens: {'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]', 'additional_special_tokens': ['[BRK]']}\n",
      "Model pad token ID: 0\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model_and_tokenizer(model_name=\"line-label-token_medbert-512_finetuned_512\",\n",
    "                                            task_type=\"token\",\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43fa24e457447d79569e051fffec1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/55 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb2dfd2f2c94412bb39266e4cfee37a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b72928d8484126a40ffea7287ee0ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_dataset = dataset_token.map(tokenize_and_align_labels, batched=True, fn_kwargs={\"tokenizer\": tokenizer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                    data_collator=DataCollatorForTokenClassification(tokenizer),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions, labels, metrics = trainer.predict(encoded_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(current_predictions: list):\n",
    "    # Get the most common prediction\n",
    "    remapped_predictions = [line_label_token_id2label[p][2:] for p in current_predictions] # Remove the B- or I- prefix\n",
    "\n",
    "    # Counte the occurrences of each class\n",
    "    class_counts = Counter(remapped_predictions)\n",
    "\n",
    "    # Find the maximum count\n",
    "    max_count = max(class_counts.values())\n",
    "\n",
    "    # Find all classes with the maximum count\n",
    "    most_common_predictions = [prediction for prediction, count in class_counts.items() if count == max_count]\n",
    "\n",
    "    # Return the first one among tied classes\n",
    "    return most_common_predictions[0]\n",
    "    \n",
    "\n",
    "def group_labels_by_text(tokenized_texts, predictions):\n",
    "    line_predictions = []\n",
    "    current_text_predictions = []\n",
    "\n",
    "    for token, prediction in zip(tokenized_texts, predictions):\n",
    "        # The zip will make sure that padded elements from predictions are ignored as overflow is discarded\n",
    "        # Check for the end of a text line (using the BRK token)\n",
    "        if '[BRK]' == token:\n",
    "            # Don't need to add BRK prediction as it is not a token, at this point just add the current text predictions\n",
    "            line_prediction = majority_vote(current_text_predictions)\n",
    "            line_predictions.append(line_prediction)\n",
    "            current_text_predictions = []\n",
    "            \n",
    "        else:\n",
    "            current_text_predictions.append(prediction)\n",
    "\n",
    "    return line_predictions\n",
    "\n",
    "def get_results_from_token_preds(predictions:np.ndarray,\n",
    "                                 dataset:DatasetDict,\n",
    "                                 split:str=\"test\"):\n",
    "    \"\"\"Get a list of line labels from the token predictions. This is done by finding the line breaks in the text\n",
    "    for each rid, then take a majority vote of the labels for each line. All the line labels are concatenated\n",
    "    to a list that should match the labels in the dataset. Because of truncation might have bugs\n",
    "    \n",
    "    Args:\n",
    "        predictions (np.ndarray): shape (n_samples, max_len, n_labels)\n",
    "        dataset (DatasetDict): must contain \"input_ids\" and \"line_label\" for the specified split. Line label is a list of one label per line.\n",
    "        split (str, optional): Split that was used to calculate predictions Defaults to \"test\".\"\"\"\n",
    "    \n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    preds, labs = [], []\n",
    "    for i in range(len(dataset[split])):\n",
    "        # Because of truncation only add labels up to the max length\n",
    "        recoded_preds = group_labels_by_text(tokenizer.convert_ids_to_tokens(dataset[split][i][\"input_ids\"]), predictions[i,:])\n",
    "        max_len = len(recoded_preds)\n",
    "        preds.extend(recoded_preds)\n",
    "        labs.extend(dataset[\"test\"][i][\"line_label\"][:max_len])\n",
    "\n",
    "    return preds, labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, labs = get_results_from_token_preds(predictions, encoded_dataset, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [\"bli\", \"bla\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='/mnt/c/Users/marc_/OneDrive/ETH/MSC_Thesis/inf-extr/resources/models/medbert-512', revision=None, task_type='TOKEN_CLS', inference_mode=True, r=16, target_modules={'value', 'query'}, lora_alpha=8, lora_dropout=0.0, fan_in_fan_out=False, bias='none', modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import PeftConfig, PeftModel\n",
    "PeftConfig.from_pretrained(paths.MODEL_PATH/\"line-label_medbert-512_4bit_LORA_token_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "            dm       0.87      1.00      0.93        13\n",
      "          head       1.00      0.98      0.99        44\n",
      "    his_sym_cu       0.99      0.99      0.99        77\n",
      "     labr_labo       1.00      1.00      1.00        32\n",
      "         medms       1.00      1.00      1.00        16\n",
      "medo_unk_do_so       1.00      0.55      0.71        11\n",
      "            mr       0.96      1.00      0.98        44\n",
      "         to_tr       0.86      1.00      0.92        12\n",
      "\n",
      "      accuracy                           0.97       249\n",
      "     macro avg       0.96      0.94      0.94       249\n",
      "  weighted avg       0.97      0.97      0.97       249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(labs, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inf-extr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
